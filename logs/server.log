[2019-01-10 01:33:16,655] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 01:33:16,662] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 01:33:16,662] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 01:33:16,663] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 01:33:16,663] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-10 01:33:16,696] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 01:33:16,697] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-10 01:33:17,219] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,220] INFO Server environment:host.name=192.168.1.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,222] INFO Server environment:java.version=10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,223] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,223] INFO Server environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,224] INFO Server environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,230] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,259] INFO Server environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,261] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,262] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,263] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,264] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,264] INFO Server environment:user.name=AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,265] INFO Server environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,267] INFO Server environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,301] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,308] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,309] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:17,356] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-10 01:33:17,360] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:33:53,326] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 01:33:55,166] INFO starting (kafka.server.KafkaServer)
[2019-01-10 01:33:55,171] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 01:33:55,296] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:33:55,510] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,511] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,512] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,512] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,513] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,513] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,523] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,546] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,547] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,548] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,550] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,555] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,563] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,564] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,565] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,570] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:33:55,641] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:33:55,658] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:33:55,663] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:33:55,664] INFO Accepted socket connection from /127.0.0.1:60160 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:33:55,688] INFO Client attempting to establish new session at /127.0.0.1:60160 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:55,690] INFO Creating new log file: log.97 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-10 01:33:55,746] INFO Established session 0x1002faa26460000 with negotiated timeout 6000 for client /127.0.0.1:60160 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:33:55,750] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002faa26460000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:33:55,760] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:33:56,192] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0x1 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,261] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0x2 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,290] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0x3 zxid:0x9a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,320] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0x4 zxid:0x9b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,346] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0x5 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,401] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0x6 zxid:0x9d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,466] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0x7 zxid:0x9e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,495] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0x8 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,523] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0x9 zxid:0xa0 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,552] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0xa zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,578] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0xb zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,619] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0xc zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:56,645] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:create cxid:0xd zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:33:57,161] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 01:33:57,211] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 01:33:57,495] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:33:57,530] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:33:57,707] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:33:57,713] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:33:57,708] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:33:57,840] INFO Log directory C:\tmp\kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2019-01-10 01:33:57,867] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 01:33:57,928] INFO Logs loading complete in 61 ms. (kafka.log.LogManager)
[2019-01-10 01:33:57,991] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 01:33:58,006] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 01:33:59,205] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-01-10 01:33:59,338] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 01:33:59,444] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:33:59,449] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:33:59,449] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:33:59,493] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:33:59,650] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 01:33:59,702] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 01:33:59,706] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(your.host.name,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 01:33:59,711] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 01:33:59,920] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:33:59,930] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:33:59,932] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:00,048] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:34:00,123] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:34:00,237] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 01:34:00,264] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:34:00,433] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:34:00,444] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:34:00,448] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:34:00,658] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:34:00,814] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 01:34:00,874] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:34:00,880] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:34:00,898] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 01:34:01,210] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:multi cxid:0xd1 zxid:0xa8 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:01,268] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460000 type:multi cxid:0xd3 zxid:0xa9 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:13,939] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 01:34:15,159] INFO starting (kafka.server.KafkaServer)
[2019-01-10 01:34:15,161] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 01:34:15,212] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:34:15,271] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,271] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,272] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,272] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,272] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,272] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,276] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,277] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,278] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,279] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,280] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,281] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,303] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,305] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,307] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,316] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:15,386] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:34:15,393] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:34:15,400] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60176 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:34:15,401] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:34:15,415] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60176 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:34:15,506] INFO Established session 0x1002faa26460001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60176 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:34:15,511] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002faa26460001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:34:15,526] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:34:15,630] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0x1 zxid:0xab txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:15,706] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0x2 zxid:0xac txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:15,756] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0x3 zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:15,835] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0x4 zxid:0xae txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:15,886] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0x5 zxid:0xaf txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:15,914] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0x6 zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:15,963] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0x7 zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:15,990] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0x8 zxid:0xb2 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:16,019] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0x9 zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:16,045] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0xa zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:16,072] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0xb zxid:0xb5 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:16,102] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0xc zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:16,128] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:create cxid:0xd zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:16,611] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 01:34:16,639] WARN No meta.properties file under dir C:\tmp\kafka-logs-2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 01:34:16,846] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:34:16,877] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:34:16,964] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:34:16,973] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:34:16,965] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:34:17,076] INFO Log directory C:\tmp\kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2019-01-10 01:34:17,104] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 01:34:17,130] INFO Logs loading complete in 26 ms. (kafka.log.LogManager)
[2019-01-10 01:34:17,177] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 01:34:17,189] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 01:34:18,102] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2019-01-10 01:34:18,362] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 01:34:18,460] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:18,472] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:18,474] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:18,524] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:34:18,770] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 01:34:18,841] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 01:34:18,890] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(your.host.name,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 01:34:19,056] WARN No meta.properties file under dir C:\tmp\kafka-logs-2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 01:34:19,398] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:19,413] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:19,413] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:19,472] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:34:19,478] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:34:19,522] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 30 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 01:34:19,670] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:34:19,763] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:34:19,772] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:34:19,772] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:34:19,918] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:34:19,979] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 01:34:19,997] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:34:20,005] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:34:20,012] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-10 01:34:34,701] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 01:34:35,737] INFO starting (kafka.server.KafkaServer)
[2019-01-10 01:34:35,740] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 01:34:35,773] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:34:35,837] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,838] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,841] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,841] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,841] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,842] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,850] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,886] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,886] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,887] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,888] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,889] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,890] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,901] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,901] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,906] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:34:35,965] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:34:35,969] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:34:35,976] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:34:35,975] INFO Accepted socket connection from /127.0.0.1:60196 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:34:35,989] INFO Client attempting to establish new session at /127.0.0.1:60196 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:34:36,036] INFO Established session 0x1002faa26460002 with negotiated timeout 6000 for client /127.0.0.1:60196 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:34:36,040] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002faa26460002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:34:36,052] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:34:36,138] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0x1 zxid:0xbb txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,196] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0x2 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,247] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0x3 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,310] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0x4 zxid:0xbe txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,374] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0x5 zxid:0xbf txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,455] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0x6 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,520] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0x7 zxid:0xc1 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,588] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0x8 zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,658] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0x9 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,684] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0xa zxid:0xc4 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,711] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0xb zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,741] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0xc zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:36,816] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:create cxid:0xd zxid:0xc7 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:34:37,278] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 01:34:37,293] WARN No meta.properties file under dir C:\tmp\kafka-logs-3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 01:34:37,508] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:34:37,543] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:34:37,623] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:34:37,623] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:34:37,626] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:34:37,711] INFO Log directory C:\tmp\kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2019-01-10 01:34:37,742] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 01:34:37,773] INFO Logs loading complete in 29 ms. (kafka.log.LogManager)
[2019-01-10 01:34:37,840] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 01:34:37,855] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 01:34:38,915] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2019-01-10 01:34:39,011] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 01:34:39,096] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:39,103] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:39,103] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:39,153] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:34:39,340] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 01:34:39,375] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 01:34:39,400] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(your.host.name,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 01:34:39,507] WARN No meta.properties file under dir C:\tmp\kafka-logs-3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 01:34:39,741] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:39,743] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:39,756] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:34:39,816] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:34:39,818] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:34:39,835] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 17 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 01:34:39,891] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:34:39,966] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:34:39,974] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:34:39,974] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:34:40,090] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:34:40,162] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 01:34:40,208] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:34:40,212] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:34:40,223] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-10 01:38:04,056] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60246 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:38:04,057] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60246 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:38:04,112] INFO Established session 0x1002faa26460003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:60246 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:38:04,781] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460003 type:setData cxid:0x6 zxid:0xcb txntype:-1 reqpath:n/a Error Path:/config/topics/metalingus Error:KeeperErrorCode = NoNode for /config/topics/metalingus (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:38:04,989] INFO Processed session termination for sessionid: 0x1002faa26460003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:38:05,031] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60246 which had sessionid 0x1002faa26460003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:38:39,140] INFO Accepted socket connection from /127.0.0.1:60257 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:38:39,149] INFO Client attempting to establish new session at /127.0.0.1:60257 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:38:39,201] INFO Established session 0x1002faa26460004 with negotiated timeout 30000 for client /127.0.0.1:60257 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:38:39,744] INFO Processed session termination for sessionid: 0x1002faa26460004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:38:39,801] INFO Closed socket connection for client /127.0.0.1:60257 which had sessionid 0x1002faa26460004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:39:53,827] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60285 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:39:53,833] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60285 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:39:53,880] INFO Established session 0x1002faa26460005 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:60285 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:39:54,290] INFO Processed session termination for sessionid: 0x1002faa26460005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:39:54,334] WARN Unable to read additional data from client sessionid 0x1002faa26460005, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:39:54,346] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60285 which had sessionid 0x1002faa26460005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:41:16,053] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-01-10 01:41:16,062] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 01:41:16,091] WARN No entry found for connection 1 (kafka.utils.CoreUtils$)
java.lang.IllegalStateException: No entry found for connection 1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:330)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:134)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:885)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.server.KafkaServer.doControlledShutdown$1(KafkaServer.scala:496)
	at kafka.server.KafkaServer.controlledShutdown(KafkaServer.scala:545)
	at kafka.server.KafkaServer.$anonfun$shutdown$2(KafkaServer.scala:567)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:567)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:48)
	at kafka.Kafka$$anon$1.run(Kafka.scala:72)
[2019-01-10 01:41:16,095] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:41:16,096] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:41:16,096] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:41:16,097] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:41:16,118] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:41:16,119] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:41:16,125] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:41:16,134] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 01:41:16,136] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,179] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,179] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,185] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:41:16,187] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 1000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:41:16,190] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 01:41:16,192] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:41:16,194] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:41:16,194] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:41:16,195] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:41:16,198] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:41:16,199] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,385] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,385] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,385] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,581] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,581] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,582] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:41:16,588] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 01:41:16,588] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:41:16,590] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:41:16,590] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:41:16,593] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:41:16,600] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:41:16,601] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:41:16,603] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:41:16,603] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,780] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,780] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,781] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,983] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,983] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:16,990] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:17,187] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:17,187] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:17,240] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 01:41:17,242] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 01:41:17,266] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 01:41:17,294] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:41:17,300] INFO Processed session termination for sessionid: 0x1002faa26460000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:41:17,336] INFO Session: 0x1002faa26460000 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:41:17,344] INFO EventThread shut down for session: 0x1002faa26460000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:41:17,342] WARN Unable to read additional data from client sessionid 0x1002faa26460000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:41:17,365] INFO Closed socket connection for client /127.0.0.1:60160 which had sessionid 0x1002faa26460000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:41:17,364] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:41:17,418] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:17,418] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460001 type:multi cxid:0x2b zxid:0xd8 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:41:17,971] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:multi cxid:0xdc zxid:0xd9 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:41:18,030] INFO Got user-level KeeperException when processing sessionid:0x1002faa26460002 type:multi cxid:0xde zxid:0xda txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:41:18,068] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:18,068] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:18,069] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:19,069] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:19,069] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:19,076] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:20,070] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:20,070] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:20,075] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 01:41:20,149] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 01:41:20,157] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-01-10 01:41:25,453] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-01-10 01:41:25,458] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 01:41:25,546] WARN No entry found for connection 3 (kafka.utils.CoreUtils$)
java.lang.IllegalStateException: No entry found for connection 3
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:330)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:134)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:885)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.server.KafkaServer.doControlledShutdown$1(KafkaServer.scala:496)
	at kafka.server.KafkaServer.controlledShutdown(KafkaServer.scala:545)
	at kafka.server.KafkaServer.$anonfun$shutdown$2(KafkaServer.scala:567)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:567)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:48)
	at kafka.Kafka$$anon$1.run(Kafka.scala:72)
[2019-01-10 01:41:25,552] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:41:25,555] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:41:25,555] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:41:25,557] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:41:25,583] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:41:25,585] INFO [Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:41:25,594] INFO [Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:41:25,608] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 01:41:25,612] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:25,644] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:25,644] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:25,650] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:41:25,652] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 2000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:41:25,658] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 01:41:25,660] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:41:25,662] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:41:25,662] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:41:25,665] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:41:25,667] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:41:25,668] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:25,846] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:25,846] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:25,855] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,043] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,043] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,053] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:41:26,060] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 01:41:26,064] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:41:26,065] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:41:26,066] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:41:26,076] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:41:26,086] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:41:26,090] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:41:26,097] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:41:26,098] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,242] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,242] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,250] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,442] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,442] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,447] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,643] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,643] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:26,668] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 01:41:26,672] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 01:41:26,700] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 01:41:26,713] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:41:26,715] INFO Processed session termination for sessionid: 0x1002faa26460001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:41:26,729] INFO Session: 0x1002faa26460001 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:41:26,730] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60176 which had sessionid 0x1002faa26460001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:41:26,736] INFO EventThread shut down for session: 0x1002faa26460001 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:41:26,743] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:41:26,752] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:27,291] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:27,291] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:27,300] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:27,314] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:27,315] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:27,318] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:28,282] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:28,282] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:28,288] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 01:41:28,382] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 01:41:28,390] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-01-10 01:41:28,838] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-01-10 01:41:28,850] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 01:41:28,874] WARN No entry found for connection 3 (kafka.utils.CoreUtils$)
java.lang.IllegalStateException: No entry found for connection 3
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:330)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:134)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:885)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.server.KafkaServer.doControlledShutdown$1(KafkaServer.scala:496)
	at kafka.server.KafkaServer.controlledShutdown(KafkaServer.scala:545)
	at kafka.server.KafkaServer.$anonfun$shutdown$2(KafkaServer.scala:567)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:567)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:48)
	at kafka.Kafka$$anon$1.run(Kafka.scala:72)
[2019-01-10 01:41:28,877] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:41:28,882] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:41:28,882] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:41:28,885] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:41:28,913] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:41:28,917] INFO [Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:41:28,927] INFO [Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:41:28,945] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 01:41:28,950] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,057] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,057] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,071] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:41:29,078] INFO [ProducerId Manager 3]: Shutdown complete: last producerId assigned 3000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:41:29,081] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 01:41:29,082] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:41:29,086] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:41:29,086] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:41:29,099] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:41:29,101] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:41:29,103] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,252] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,252] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,258] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,458] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,458] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,462] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:41:29,464] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 01:41:29,464] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:41:29,465] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:41:29,465] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:41:29,468] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:41:29,477] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:41:29,478] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:41:29,479] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:41:29,480] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,663] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,663] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,670] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,859] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,859] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:29,859] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:30,060] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:30,060] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:41:30,078] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 01:41:30,081] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 01:41:30,105] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 01:41:30,125] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:41:30,127] INFO Processed session termination for sessionid: 0x1002faa26460002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:41:30,155] INFO Session: 0x1002faa26460002 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:41:30,162] INFO EventThread shut down for session: 0x1002faa26460002 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:41:30,156] INFO Closed socket connection for client /127.0.0.1:60196 which had sessionid 0x1002faa26460002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:41:30,166] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:41:30,168] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:30,896] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:30,896] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:30,905] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:31,887] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:31,887] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:31,896] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:31,960] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:31,960] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:41:31,965] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 01:41:32,057] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 01:41:32,066] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-01-10 01:46:22,408] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 01:46:22,417] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 01:46:22,419] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 01:46:22,420] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 01:46:22,421] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-10 01:46:22,456] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 01:46:22,458] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-10 01:46:22,823] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,823] INFO Server environment:host.name=192.168.1.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,831] INFO Server environment:java.version=10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,833] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,836] INFO Server environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,840] INFO Server environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,857] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,880] INFO Server environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,881] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,883] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,885] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,886] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,887] INFO Server environment:user.name=AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,888] INFO Server environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,896] INFO Server environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,913] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,913] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,914] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:22,961] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-10 01:46:22,967] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:46:32,442] INFO Accepted socket connection from /127.0.0.1:60395 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:46:32,460] INFO Client attempting to establish new session at /127.0.0.1:60395 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:32,463] INFO Creating new log file: log.dd (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-10 01:46:32,522] INFO Established session 0x1002fb622f80000 with negotiated timeout 30000 for client /127.0.0.1:60395 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:46:32,735] INFO Processed session termination for sessionid: 0x1002fb622f80000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:46:32,761] INFO Closed socket connection for client /127.0.0.1:60395 which had sessionid 0x1002fb622f80000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:47:08,796] INFO Accepted socket connection from /127.0.0.1:60404 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:47:08,804] INFO Client attempting to establish new session at /127.0.0.1:60404 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:47:08,859] INFO Established session 0x1002fb622f80001 with negotiated timeout 30000 for client /127.0.0.1:60404 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:47:08,985] INFO Processed session termination for sessionid: 0x1002fb622f80001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:09,025] INFO Closed socket connection for client /127.0.0.1:60404 which had sessionid 0x1002fb622f80001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:47:30,430] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 01:47:31,342] INFO starting (kafka.server.KafkaServer)
[2019-01-10 01:47:31,343] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 01:47:31,373] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:47:31,474] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,475] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,476] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,477] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,477] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,477] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,484] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,486] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,512] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,513] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,516] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,518] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,523] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,525] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,527] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,532] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:31,583] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:47:31,588] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:47:31,594] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60415 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:47:31,595] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:47:31,608] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60415 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:47:31,663] INFO Established session 0x1002fb622f80002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60415 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:47:31,669] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002fb622f80002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:47:31,679] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:47:31,791] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0x1 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:31,839] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0x2 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:31,864] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0x3 zxid:0xe5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:31,907] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0x4 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:31,930] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0x5 zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:31,951] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0x6 zxid:0xe8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:31,984] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0x7 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:32,008] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0x8 zxid:0xea txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:32,030] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0x9 zxid:0xeb txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:32,051] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0xa zxid:0xec txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:32,074] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0xb zxid:0xed txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:32,096] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0xc zxid:0xee txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:32,118] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:create cxid:0xd zxid:0xef txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:32,601] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 01:47:32,799] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:47:32,836] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:47:32,929] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:47:32,929] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:47:32,938] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:47:33,076] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 01:47:33,115] INFO Logs loading complete in 34 ms. (kafka.log.LogManager)
[2019-01-10 01:47:33,187] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 01:47:33,201] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 01:47:34,354] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-01-10 01:47:34,474] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 01:47:34,540] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:34,542] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:34,547] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:34,602] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:47:34,751] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 01:47:34,820] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 01:47:34,829] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(your.host.name,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 01:47:35,035] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:35,051] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:35,051] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:35,219] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:47:35,291] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:47:35,362] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 01:47:35,387] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:47:35,463] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:47:35,471] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:47:35,475] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:47:35,665] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:47:35,674] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 01:47:35,750] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:47:35,859] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:47:35,922] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 01:47:36,087] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:multi cxid:0xd5 zxid:0xf3 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:36,344] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80002 type:multi cxid:0xd9 zxid:0xf5 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:36,813] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 01:47:38,814] INFO starting (kafka.server.KafkaServer)
[2019-01-10 01:47:38,817] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 01:47:38,867] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:47:38,948] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:38,966] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:38,967] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:38,968] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:38,969] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:38,969] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:38,981] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,001] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,003] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,010] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,015] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,022] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,025] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,027] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,036] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,046] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3a0baae5 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:39,152] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:47:39,187] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:47:39,192] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:47:39,192] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60434 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:47:39,210] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60434 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:47:39,309] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002fb622f80003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:47:39,311] INFO Established session 0x1002fb622f80003 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60434 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:47:39,354] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:47:39,508] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0x1 zxid:0xf7 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,564] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0x2 zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,590] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0x3 zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,634] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0x4 zxid:0xfa txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,680] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0x5 zxid:0xfb txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,723] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0x6 zxid:0xfc txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,775] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0x7 zxid:0xfd txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,810] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0x8 zxid:0xfe txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,847] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0x9 zxid:0xff txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,877] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0xa zxid:0x100 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,947] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0xb zxid:0x101 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:39,978] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0xc zxid:0x102 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:40,023] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:create cxid:0xd zxid:0x103 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:40,694] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 01:47:40,956] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 01:47:41,012] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:47:41,067] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:47:41,176] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:47:41,177] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:47:41,177] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:47:41,342] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 01:47:41,434] INFO Logs loading complete in 91 ms. (kafka.log.LogManager)
[2019-01-10 01:47:41,551] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 01:47:41,565] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 01:47:42,852] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2019-01-10 01:47:42,953] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 01:47:43,059] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:43,060] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:43,060] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:43,136] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:47:43,384] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 01:47:43,416] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 01:47:43,425] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(your.host.name,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 01:47:43,510] INFO starting (kafka.server.KafkaServer)
[2019-01-10 01:47:43,539] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 01:47:43,707] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:47:43,742] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:43,783] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:43,784] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:43,824] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,828] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,831] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,831] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,831] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,832] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,838] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,852] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:47:43,840] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,870] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:47:43,870] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,874] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,904] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 17 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 01:47:43,892] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,930] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,935] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,938] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,942] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:43,952] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:47:44,039] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:47:44,037] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:47:44,055] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:47:44,063] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60453 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:47:44,066] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:47:44,081] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60453 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:47:44,105] INFO Established session 0x1002fb622f80004 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60453 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:47:44,108] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002fb622f80004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:47:44,124] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:47:44,139] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:47:44,186] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:47:44,208] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:47:44,288] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0x1 zxid:0x107 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,346] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0x2 zxid:0x108 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,356] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:47:44,405] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0x3 zxid:0x109 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,427] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0x4 zxid:0x10a txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,454] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0x5 zxid:0x10b txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,485] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0x6 zxid:0x10c txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,516] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0x7 zxid:0x10d txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,551] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0x8 zxid:0x10e txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,590] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0x9 zxid:0x10f txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,653] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0xa zxid:0x110 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,686] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0xb zxid:0x111 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,689] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 01:47:44,718] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:47:44,720] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:47:44,731] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-10 01:47:44,720] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0xc zxid:0x112 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:44,760] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:create cxid:0xd zxid:0x113 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:47:45,433] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 01:47:45,709] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:47:45,751] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:47:45,849] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:47:45,849] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:47:45,849] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:47:45,973] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 01:47:46,002] INFO Logs loading complete in 28 ms. (kafka.log.LogManager)
[2019-01-10 01:47:46,057] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 01:47:46,071] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 01:47:47,338] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2019-01-10 01:47:47,434] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 01:47:47,504] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:47,509] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:47,509] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:47,571] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:47:47,768] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 01:47:47,816] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 01:47:47,823] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(your.host.name,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 01:47:48,153] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:48,168] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:48,168] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:47:48,267] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:47:48,271] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:47:48,287] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 01:47:48,342] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:6000,blockEndProducerId:6999) by writing to Zk with path version 7 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:47:48,408] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:47:48,417] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:47:48,421] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:47:48,524] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:47:48,580] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 01:47:48,599] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:47:48,600] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:47:48,608] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-10 01:48:02,100] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60476 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:48:02,106] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60476 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:48:02,182] INFO Established session 0x1002fb622f80005 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:60476 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:48:02,788] INFO Processed session termination for sessionid: 0x1002fb622f80005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:48:02,893] WARN Unable to read additional data from client sessionid 0x1002fb622f80005, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:48:02,901] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60476 which had sessionid 0x1002fb622f80005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:51:30,142] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-01-10 01:51:30,150] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 01:51:30,191] WARN No entry found for connection 1 (kafka.utils.CoreUtils$)
java.lang.IllegalStateException: No entry found for connection 1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:330)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:134)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:885)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.server.KafkaServer.doControlledShutdown$1(KafkaServer.scala:496)
	at kafka.server.KafkaServer.controlledShutdown(KafkaServer.scala:545)
	at kafka.server.KafkaServer.$anonfun$shutdown$2(KafkaServer.scala:567)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:567)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:48)
	at kafka.Kafka$$anon$1.run(Kafka.scala:72)
[2019-01-10 01:51:30,201] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:51:30,203] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:51:30,203] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:51:30,206] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:51:30,237] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:51:30,242] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:51:30,253] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:51:30,262] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 01:51:30,267] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,327] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,327] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,335] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:51:30,338] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 4000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:51:30,345] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 01:51:30,346] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:51:30,351] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:51:30,351] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:51:30,360] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:51:30,364] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:51:30,365] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,542] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,542] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,546] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,719] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,719] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,727] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:51:30,736] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 01:51:30,738] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:51:30,741] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:51:30,741] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:51:30,747] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:51:30,755] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:51:30,756] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:51:30,758] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:51:30,758] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,921] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,921] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:30,929] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:31,130] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:31,130] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:31,137] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:31,333] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:31,333] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:31,354] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 01:51:31,361] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 01:51:31,397] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 01:51:31,425] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:51:31,430] INFO Processed session termination for sessionid: 0x1002fb622f80002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:51:31,546] INFO Session: 0x1002fb622f80002 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:51:31,553] INFO EventThread shut down for session: 0x1002fb622f80002 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:51:31,547] WARN Unable to read additional data from client sessionid 0x1002fb622f80002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:51:31,557] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60415 which had sessionid 0x1002fb622f80002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:51:31,569] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:51:31,604] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:31,610] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80003 type:multi cxid:0x2d zxid:0x11a txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:51:32,240] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:32,240] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:32,250] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:32,410] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:multi cxid:0xdc zxid:0x11b txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:51:32,522] INFO Got user-level KeeperException when processing sessionid:0x1002fb622f80004 type:multi cxid:0xe0 zxid:0x11d txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:51:33,245] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:33,245] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:33,245] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:33,559] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-01-10 01:51:33,567] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 01:51:33,612] WARN No entry found for connection 3 (kafka.utils.CoreUtils$)
java.lang.IllegalStateException: No entry found for connection 3
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:330)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:134)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:885)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.server.KafkaServer.doControlledShutdown$1(KafkaServer.scala:496)
	at kafka.server.KafkaServer.controlledShutdown(KafkaServer.scala:545)
	at kafka.server.KafkaServer.$anonfun$shutdown$2(KafkaServer.scala:567)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:567)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:48)
	at kafka.Kafka$$anon$1.run(Kafka.scala:72)
[2019-01-10 01:51:33,619] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:51:33,623] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:51:33,623] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:51:33,625] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:51:33,654] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:51:33,656] INFO [Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:51:33,664] INFO [Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:51:33,672] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 01:51:33,676] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:33,821] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:33,821] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:33,837] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:51:33,843] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 5000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:51:33,847] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 01:51:33,847] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:51:33,852] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:51:33,852] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:51:33,867] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:51:33,874] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:51:33,875] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,026] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,031] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,026] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,225] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:34,227] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,225] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:34,227] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,231] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 01:51:34,231] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:51:34,255] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 01:51:34,259] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:51:34,263] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:51:34,265] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:51:34,272] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:51:34,299] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:51:34,306] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:51:34,309] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:51:34,311] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,346] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 01:51:34,356] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-01-10 01:51:34,429] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,429] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,438] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,627] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,631] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,627] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,838] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,838] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:34,872] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 01:51:34,875] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 01:51:34,919] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 01:51:34,941] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:51:34,944] INFO Processed session termination for sessionid: 0x1002fb622f80003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:51:34,981] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60434 which had sessionid 0x1002fb622f80003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:51:34,981] INFO Session: 0x1002fb622f80003 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:51:34,987] INFO EventThread shut down for session: 0x1002fb622f80003 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:51:34,992] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:51:35,010] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:35,388] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:35,388] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:35,393] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:36,389] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:36,389] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:36,398] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:36,458] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-01-10 01:51:36,466] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 01:51:36,492] WARN No entry found for connection 3 (kafka.utils.CoreUtils$)
java.lang.IllegalStateException: No entry found for connection 3
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:330)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:134)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:885)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.server.KafkaServer.doControlledShutdown$1(KafkaServer.scala:496)
	at kafka.server.KafkaServer.controlledShutdown(KafkaServer.scala:545)
	at kafka.server.KafkaServer.$anonfun$shutdown$2(KafkaServer.scala:567)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:567)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:48)
	at kafka.Kafka$$anon$1.run(Kafka.scala:72)
[2019-01-10 01:51:36,495] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:51:36,502] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:51:36,502] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:51:36,505] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:51:36,529] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 01:51:36,534] INFO [Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:51:36,541] INFO [Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 01:51:36,551] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 01:51:36,552] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:36,597] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:36,597] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:36,609] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:51:36,618] INFO [ProducerId Manager 3]: Shutdown complete: last producerId assigned 6000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:51:36,621] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 01:51:36,621] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:51:36,633] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:51:36,633] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:51:36,636] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:51:36,638] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:51:36,639] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:36,844] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:36,844] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:36,850] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:36,998] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:36,998] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,013] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:51:37,024] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 01:51:37,025] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:51:37,026] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:51:37,026] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:51:37,032] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:51:37,037] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 01:51:37,039] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:51:37,040] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 01:51:37,041] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,045] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,045] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,050] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,245] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,245] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,252] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,389] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:37,389] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:37,400] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 01:51:37,445] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,449] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:51:37,461] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 01:51:37,470] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 01:51:37,500] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 01:51:37,509] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 01:51:37,521] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-01-10 01:51:37,531] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:51:37,537] INFO Processed session termination for sessionid: 0x1002fb622f80004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:51:37,592] INFO Session: 0x1002fb622f80004 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:51:37,594] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60453 which had sessionid 0x1002fb622f80004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:51:37,606] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:51:37,620] INFO EventThread shut down for session: 0x1002fb622f80004 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:51:37,623] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:38,026] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:38,026] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:38,026] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:39,027] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:39,027] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:39,034] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:40,028] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:40,028] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:51:40,040] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 01:51:40,109] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 01:51:40,119] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-01-10 01:52:13,049] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 01:52:13,056] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 01:52:13,056] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 01:52:13,058] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 01:52:13,060] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-10 01:52:13,096] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 01:52:13,101] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-10 01:52:13,432] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,432] INFO Server environment:host.name=192.168.1.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,436] INFO Server environment:java.version=10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,437] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,439] INFO Server environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,440] INFO Server environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,443] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,444] INFO Server environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,445] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,468] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,469] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,469] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,471] INFO Server environment:user.name=AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,472] INFO Server environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,473] INFO Server environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,492] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,492] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,499] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:13,546] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-10 01:52:13,549] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:52:28,171] INFO Accepted socket connection from /127.0.0.1:60572 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:52:28,185] INFO Client attempting to establish new session at /127.0.0.1:60572 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:28,189] INFO Creating new log file: log.120 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-10 01:52:28,259] INFO Established session 0x1002fbb7c7b0000 with negotiated timeout 30000 for client /127.0.0.1:60572 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:28,384] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0000 type:create cxid:0x2 zxid:0x121 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics/metalingus Error:KeeperErrorCode = NodeExists for /admin/delete_topics/metalingus (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:28,466] INFO Processed session termination for sessionid: 0x1002fbb7c7b0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:28,495] INFO Closed socket connection for client /127.0.0.1:60572 which had sessionid 0x1002fbb7c7b0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:52:45,784] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 01:52:46,724] INFO starting (kafka.server.KafkaServer)
[2019-01-10 01:52:46,726] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 01:52:46,756] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:52:46,826] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,826] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,828] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,828] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,829] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,829] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,838] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,867] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,868] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,870] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,871] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,872] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,873] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,875] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,884] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,888] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:46,993] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:52:47,002] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:52:47,008] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60583 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:52:47,010] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:52:47,023] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60583 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:47,058] INFO Established session 0x1002fbb7c7b0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60583 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:47,066] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002fbb7c7b0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:52:47,075] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:52:47,225] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0x1 zxid:0x124 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,316] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0x2 zxid:0x125 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,354] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0x3 zxid:0x126 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,402] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0x4 zxid:0x127 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,435] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0x5 zxid:0x128 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,457] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0x6 zxid:0x129 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,496] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0x7 zxid:0x12a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,524] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0x8 zxid:0x12b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,545] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0x9 zxid:0x12c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,568] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0xa zxid:0x12d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,591] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0xb zxid:0x12e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,612] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0xc zxid:0x12f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,635] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:create cxid:0xd zxid:0x130 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:47,978] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 01:52:48,156] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:52:48,188] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:52:48,276] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:52:48,279] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:52:48,276] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:52:48,374] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 01:52:48,404] INFO Logs loading complete in 29 ms. (kafka.log.LogManager)
[2019-01-10 01:52:48,449] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 01:52:48,459] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 01:52:49,215] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-01-10 01:52:49,326] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 01:52:49,386] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:49,394] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:49,393] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:49,445] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:52:49,607] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 01:52:49,652] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 01:52:49,657] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(your.host.name,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 01:52:49,812] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:49,823] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:49,828] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:49,918] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:52:49,926] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:52:50,046] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 90 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 01:52:50,070] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:7000,blockEndProducerId:7999) by writing to Zk with path version 8 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:52:50,143] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:52:50,149] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:52:50,155] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:52:50,328] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:52:50,395] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 01:52:50,497] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:52:50,720] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:52:50,754] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 01:52:50,960] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:multi cxid:0xd5 zxid:0x134 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:51,176] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0001 type:multi cxid:0xd9 zxid:0x136 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:53,454] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 01:52:55,069] INFO starting (kafka.server.KafkaServer)
[2019-01-10 01:52:55,071] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 01:52:55,128] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:52:55,207] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,210] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,211] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,211] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,212] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,212] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,218] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,219] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,245] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,251] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,260] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,263] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,268] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,270] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,278] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,285] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:52:55,358] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:52:55,368] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:52:55,388] INFO Accepted socket connection from /127.0.0.1:60601 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:52:55,389] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:52:55,417] INFO Client attempting to establish new session at /127.0.0.1:60601 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:55,445] INFO Established session 0x1002fbb7c7b0002 with negotiated timeout 6000 for client /127.0.0.1:60601 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:52:55,446] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002fbb7c7b0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:52:55,478] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:52:55,673] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0x1 zxid:0x138 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:55,776] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0x2 zxid:0x139 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:55,833] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0x3 zxid:0x13a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:55,885] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0x4 zxid:0x13b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:55,936] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0x5 zxid:0x13c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:56,037] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0x6 zxid:0x13d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:56,086] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0x7 zxid:0x13e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:56,120] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0x8 zxid:0x13f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:56,149] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0x9 zxid:0x140 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:56,182] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0xa zxid:0x141 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:56,201] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0xb zxid:0x142 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:56,233] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0xc zxid:0x143 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:56,261] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0002 type:create cxid:0xd zxid:0x144 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:52:56,900] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 01:52:57,219] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:52:57,285] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:52:57,473] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:52:57,473] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:52:57,474] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:52:57,538] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 01:52:57,581] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 01:52:57,627] INFO Logs loading complete in 32 ms. (kafka.log.LogManager)
[2019-01-10 01:52:57,689] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 01:52:57,702] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 01:52:58,847] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2019-01-10 01:52:58,960] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 01:52:59,025] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:59,031] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:59,031] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:59,108] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:52:59,268] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 01:52:59,347] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 01:52:59,417] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(your.host.name,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 01:52:59,635] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:59,646] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:59,646] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:52:59,713] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:52:59,720] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:52:59,744] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 17 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 01:52:59,805] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:8000,blockEndProducerId:8999) by writing to Zk with path version 9 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:52:59,879] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:52:59,889] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:52:59,895] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:52:59,944] INFO starting (kafka.server.KafkaServer)
[2019-01-10 01:52:59,947] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 01:52:59,999] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:53:00,077] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:53:00,095] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 01:53:00,111] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:53:00,113] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:53:00,125] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-10 01:53:00,134] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,185] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,254] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,260] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,263] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,266] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,294] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,306] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,316] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,330] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,334] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,338] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,345] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,351] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,359] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,378] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 01:53:00,491] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:53:00,511] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:53:00,521] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:53:00,521] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60624 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:53:00,535] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60624 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:53:00,577] INFO Established session 0x1002fbb7c7b0003 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:60624 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:53:00,587] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002fbb7c7b0003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 01:53:00,604] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 01:53:00,740] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0x1 zxid:0x148 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:00,814] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0x2 zxid:0x149 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:00,841] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0x3 zxid:0x14a txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:00,865] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0x4 zxid:0x14b txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:00,887] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0x5 zxid:0x14c txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:00,939] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0x6 zxid:0x14d txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:00,990] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0x7 zxid:0x14e txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:01,036] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0x8 zxid:0x14f txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:01,068] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0x9 zxid:0x150 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:01,101] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0xa zxid:0x151 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:01,135] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0xb zxid:0x152 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:01,169] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0xc zxid:0x153 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:01,200] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0003 type:create cxid:0xd zxid:0x154 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:01,598] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 01:53:01,798] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:53:01,853] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://your.host.name:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 01:53:01,960] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:53:01,968] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:53:01,962] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 01:53:02,074] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 01:53:02,107] INFO Logs loading complete in 32 ms. (kafka.log.LogManager)
[2019-01-10 01:53:02,160] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 01:53:02,170] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 01:53:03,025] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2019-01-10 01:53:03,106] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 01:53:03,158] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:53:03,165] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:53:03,164] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:53:03,211] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 01:53:03,371] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 01:53:03,433] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 01:53:03,444] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(your.host.name,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 01:53:03,738] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:53:03,739] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:53:03,739] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 01:53:03,818] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:53:03,835] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 01:53:03,852] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 01:53:03,921] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:9000,blockEndProducerId:9999) by writing to Zk with path version 10 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 01:53:03,972] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:53:03,978] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 01:53:03,978] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 01:53:04,072] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 01:53:04,127] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 01:53:04,138] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:53:04,167] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 01:53:04,182] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-10 01:53:28,640] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60649 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:53:28,648] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60649 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:53:28,736] INFO Established session 0x1002fbb7c7b0004 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:60649 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:53:29,245] INFO Processed session termination for sessionid: 0x1002fbb7c7b0004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:29,352] WARN Unable to read additional data from client sessionid 0x1002fbb7c7b0004, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:53:29,357] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60649 which had sessionid 0x1002fbb7c7b0004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 01:53:59,131] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:60656 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 01:53:59,138] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:60656 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:53:59,166] INFO Established session 0x1002fbb7c7b0005 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:60656 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 01:53:59,772] INFO Got user-level KeeperException when processing sessionid:0x1002fbb7c7b0005 type:setData cxid:0x6 zxid:0x15a txntype:-1 reqpath:n/a Error Path:/config/topics/old-skul Error:KeeperErrorCode = NoNode for /config/topics/old-skul (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:59,904] INFO Processed session termination for sessionid: 0x1002fbb7c7b0005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 01:53:59,930] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60656 which had sessionid 0x1002fbb7c7b0005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:02:49,926] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:02:59,718] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:03:03,829] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:05:17,057] ERROR [KafkaApi-1] Number of alive brokers '0' does not meet the required replication factor '1' for the offsets topic (configured via 'offsets.topic.replication.factor'). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)
[2019-01-10 02:12:49,927] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:12:59,718] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:13:03,830] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:22:37,269] INFO Accepted socket connection from /127.0.0.1:61078 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:37,303] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:37,303] INFO Closed socket connection for client /127.0.0.1:61078 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:37,374] INFO Accepted socket connection from /127.0.0.1:61079 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:37,377] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:37,380] INFO Closed socket connection for client /127.0.0.1:61079 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:37,488] INFO Accepted socket connection from /127.0.0.1:61080 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:37,490] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:37,495] INFO Closed socket connection for client /127.0.0.1:61080 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:37,704] INFO Accepted socket connection from /127.0.0.1:61081 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:37,714] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:37,715] INFO Closed socket connection for client /127.0.0.1:61081 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:38,079] INFO Accepted socket connection from /127.0.0.1:61082 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:38,080] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:38,087] INFO Closed socket connection for client /127.0.0.1:61082 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:38,905] INFO Accepted socket connection from /127.0.0.1:61083 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:38,906] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:38,910] INFO Closed socket connection for client /127.0.0.1:61083 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:39,883] INFO Accepted socket connection from /127.0.0.1:61084 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:39,885] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:39,892] INFO Closed socket connection for client /127.0.0.1:61084 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:40,958] INFO Accepted socket connection from /127.0.0.1:61085 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:40,959] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:40,970] INFO Closed socket connection for client /127.0.0.1:61085 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:42,188] INFO Accepted socket connection from /127.0.0.1:61086 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:42,189] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:42,197] INFO Closed socket connection for client /127.0.0.1:61086 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:43,366] INFO Accepted socket connection from /127.0.0.1:61087 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:43,367] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:43,374] INFO Closed socket connection for client /127.0.0.1:61087 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:44,390] INFO Accepted socket connection from /127.0.0.1:61088 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:44,393] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:44,402] INFO Closed socket connection for client /127.0.0.1:61088 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:45,569] INFO Accepted socket connection from /127.0.0.1:61089 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:45,570] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:45,578] INFO Closed socket connection for client /127.0.0.1:61089 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:46,748] INFO Accepted socket connection from /127.0.0.1:61090 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:46,749] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:46,759] INFO Closed socket connection for client /127.0.0.1:61090 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:47,826] INFO Accepted socket connection from /127.0.0.1:61092 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:47,827] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:47,838] INFO Closed socket connection for client /127.0.0.1:61092 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:48,904] INFO Accepted socket connection from /127.0.0.1:61097 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:48,905] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:48,914] INFO Closed socket connection for client /127.0.0.1:61097 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:49,925] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:22:50,030] INFO Accepted socket connection from /127.0.0.1:61098 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:50,031] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:50,041] INFO Closed socket connection for client /127.0.0.1:61098 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:50,957] INFO Accepted socket connection from /127.0.0.1:61099 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:50,958] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:50,965] INFO Closed socket connection for client /127.0.0.1:61099 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:51,781] INFO Accepted socket connection from /127.0.0.1:61100 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:51,782] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:51,792] INFO Closed socket connection for client /127.0.0.1:61100 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:52,955] INFO Accepted socket connection from /127.0.0.1:61101 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:52,956] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:52,967] INFO Closed socket connection for client /127.0.0.1:61101 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:53,932] INFO Accepted socket connection from /127.0.0.1:61102 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:53,934] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:53,944] INFO Closed socket connection for client /127.0.0.1:61102 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:54,826] INFO Accepted socket connection from /127.0.0.1:61104 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:54,828] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:54,837] INFO Closed socket connection for client /127.0.0.1:61104 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:55,805] INFO Accepted socket connection from /127.0.0.1:61105 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:55,806] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:55,815] INFO Closed socket connection for client /127.0.0.1:61105 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:56,732] INFO Accepted socket connection from /127.0.0.1:61106 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:56,734] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:56,742] INFO Closed socket connection for client /127.0.0.1:61106 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:57,707] INFO Accepted socket connection from /127.0.0.1:61107 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:57,710] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:57,719] INFO Closed socket connection for client /127.0.0.1:61107 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:58,931] INFO Accepted socket connection from /127.0.0.1:61108 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:58,932] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:58,940] INFO Closed socket connection for client /127.0.0.1:61108 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:59,719] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:22:59,808] INFO Accepted socket connection from /127.0.0.1:61110 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:22:59,809] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:22:59,819] INFO Closed socket connection for client /127.0.0.1:61110 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:00,991] INFO Accepted socket connection from /127.0.0.1:61111 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:00,993] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:01,005] INFO Closed socket connection for client /127.0.0.1:61111 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:02,221] INFO Accepted socket connection from /127.0.0.1:61112 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:02,222] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:02,230] INFO Closed socket connection for client /127.0.0.1:61112 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:03,448] INFO Accepted socket connection from /127.0.0.1:61114 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:03,449] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:03,453] INFO Closed socket connection for client /127.0.0.1:61114 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:03,828] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:23:04,419] INFO Accepted socket connection from /127.0.0.1:61115 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:04,421] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:04,437] INFO Closed socket connection for client /127.0.0.1:61115 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:05,354] INFO Accepted socket connection from /127.0.0.1:61116 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:05,355] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:05,364] INFO Closed socket connection for client /127.0.0.1:61116 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:06,584] INFO Accepted socket connection from /127.0.0.1:61117 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:06,586] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:06,597] INFO Closed socket connection for client /127.0.0.1:61117 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:07,763] INFO Accepted socket connection from /127.0.0.1:61118 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:07,765] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:07,775] INFO Closed socket connection for client /127.0.0.1:61118 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:08,842] INFO Accepted socket connection from /127.0.0.1:61120 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:08,844] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:08,852] INFO Closed socket connection for client /127.0.0.1:61120 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:09,868] INFO Accepted socket connection from /127.0.0.1:61122 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:09,869] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:09,872] INFO Closed socket connection for client /127.0.0.1:61122 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:10,838] INFO Accepted socket connection from /127.0.0.1:61123 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:10,839] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:10,851] INFO Closed socket connection for client /127.0.0.1:61123 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:11,716] INFO Accepted socket connection from /127.0.0.1:61124 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:11,717] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:11,725] INFO Closed socket connection for client /127.0.0.1:61124 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:12,791] INFO Accepted socket connection from /127.0.0.1:61125 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:12,792] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:12,801] INFO Closed socket connection for client /127.0.0.1:61125 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:13,918] INFO Accepted socket connection from /127.0.0.1:61126 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:13,919] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:13,927] INFO Closed socket connection for client /127.0.0.1:61126 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:14,895] INFO Accepted socket connection from /127.0.0.1:61127 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:14,896] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:14,904] INFO Closed socket connection for client /127.0.0.1:61127 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:15,766] INFO Accepted socket connection from /127.0.0.1:61128 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:15,769] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:15,775] INFO Closed socket connection for client /127.0.0.1:61128 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:16,639] INFO Accepted socket connection from /127.0.0.1:61129 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:16,641] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:16,650] INFO Closed socket connection for client /127.0.0.1:61129 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:17,817] INFO Accepted socket connection from /127.0.0.1:61130 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:17,819] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:17,827] INFO Closed socket connection for client /127.0.0.1:61130 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:18,892] INFO Accepted socket connection from /127.0.0.1:61131 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:18,893] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:18,901] INFO Closed socket connection for client /127.0.0.1:61131 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:19,963] INFO Accepted socket connection from /127.0.0.1:61133 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:19,965] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:19,974] INFO Closed socket connection for client /127.0.0.1:61133 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:20,937] INFO Accepted socket connection from /127.0.0.1:61134 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:20,939] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:20,946] INFO Closed socket connection for client /127.0.0.1:61134 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:21,961] INFO Accepted socket connection from /127.0.0.1:61135 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:21,962] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:21,971] INFO Closed socket connection for client /127.0.0.1:61135 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:22,834] INFO Accepted socket connection from /127.0.0.1:61136 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:22,835] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:22,839] INFO Closed socket connection for client /127.0.0.1:61136 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:23,702] INFO Accepted socket connection from /127.0.0.1:61137 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:23,703] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:23,710] INFO Closed socket connection for client /127.0.0.1:61137 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:24,925] INFO Accepted socket connection from /127.0.0.1:61138 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:24,926] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:24,935] INFO Closed socket connection for client /127.0.0.1:61138 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:25,949] INFO Accepted socket connection from /127.0.0.1:61139 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:25,952] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:25,956] INFO Closed socket connection for client /127.0.0.1:61139 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:26,870] INFO Accepted socket connection from /127.0.0.1:61142 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:26,871] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:26,880] INFO Closed socket connection for client /127.0.0.1:61142 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:27,898] INFO Accepted socket connection from /127.0.0.1:61143 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:27,900] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:27,911] INFO Closed socket connection for client /127.0.0.1:61143 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:28,929] INFO Accepted socket connection from /127.0.0.1:61144 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:28,931] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:28,935] INFO Closed socket connection for client /127.0.0.1:61144 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:29,850] INFO Accepted socket connection from /127.0.0.1:61145 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:29,852] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:29,860] INFO Closed socket connection for client /127.0.0.1:61145 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:30,779] INFO Accepted socket connection from /127.0.0.1:61147 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:30,780] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:30,785] INFO Closed socket connection for client /127.0.0.1:61147 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:31,903] INFO Accepted socket connection from /127.0.0.1:61150 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:31,906] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:31,916] INFO Closed socket connection for client /127.0.0.1:61150 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:32,834] INFO Accepted socket connection from /127.0.0.1:61151 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:32,841] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:32,845] INFO Closed socket connection for client /127.0.0.1:61151 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:33,766] INFO Accepted socket connection from /127.0.0.1:61153 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:33,767] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:33,770] INFO Closed socket connection for client /127.0.0.1:61153 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:34,684] INFO Accepted socket connection from /127.0.0.1:61154 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:34,685] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:34,691] INFO Closed socket connection for client /127.0.0.1:61154 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:35,859] INFO Accepted socket connection from /127.0.0.1:61155 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:35,860] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:35,867] INFO Closed socket connection for client /127.0.0.1:61155 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:37,094] INFO Accepted socket connection from /127.0.0.1:61156 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:37,096] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:37,102] INFO Closed socket connection for client /127.0.0.1:61156 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:38,070] INFO Accepted socket connection from /127.0.0.1:61159 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:38,071] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:38,075] INFO Closed socket connection for client /127.0.0.1:61159 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:39,042] INFO Accepted socket connection from /127.0.0.1:61160 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:39,044] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:39,054] INFO Closed socket connection for client /127.0.0.1:61160 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:40,181] INFO Accepted socket connection from /127.0.0.1:61162 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:40,188] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:40,195] INFO Closed socket connection for client /127.0.0.1:61162 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:41,212] INFO Accepted socket connection from /127.0.0.1:61175 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:41,214] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:41,218] INFO Closed socket connection for client /127.0.0.1:61175 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:42,287] INFO Accepted socket connection from /127.0.0.1:61182 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:42,288] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:42,292] INFO Closed socket connection for client /127.0.0.1:61182 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:43,261] INFO Accepted socket connection from /127.0.0.1:61183 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:43,266] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:43,268] INFO Closed socket connection for client /127.0.0.1:61183 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:44,183] INFO Accepted socket connection from /127.0.0.1:61186 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:44,184] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:44,190] INFO Closed socket connection for client /127.0.0.1:61186 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:45,156] INFO Accepted socket connection from /127.0.0.1:61187 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:45,157] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:45,165] INFO Closed socket connection for client /127.0.0.1:61187 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:46,029] INFO Accepted socket connection from /127.0.0.1:61188 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:46,031] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:46,038] INFO Closed socket connection for client /127.0.0.1:61188 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:47,103] INFO Accepted socket connection from /127.0.0.1:61189 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:47,106] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:47,111] INFO Closed socket connection for client /127.0.0.1:61189 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:48,076] INFO Accepted socket connection from /127.0.0.1:61190 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:48,076] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:48,083] INFO Closed socket connection for client /127.0.0.1:61190 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:49,098] INFO Accepted socket connection from /127.0.0.1:61191 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:49,099] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:49,102] INFO Closed socket connection for client /127.0.0.1:61191 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:50,216] INFO Accepted socket connection from /127.0.0.1:61192 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:50,217] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:50,221] INFO Closed socket connection for client /127.0.0.1:61192 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:51,083] INFO Accepted socket connection from /127.0.0.1:61193 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:51,085] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:51,093] INFO Closed socket connection for client /127.0.0.1:61193 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:52,212] INFO Accepted socket connection from /127.0.0.1:61196 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:52,213] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:52,216] INFO Closed socket connection for client /127.0.0.1:61196 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:53,183] INFO Accepted socket connection from /127.0.0.1:61197 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:53,184] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:53,192] INFO Closed socket connection for client /127.0.0.1:61197 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:54,207] INFO Accepted socket connection from /127.0.0.1:61198 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:54,209] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:54,217] INFO Closed socket connection for client /127.0.0.1:61198 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:55,230] INFO Accepted socket connection from /127.0.0.1:61199 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:55,231] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:55,234] INFO Closed socket connection for client /127.0.0.1:61199 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:56,198] INFO Accepted socket connection from /127.0.0.1:61200 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:56,199] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:56,206] INFO Closed socket connection for client /127.0.0.1:61200 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:57,321] INFO Accepted socket connection from /127.0.0.1:61201 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:57,322] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:57,327] INFO Closed socket connection for client /127.0.0.1:61201 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:58,348] INFO Accepted socket connection from /127.0.0.1:61202 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:58,350] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:58,356] INFO Closed socket connection for client /127.0.0.1:61202 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:59,379] INFO Accepted socket connection from /127.0.0.1:61204 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:23:59,381] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:23:59,386] INFO Closed socket connection for client /127.0.0.1:61204 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:00,511] INFO Accepted socket connection from /127.0.0.1:61205 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:00,513] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:00,524] INFO Closed socket connection for client /127.0.0.1:61205 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:01,593] INFO Accepted socket connection from /127.0.0.1:61206 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:01,594] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:01,601] INFO Closed socket connection for client /127.0.0.1:61206 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:02,417] INFO Accepted socket connection from /127.0.0.1:61208 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:02,418] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:02,423] INFO Closed socket connection for client /127.0.0.1:61208 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:03,337] INFO Accepted socket connection from /127.0.0.1:61215 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:03,338] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:03,350] INFO Closed socket connection for client /127.0.0.1:61215 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:04,413] INFO Accepted socket connection from /127.0.0.1:61217 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:04,414] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:04,418] INFO Closed socket connection for client /127.0.0.1:61217 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:05,585] INFO Accepted socket connection from /127.0.0.1:61227 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:05,586] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:05,589] INFO Closed socket connection for client /127.0.0.1:61227 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:06,556] INFO Accepted socket connection from /127.0.0.1:61236 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:06,558] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:06,565] INFO Closed socket connection for client /127.0.0.1:61236 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:07,634] INFO Accepted socket connection from /127.0.0.1:61237 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:07,636] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:07,647] INFO Closed socket connection for client /127.0.0.1:61237 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:08,662] INFO Accepted socket connection from /127.0.0.1:61238 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:08,663] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:08,670] INFO Closed socket connection for client /127.0.0.1:61238 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:09,737] INFO Accepted socket connection from /127.0.0.1:61239 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:09,739] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:09,744] INFO Closed socket connection for client /127.0.0.1:61239 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:10,759] INFO Accepted socket connection from /127.0.0.1:61240 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:10,761] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:10,769] INFO Closed socket connection for client /127.0.0.1:61240 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:11,891] INFO Accepted socket connection from /127.0.0.1:61241 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:11,896] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:11,903] INFO Closed socket connection for client /127.0.0.1:61241 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:13,025] INFO Accepted socket connection from /127.0.0.1:61242 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:13,030] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:13,034] INFO Closed socket connection for client /127.0.0.1:61242 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:14,099] INFO Accepted socket connection from /127.0.0.1:61243 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:14,100] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:14,108] INFO Closed socket connection for client /127.0.0.1:61243 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:15,075] INFO Accepted socket connection from /127.0.0.1:61245 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:15,076] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:15,081] INFO Closed socket connection for client /127.0.0.1:61245 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:16,043] INFO Accepted socket connection from /127.0.0.1:61246 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:16,045] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:16,054] INFO Closed socket connection for client /127.0.0.1:61246 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:16,918] INFO Accepted socket connection from /127.0.0.1:61247 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:16,920] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:16,930] INFO Closed socket connection for client /127.0.0.1:61247 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:18,097] INFO Accepted socket connection from /127.0.0.1:61249 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:18,098] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:18,104] INFO Closed socket connection for client /127.0.0.1:61249 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:19,219] INFO Accepted socket connection from /127.0.0.1:61251 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:19,220] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:19,223] INFO Closed socket connection for client /127.0.0.1:61251 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:20,287] INFO Accepted socket connection from /127.0.0.1:61253 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:20,287] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:20,291] INFO Closed socket connection for client /127.0.0.1:61253 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:21,108] INFO Accepted socket connection from /127.0.0.1:61256 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:21,110] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:21,117] INFO Closed socket connection for client /127.0.0.1:61256 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:22,242] INFO Accepted socket connection from /127.0.0.1:61257 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:22,243] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:22,253] INFO Closed socket connection for client /127.0.0.1:61257 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:23,470] INFO Accepted socket connection from /127.0.0.1:61258 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:23,472] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:23,482] INFO Closed socket connection for client /127.0.0.1:61258 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:24,299] INFO Accepted socket connection from /127.0.0.1:61262 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:24,300] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:24,305] INFO Closed socket connection for client /127.0.0.1:61262 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:25,329] INFO Accepted socket connection from /127.0.0.1:61266 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:25,330] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:25,334] INFO Closed socket connection for client /127.0.0.1:61266 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:26,559] INFO Accepted socket connection from /127.0.0.1:61268 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:26,562] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:26,571] INFO Closed socket connection for client /127.0.0.1:61268 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:27,585] INFO Accepted socket connection from /127.0.0.1:61269 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:27,586] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:27,596] INFO Closed socket connection for client /127.0.0.1:61269 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:28,758] INFO Accepted socket connection from /127.0.0.1:61271 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:28,758] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:28,763] INFO Closed socket connection for client /127.0.0.1:61271 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:29,726] INFO Accepted socket connection from /127.0.0.1:61272 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:29,727] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:29,732] INFO Closed socket connection for client /127.0.0.1:61272 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:30,845] INFO Accepted socket connection from /127.0.0.1:61273 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:30,846] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:30,854] INFO Closed socket connection for client /127.0.0.1:61273 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:31,770] INFO Accepted socket connection from /127.0.0.1:61274 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:31,772] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:31,780] INFO Closed socket connection for client /127.0.0.1:61274 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:32,843] INFO Accepted socket connection from /127.0.0.1:61276 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:32,843] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:32,848] INFO Closed socket connection for client /127.0.0.1:61276 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:33,914] INFO Accepted socket connection from /127.0.0.1:61278 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:33,916] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:33,927] INFO Closed socket connection for client /127.0.0.1:61278 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:34,838] INFO Accepted socket connection from /127.0.0.1:61279 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:34,840] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:34,850] INFO Closed socket connection for client /127.0.0.1:61279 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:35,914] INFO Accepted socket connection from /127.0.0.1:61280 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:35,915] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:35,922] INFO Closed socket connection for client /127.0.0.1:61280 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:36,943] INFO Accepted socket connection from /127.0.0.1:61281 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:36,944] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:36,952] INFO Closed socket connection for client /127.0.0.1:61281 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:38,123] INFO Accepted socket connection from /127.0.0.1:61282 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:38,124] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:38,129] INFO Closed socket connection for client /127.0.0.1:61282 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:39,194] INFO Accepted socket connection from /127.0.0.1:61283 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:39,197] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:39,204] INFO Closed socket connection for client /127.0.0.1:61283 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:40,423] INFO Accepted socket connection from /127.0.0.1:61284 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:40,425] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:40,433] INFO Closed socket connection for client /127.0.0.1:61284 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:41,650] INFO Accepted socket connection from /127.0.0.1:61285 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:41,652] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:41,659] INFO Closed socket connection for client /127.0.0.1:61285 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:42,727] INFO Accepted socket connection from /127.0.0.1:61286 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:42,729] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:42,739] INFO Closed socket connection for client /127.0.0.1:61286 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:43,958] INFO Accepted socket connection from /127.0.0.1:61287 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:43,960] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:43,966] INFO Closed socket connection for client /127.0.0.1:61287 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:44,929] INFO Accepted socket connection from /127.0.0.1:61288 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:44,930] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:44,938] INFO Closed socket connection for client /127.0.0.1:61288 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:46,059] INFO Accepted socket connection from /127.0.0.1:61289 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:46,060] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:46,068] INFO Closed socket connection for client /127.0.0.1:61289 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:46,937] INFO Accepted socket connection from /127.0.0.1:61290 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:46,938] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:46,947] INFO Closed socket connection for client /127.0.0.1:61290 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:48,161] INFO Accepted socket connection from /127.0.0.1:61291 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:48,161] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:48,169] INFO Closed socket connection for client /127.0.0.1:61291 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:49,185] INFO Accepted socket connection from /127.0.0.1:61292 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:49,204] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:49,211] INFO Closed socket connection for client /127.0.0.1:61292 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:50,071] INFO Accepted socket connection from /127.0.0.1:61293 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:50,072] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:50,080] INFO Closed socket connection for client /127.0.0.1:61293 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:51,043] INFO Accepted socket connection from /127.0.0.1:61294 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:51,044] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:51,049] INFO Closed socket connection for client /127.0.0.1:61294 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:52,267] INFO Accepted socket connection from /127.0.0.1:61295 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:52,268] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:52,277] INFO Closed socket connection for client /127.0.0.1:61295 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:53,142] INFO Accepted socket connection from /127.0.0.1:61297 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:53,144] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:53,151] INFO Closed socket connection for client /127.0.0.1:61297 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:54,316] INFO Accepted socket connection from /127.0.0.1:61298 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:54,317] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:54,324] INFO Closed socket connection for client /127.0.0.1:61298 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:55,238] INFO Accepted socket connection from /127.0.0.1:61299 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:55,239] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:55,249] INFO Closed socket connection for client /127.0.0.1:61299 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:56,262] INFO Accepted socket connection from /127.0.0.1:61301 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:56,263] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:56,271] INFO Closed socket connection for client /127.0.0.1:61301 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:57,388] INFO Accepted socket connection from /127.0.0.1:61302 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:57,389] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:57,398] INFO Closed socket connection for client /127.0.0.1:61302 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:58,259] INFO Accepted socket connection from /127.0.0.1:61303 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:58,261] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:58,270] INFO Closed socket connection for client /127.0.0.1:61303 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:59,232] INFO Accepted socket connection from /127.0.0.1:61305 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:24:59,233] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:24:59,241] INFO Closed socket connection for client /127.0.0.1:61305 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:00,463] INFO Accepted socket connection from /127.0.0.1:61306 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:00,465] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:00,471] INFO Closed socket connection for client /127.0.0.1:61306 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:01,687] INFO Accepted socket connection from /127.0.0.1:61307 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:01,688] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:01,697] INFO Closed socket connection for client /127.0.0.1:61307 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:02,862] INFO Accepted socket connection from /127.0.0.1:61308 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:02,863] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:02,871] INFO Closed socket connection for client /127.0.0.1:61308 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:03,935] INFO Accepted socket connection from /127.0.0.1:61309 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:03,936] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:03,945] INFO Closed socket connection for client /127.0.0.1:61309 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:04,810] INFO Accepted socket connection from /127.0.0.1:61310 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:04,810] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:04,818] INFO Closed socket connection for client /127.0.0.1:61310 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:05,680] INFO Accepted socket connection from /127.0.0.1:61311 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:05,681] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:05,689] INFO Closed socket connection for client /127.0.0.1:61311 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:06,704] INFO Accepted socket connection from /127.0.0.1:61312 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:06,706] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:06,714] INFO Closed socket connection for client /127.0.0.1:61312 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:07,829] INFO Accepted socket connection from /127.0.0.1:61313 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:07,832] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:07,839] INFO Closed socket connection for client /127.0.0.1:61313 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:08,753] INFO Accepted socket connection from /127.0.0.1:61314 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:08,755] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:08,762] INFO Closed socket connection for client /127.0.0.1:61314 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:09,778] INFO Accepted socket connection from /127.0.0.1:61315 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:09,779] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:09,787] INFO Closed socket connection for client /127.0.0.1:61315 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:11,003] INFO Accepted socket connection from /127.0.0.1:61317 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:11,004] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:11,012] INFO Closed socket connection for client /127.0.0.1:61317 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:12,076] INFO Accepted socket connection from /127.0.0.1:61318 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:12,078] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:12,084] INFO Closed socket connection for client /127.0.0.1:61318 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:13,047] INFO Accepted socket connection from /127.0.0.1:61319 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:13,048] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:13,054] INFO Closed socket connection for client /127.0.0.1:61319 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:14,171] INFO Accepted socket connection from /127.0.0.1:61320 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:14,172] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:14,180] INFO Closed socket connection for client /127.0.0.1:61320 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:15,393] INFO Accepted socket connection from /127.0.0.1:61321 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:15,394] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:15,400] INFO Closed socket connection for client /127.0.0.1:61321 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:16,415] INFO Accepted socket connection from /127.0.0.1:61322 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:16,416] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:16,427] INFO Closed socket connection for client /127.0.0.1:61322 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:17,594] INFO Accepted socket connection from /127.0.0.1:61323 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:17,596] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:17,604] INFO Closed socket connection for client /127.0.0.1:61323 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:18,570] INFO Accepted socket connection from /127.0.0.1:61324 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:18,571] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:18,581] INFO Closed socket connection for client /127.0.0.1:61324 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:19,700] INFO Accepted socket connection from /127.0.0.1:61325 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:19,701] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:19,710] INFO Closed socket connection for client /127.0.0.1:61325 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:20,925] INFO Accepted socket connection from /127.0.0.1:61326 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:20,927] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:20,931] INFO Closed socket connection for client /127.0.0.1:61326 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:21,794] INFO Accepted socket connection from /127.0.0.1:61328 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:21,795] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:21,803] INFO Closed socket connection for client /127.0.0.1:61328 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:22,923] INFO Accepted socket connection from /127.0.0.1:61329 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:22,925] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:22,933] INFO Closed socket connection for client /127.0.0.1:61329 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:23,901] INFO Accepted socket connection from /127.0.0.1:61330 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:23,902] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:23,913] INFO Closed socket connection for client /127.0.0.1:61330 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:24,778] INFO Accepted socket connection from /127.0.0.1:61331 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:24,779] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:24,782] INFO Closed socket connection for client /127.0.0.1:61331 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:25,845] INFO Accepted socket connection from /127.0.0.1:61332 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:25,846] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:25,851] INFO Closed socket connection for client /127.0.0.1:61332 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:26,919] INFO Accepted socket connection from /127.0.0.1:61333 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:26,921] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:26,931] INFO Closed socket connection for client /127.0.0.1:61333 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:27,843] INFO Accepted socket connection from /127.0.0.1:61335 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:27,845] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:27,850] INFO Closed socket connection for client /127.0.0.1:61335 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:28,965] INFO Accepted socket connection from /127.0.0.1:61337 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:28,965] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:28,969] INFO Closed socket connection for client /127.0.0.1:61337 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:29,882] INFO Accepted socket connection from /127.0.0.1:61338 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:29,893] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:29,893] INFO Closed socket connection for client /127.0.0.1:61338 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:31,061] INFO Accepted socket connection from /127.0.0.1:61340 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:31,062] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:31,065] INFO Closed socket connection for client /127.0.0.1:61340 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:32,231] INFO Accepted socket connection from /127.0.0.1:61341 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:32,232] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:32,242] INFO Closed socket connection for client /127.0.0.1:61341 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:33,356] INFO Accepted socket connection from /127.0.0.1:61342 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:33,357] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:33,361] INFO Closed socket connection for client /127.0.0.1:61342 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:34,376] INFO Accepted socket connection from /127.0.0.1:61343 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:34,377] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:34,384] INFO Closed socket connection for client /127.0.0.1:61343 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:35,351] INFO Accepted socket connection from /127.0.0.1:61344 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:35,352] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:35,364] INFO Closed socket connection for client /127.0.0.1:61344 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:36,481] INFO Accepted socket connection from /127.0.0.1:61345 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:36,482] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:36,492] INFO Closed socket connection for client /127.0.0.1:61345 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:37,557] INFO Accepted socket connection from /127.0.0.1:61346 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:37,558] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:37,566] INFO Closed socket connection for client /127.0.0.1:61346 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:38,736] INFO Accepted socket connection from /127.0.0.1:61347 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:38,738] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:38,748] INFO Closed socket connection for client /127.0.0.1:61347 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:39,616] INFO Accepted socket connection from /127.0.0.1:61348 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:39,617] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:39,620] INFO Closed socket connection for client /127.0.0.1:61348 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:40,733] INFO Accepted socket connection from /127.0.0.1:61349 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:40,734] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:40,744] INFO Closed socket connection for client /127.0.0.1:61349 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:41,660] INFO Accepted socket connection from /127.0.0.1:61350 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:41,661] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:41,668] INFO Closed socket connection for client /127.0.0.1:61350 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:42,532] INFO Accepted socket connection from /127.0.0.1:61352 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:42,533] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:42,541] INFO Closed socket connection for client /127.0.0.1:61352 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:43,758] INFO Accepted socket connection from /127.0.0.1:61353 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:43,759] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:43,769] INFO Closed socket connection for client /127.0.0.1:61353 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:44,787] INFO Accepted socket connection from /127.0.0.1:61354 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:44,789] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:44,794] INFO Closed socket connection for client /127.0.0.1:61354 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:45,909] INFO Accepted socket connection from /127.0.0.1:61355 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:45,911] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:45,918] INFO Closed socket connection for client /127.0.0.1:61355 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:46,734] INFO Accepted socket connection from /127.0.0.1:61357 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:46,736] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:46,744] INFO Closed socket connection for client /127.0.0.1:61357 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:47,862] INFO Accepted socket connection from /127.0.0.1:61358 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:47,863] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:47,869] INFO Closed socket connection for client /127.0.0.1:61358 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:48,783] INFO Accepted socket connection from /127.0.0.1:61360 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:48,784] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:48,792] INFO Closed socket connection for client /127.0.0.1:61360 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:49,905] INFO Accepted socket connection from /127.0.0.1:61361 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:49,907] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:49,914] INFO Closed socket connection for client /127.0.0.1:61361 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:50,933] INFO Accepted socket connection from /127.0.0.1:61362 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:50,934] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:50,942] INFO Closed socket connection for client /127.0.0.1:61362 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:52,110] INFO Accepted socket connection from /127.0.0.1:61363 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:52,112] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:52,125] INFO Closed socket connection for client /127.0.0.1:61363 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:53,195] INFO Accepted socket connection from /127.0.0.1:61364 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:53,198] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:53,208] INFO Closed socket connection for client /127.0.0.1:61364 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:54,430] INFO Accepted socket connection from /127.0.0.1:61365 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:54,451] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:54,460] INFO Closed socket connection for client /127.0.0.1:61365 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:55,475] INFO Accepted socket connection from /127.0.0.1:61366 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:55,476] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:55,479] INFO Closed socket connection for client /127.0.0.1:61366 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:56,442] INFO Accepted socket connection from /127.0.0.1:61367 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:56,442] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:56,446] INFO Closed socket connection for client /127.0.0.1:61367 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:57,308] INFO Accepted socket connection from /127.0.0.1:61368 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:57,309] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:57,316] INFO Closed socket connection for client /127.0.0.1:61368 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:58,332] INFO Accepted socket connection from /127.0.0.1:61369 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:58,333] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:58,336] INFO Closed socket connection for client /127.0.0.1:61369 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:59,400] INFO Accepted socket connection from /127.0.0.1:61370 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:25:59,401] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:25:59,407] INFO Closed socket connection for client /127.0.0.1:61370 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:00,372] INFO Accepted socket connection from /127.0.0.1:61371 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:00,376] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:00,383] INFO Closed socket connection for client /127.0.0.1:61371 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:01,297] INFO Accepted socket connection from /127.0.0.1:61372 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:01,297] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:01,305] INFO Closed socket connection for client /127.0.0.1:61372 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:02,316] INFO Accepted socket connection from /127.0.0.1:61373 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:02,317] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:02,324] INFO Closed socket connection for client /127.0.0.1:61373 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:03,239] INFO Accepted socket connection from /127.0.0.1:61374 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:03,240] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:03,248] INFO Closed socket connection for client /127.0.0.1:61374 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:04,110] INFO Accepted socket connection from /127.0.0.1:61376 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:04,111] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:04,117] INFO Closed socket connection for client /127.0.0.1:61376 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:04,981] INFO Accepted socket connection from /127.0.0.1:61377 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:04,981] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:04,989] INFO Closed socket connection for client /127.0.0.1:61377 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:05,850] INFO Accepted socket connection from /127.0.0.1:61378 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:05,851] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:05,860] INFO Closed socket connection for client /127.0.0.1:61378 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:06,823] INFO Accepted socket connection from /127.0.0.1:61379 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:06,825] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:06,832] INFO Closed socket connection for client /127.0.0.1:61379 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:07,947] INFO Accepted socket connection from /127.0.0.1:61380 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:07,948] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:07,956] INFO Closed socket connection for client /127.0.0.1:61380 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:09,122] INFO Accepted socket connection from /127.0.0.1:61381 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:09,123] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:09,130] INFO Closed socket connection for client /127.0.0.1:61381 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:09,993] INFO Accepted socket connection from /127.0.0.1:61382 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:09,994] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:10,000] INFO Closed socket connection for client /127.0.0.1:61382 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:11,167] INFO Accepted socket connection from /127.0.0.1:61383 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:11,168] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:11,175] INFO Closed socket connection for client /127.0.0.1:61383 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:12,037] INFO Accepted socket connection from /127.0.0.1:61384 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:12,038] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:12,045] INFO Closed socket connection for client /127.0.0.1:61384 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:13,010] INFO Accepted socket connection from /127.0.0.1:61385 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:13,011] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:13,017] INFO Closed socket connection for client /127.0.0.1:61385 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:13,984] INFO Accepted socket connection from /127.0.0.1:61386 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:13,985] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:13,992] INFO Closed socket connection for client /127.0.0.1:61386 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:15,060] INFO Accepted socket connection from /127.0.0.1:61387 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:15,061] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:15,064] INFO Closed socket connection for client /127.0.0.1:61387 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:16,178] INFO Accepted socket connection from /127.0.0.1:61388 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:16,179] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:16,185] INFO Closed socket connection for client /127.0.0.1:61388 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:17,200] INFO Accepted socket connection from /127.0.0.1:61389 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:17,201] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:17,208] INFO Closed socket connection for client /127.0.0.1:61389 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:18,173] INFO Accepted socket connection from /127.0.0.1:61390 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:18,174] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:18,178] INFO Closed socket connection for client /127.0.0.1:61390 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:19,189] INFO Accepted socket connection from /127.0.0.1:61391 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:19,190] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:19,197] INFO Closed socket connection for client /127.0.0.1:61391 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:20,160] INFO Accepted socket connection from /127.0.0.1:61393 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:20,161] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:20,167] INFO Closed socket connection for client /127.0.0.1:61393 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:21,180] INFO Accepted socket connection from /127.0.0.1:61396 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:21,182] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:21,185] INFO Closed socket connection for client /127.0.0.1:61396 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:22,101] INFO Accepted socket connection from /127.0.0.1:61399 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:22,102] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:22,109] INFO Closed socket connection for client /127.0.0.1:61399 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:23,020] INFO Accepted socket connection from /127.0.0.1:61400 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:23,021] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:23,030] INFO Closed socket connection for client /127.0.0.1:61400 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:23,894] INFO Accepted socket connection from /127.0.0.1:61401 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:23,896] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:23,904] INFO Closed socket connection for client /127.0.0.1:61401 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:25,123] INFO Accepted socket connection from /127.0.0.1:61403 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:25,125] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:25,132] INFO Closed socket connection for client /127.0.0.1:61403 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:26,302] INFO Accepted socket connection from /127.0.0.1:61406 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:26,303] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:26,310] INFO Closed socket connection for client /127.0.0.1:61406 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:27,477] INFO Accepted socket connection from /127.0.0.1:61407 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:27,478] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:27,481] INFO Closed socket connection for client /127.0.0.1:61407 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:28,696] INFO Accepted socket connection from /127.0.0.1:61408 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:28,697] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:28,704] INFO Closed socket connection for client /127.0.0.1:61408 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:29,819] INFO Accepted socket connection from /127.0.0.1:61409 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:29,820] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:29,828] INFO Closed socket connection for client /127.0.0.1:61409 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:30,692] INFO Accepted socket connection from /127.0.0.1:61410 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:30,692] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:30,700] INFO Closed socket connection for client /127.0.0.1:61410 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:31,664] INFO Accepted socket connection from /127.0.0.1:61411 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:31,665] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:31,675] INFO Closed socket connection for client /127.0.0.1:61411 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:32,590] INFO Accepted socket connection from /127.0.0.1:61412 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:32,590] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:32,594] INFO Closed socket connection for client /127.0.0.1:61412 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:33,756] INFO Accepted socket connection from /127.0.0.1:61413 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:33,756] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:33,760] INFO Closed socket connection for client /127.0.0.1:61413 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:34,625] INFO Accepted socket connection from /127.0.0.1:61414 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:34,626] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:34,630] INFO Closed socket connection for client /127.0.0.1:61414 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:35,646] INFO Accepted socket connection from /127.0.0.1:61415 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:35,647] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:35,656] INFO Closed socket connection for client /127.0.0.1:61415 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:36,873] INFO Accepted socket connection from /127.0.0.1:61417 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:36,874] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:36,886] INFO Closed socket connection for client /127.0.0.1:61417 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:37,911] INFO Accepted socket connection from /127.0.0.1:61418 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:37,912] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:37,917] INFO Closed socket connection for client /127.0.0.1:61418 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:39,095] INFO Accepted socket connection from /127.0.0.1:61419 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:39,095] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:39,099] INFO Closed socket connection for client /127.0.0.1:61419 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:40,221] INFO Accepted socket connection from /127.0.0.1:61420 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:40,222] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:40,229] INFO Closed socket connection for client /127.0.0.1:61420 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:41,299] INFO Accepted socket connection from /127.0.0.1:61421 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:41,300] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:41,308] INFO Closed socket connection for client /127.0.0.1:61421 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:42,423] INFO Accepted socket connection from /127.0.0.1:61422 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:42,424] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:42,432] INFO Closed socket connection for client /127.0.0.1:61422 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:43,402] INFO Accepted socket connection from /127.0.0.1:61423 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:43,404] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:43,412] INFO Closed socket connection for client /127.0.0.1:61423 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:44,381] INFO Accepted socket connection from /127.0.0.1:61424 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:44,381] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:44,391] INFO Closed socket connection for client /127.0.0.1:61424 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:45,507] INFO Accepted socket connection from /127.0.0.1:61426 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:45,508] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:45,514] INFO Closed socket connection for client /127.0.0.1:61426 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:46,736] INFO Accepted socket connection from /127.0.0.1:61427 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:46,736] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:46,743] INFO Closed socket connection for client /127.0.0.1:61427 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:47,710] INFO Accepted socket connection from /127.0.0.1:61428 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:47,710] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:47,720] INFO Closed socket connection for client /127.0.0.1:61428 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:48,785] INFO Accepted socket connection from /127.0.0.1:61429 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:48,787] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:48,795] INFO Closed socket connection for client /127.0.0.1:61429 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:50,010] INFO Accepted socket connection from /127.0.0.1:61430 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:50,011] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:50,022] INFO Closed socket connection for client /127.0.0.1:61430 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:51,038] INFO Accepted socket connection from /127.0.0.1:61432 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:51,039] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:51,047] INFO Closed socket connection for client /127.0.0.1:61432 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:51,963] INFO Accepted socket connection from /127.0.0.1:61433 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:51,964] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:51,969] INFO Closed socket connection for client /127.0.0.1:61433 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:52,932] INFO Accepted socket connection from /127.0.0.1:61434 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:52,933] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:52,942] INFO Closed socket connection for client /127.0.0.1:61434 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:54,161] INFO Accepted socket connection from /127.0.0.1:61435 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:54,162] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:54,171] INFO Closed socket connection for client /127.0.0.1:61435 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:55,086] INFO Accepted socket connection from /127.0.0.1:61436 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:55,087] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:55,094] INFO Closed socket connection for client /127.0.0.1:61436 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:56,265] INFO Accepted socket connection from /127.0.0.1:61437 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:56,266] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:56,276] INFO Closed socket connection for client /127.0.0.1:61437 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:57,218] INFO Accepted socket connection from /127.0.0.1:61438 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:57,219] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:57,225] INFO Closed socket connection for client /127.0.0.1:61438 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:58,291] INFO Accepted socket connection from /127.0.0.1:61439 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:58,292] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:58,299] INFO Closed socket connection for client /127.0.0.1:61439 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:59,266] INFO Accepted socket connection from /127.0.0.1:61440 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:26:59,268] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:26:59,278] INFO Closed socket connection for client /127.0.0.1:61440 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:00,296] INFO Accepted socket connection from /127.0.0.1:61441 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:00,297] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:00,302] INFO Closed socket connection for client /127.0.0.1:61441 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:01,482] INFO Accepted socket connection from /127.0.0.1:61442 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:01,484] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:01,498] INFO Closed socket connection for client /127.0.0.1:61442 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:02,675] INFO Accepted socket connection from /127.0.0.1:61443 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:02,675] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:02,680] INFO Closed socket connection for client /127.0.0.1:61443 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:03,749] INFO Accepted socket connection from /127.0.0.1:61445 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:03,752] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:03,760] INFO Closed socket connection for client /127.0.0.1:61445 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:04,775] INFO Accepted socket connection from /127.0.0.1:61446 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:04,777] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:04,785] INFO Closed socket connection for client /127.0.0.1:61446 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:05,853] INFO Accepted socket connection from /127.0.0.1:61447 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:05,854] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:05,866] INFO Closed socket connection for client /127.0.0.1:61447 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:06,728] INFO Accepted socket connection from /127.0.0.1:61448 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:06,729] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:06,737] INFO Closed socket connection for client /127.0.0.1:61448 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:07,851] INFO Accepted socket connection from /127.0.0.1:61449 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:07,852] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:07,859] INFO Closed socket connection for client /127.0.0.1:61449 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:08,824] INFO Accepted socket connection from /127.0.0.1:61450 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:08,825] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:08,832] INFO Closed socket connection for client /127.0.0.1:61450 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:09,745] INFO Accepted socket connection from /127.0.0.1:61451 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:09,745] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:09,752] INFO Closed socket connection for client /127.0.0.1:61451 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:10,714] INFO Accepted socket connection from /127.0.0.1:61452 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:10,716] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:10,724] INFO Closed socket connection for client /127.0.0.1:61452 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:11,640] INFO Accepted socket connection from /127.0.0.1:61453 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:11,641] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:11,651] INFO Closed socket connection for client /127.0.0.1:61453 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:12,514] INFO Accepted socket connection from /127.0.0.1:61455 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:12,516] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:12,523] INFO Closed socket connection for client /127.0.0.1:61455 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:13,486] INFO Accepted socket connection from /127.0.0.1:61456 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:13,487] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:13,491] INFO Closed socket connection for client /127.0.0.1:61456 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:14,705] INFO Accepted socket connection from /127.0.0.1:61457 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:14,706] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:14,715] INFO Closed socket connection for client /127.0.0.1:61457 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:15,734] INFO Accepted socket connection from /127.0.0.1:61458 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:15,735] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:15,744] INFO Closed socket connection for client /127.0.0.1:61458 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:16,655] INFO Accepted socket connection from /127.0.0.1:61459 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:16,656] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:16,664] INFO Closed socket connection for client /127.0.0.1:61459 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:17,731] INFO Accepted socket connection from /127.0.0.1:61460 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:17,731] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:17,734] INFO Closed socket connection for client /127.0.0.1:61460 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:18,961] INFO Accepted socket connection from /127.0.0.1:61461 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:18,961] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:18,968] INFO Closed socket connection for client /127.0.0.1:61461 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:19,834] INFO Accepted socket connection from /127.0.0.1:61462 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:19,836] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:19,844] INFO Closed socket connection for client /127.0.0.1:61462 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:21,018] INFO Accepted socket connection from /127.0.0.1:61465 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:21,018] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:21,022] INFO Closed socket connection for client /127.0.0.1:61465 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:22,091] INFO Accepted socket connection from /127.0.0.1:61466 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:22,091] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:22,101] INFO Closed socket connection for client /127.0.0.1:61466 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:23,017] INFO Accepted socket connection from /127.0.0.1:61467 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:23,018] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:23,027] INFO Closed socket connection for client /127.0.0.1:61467 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:23,891] INFO Accepted socket connection from /127.0.0.1:61468 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:23,892] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:23,896] INFO Closed socket connection for client /127.0.0.1:61468 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:24,813] INFO Accepted socket connection from /127.0.0.1:61469 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:24,814] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:24,825] INFO Closed socket connection for client /127.0.0.1:61469 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:25,789] INFO Accepted socket connection from /127.0.0.1:61470 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:25,790] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:25,801] INFO Closed socket connection for client /127.0.0.1:61470 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:26,966] INFO Accepted socket connection from /127.0.0.1:61472 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:26,967] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:26,976] INFO Closed socket connection for client /127.0.0.1:61472 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:27,941] INFO Accepted socket connection from /127.0.0.1:61473 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:27,942] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:27,951] INFO Closed socket connection for client /127.0.0.1:61473 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:29,068] INFO Accepted socket connection from /127.0.0.1:61474 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:29,069] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:29,078] INFO Closed socket connection for client /127.0.0.1:61474 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:30,249] INFO Accepted socket connection from /127.0.0.1:61475 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:30,250] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:30,257] INFO Closed socket connection for client /127.0.0.1:61475 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:31,120] INFO Accepted socket connection from /127.0.0.1:61476 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:31,121] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:31,130] INFO Closed socket connection for client /127.0.0.1:61476 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:32,249] INFO Accepted socket connection from /127.0.0.1:61477 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:32,251] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:32,258] INFO Closed socket connection for client /127.0.0.1:61477 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:33,271] INFO Accepted socket connection from /127.0.0.1:61479 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:33,272] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:33,278] INFO Closed socket connection for client /127.0.0.1:61479 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:34,194] INFO Accepted socket connection from /127.0.0.1:61481 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:34,195] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:34,206] INFO Closed socket connection for client /127.0.0.1:61481 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:35,124] INFO Accepted socket connection from /127.0.0.1:61482 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:35,125] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:35,135] INFO Closed socket connection for client /127.0.0.1:61482 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:36,299] INFO Accepted socket connection from /127.0.0.1:61484 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:36,299] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:36,303] INFO Closed socket connection for client /127.0.0.1:61484 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:37,420] INFO Accepted socket connection from /127.0.0.1:61485 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:37,421] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:37,430] INFO Closed socket connection for client /127.0.0.1:61485 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:38,394] INFO Accepted socket connection from /127.0.0.1:61486 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:38,396] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:38,403] INFO Closed socket connection for client /127.0.0.1:61486 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:39,623] INFO Accepted socket connection from /127.0.0.1:61487 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:39,624] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:39,634] INFO Closed socket connection for client /127.0.0.1:61487 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:40,751] INFO Accepted socket connection from /127.0.0.1:61488 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:40,752] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:40,761] INFO Closed socket connection for client /127.0.0.1:61488 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:41,626] INFO Accepted socket connection from /127.0.0.1:61490 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:41,627] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:41,634] INFO Closed socket connection for client /127.0.0.1:61490 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:42,649] INFO Accepted socket connection from /127.0.0.1:61491 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:42,650] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:42,658] INFO Closed socket connection for client /127.0.0.1:61491 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:43,624] INFO Accepted socket connection from /127.0.0.1:61492 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:43,625] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:43,633] INFO Closed socket connection for client /127.0.0.1:61492 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:44,494] INFO Accepted socket connection from /127.0.0.1:61493 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:44,495] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:44,500] INFO Closed socket connection for client /127.0.0.1:61493 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:45,513] INFO Accepted socket connection from /127.0.0.1:61494 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:45,515] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:45,519] INFO Closed socket connection for client /127.0.0.1:61494 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:46,731] INFO Accepted socket connection from /127.0.0.1:61496 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:46,732] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:46,742] INFO Closed socket connection for client /127.0.0.1:61496 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:47,617] INFO Accepted socket connection from /127.0.0.1:61497 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:47,620] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:47,634] INFO Closed socket connection for client /127.0.0.1:61497 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:48,853] INFO Accepted socket connection from /127.0.0.1:61498 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:48,854] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:48,863] INFO Closed socket connection for client /127.0.0.1:61498 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:49,727] INFO Accepted socket connection from /127.0.0.1:61500 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:49,728] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:49,735] INFO Closed socket connection for client /127.0.0.1:61500 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:50,803] INFO Accepted socket connection from /127.0.0.1:61501 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:50,804] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:50,811] INFO Closed socket connection for client /127.0.0.1:61501 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:51,777] INFO Accepted socket connection from /127.0.0.1:61502 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:51,778] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:51,787] INFO Closed socket connection for client /127.0.0.1:61502 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:52,954] INFO Accepted socket connection from /127.0.0.1:61503 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:52,955] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:52,966] INFO Closed socket connection for client /127.0.0.1:61503 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:54,181] INFO Accepted socket connection from /127.0.0.1:61504 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:54,182] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:54,189] INFO Closed socket connection for client /127.0.0.1:61504 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:55,200] INFO Accepted socket connection from /127.0.0.1:61506 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:55,202] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:55,210] INFO Closed socket connection for client /127.0.0.1:61506 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:56,177] INFO Accepted socket connection from /127.0.0.1:61507 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:56,177] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:56,184] INFO Closed socket connection for client /127.0.0.1:61507 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:57,100] INFO Accepted socket connection from /127.0.0.1:61508 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:57,101] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:57,110] INFO Closed socket connection for client /127.0.0.1:61508 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:58,182] INFO Accepted socket connection from /127.0.0.1:61509 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:58,183] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:58,191] INFO Closed socket connection for client /127.0.0.1:61509 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:59,357] INFO Accepted socket connection from /127.0.0.1:61510 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:27:59,357] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:27:59,365] INFO Closed socket connection for client /127.0.0.1:61510 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:00,228] INFO Accepted socket connection from /127.0.0.1:61511 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:00,229] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:00,233] INFO Closed socket connection for client /127.0.0.1:61511 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:01,148] INFO Accepted socket connection from /127.0.0.1:61513 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:01,149] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:01,164] INFO Closed socket connection for client /127.0.0.1:61513 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:02,026] INFO Accepted socket connection from /127.0.0.1:61516 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:02,027] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:02,033] INFO Closed socket connection for client /127.0.0.1:61516 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:03,249] INFO Accepted socket connection from /127.0.0.1:61517 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:03,250] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:03,259] INFO Closed socket connection for client /127.0.0.1:61517 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:04,476] INFO Accepted socket connection from /127.0.0.1:61519 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:04,476] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:04,482] INFO Closed socket connection for client /127.0.0.1:61519 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:05,646] INFO Accepted socket connection from /127.0.0.1:61521 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:05,648] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:05,656] INFO Closed socket connection for client /127.0.0.1:61521 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:06,520] INFO Accepted socket connection from /127.0.0.1:61523 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:06,522] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:06,532] INFO Closed socket connection for client /127.0.0.1:61523 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:07,447] INFO Accepted socket connection from /127.0.0.1:61525 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:07,447] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:07,451] INFO Closed socket connection for client /127.0.0.1:61525 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:08,365] INFO Accepted socket connection from /127.0.0.1:61526 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:08,366] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:08,372] INFO Closed socket connection for client /127.0.0.1:61526 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:09,189] INFO Accepted socket connection from /127.0.0.1:61527 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:09,190] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:09,199] INFO Closed socket connection for client /127.0.0.1:61527 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:10,417] INFO Accepted socket connection from /127.0.0.1:61528 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:10,417] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:10,426] INFO Closed socket connection for client /127.0.0.1:61528 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:11,541] INFO Accepted socket connection from /127.0.0.1:61529 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:11,541] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:11,544] INFO Closed socket connection for client /127.0.0.1:61529 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:12,713] INFO Accepted socket connection from /127.0.0.1:61530 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:12,714] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:12,721] INFO Closed socket connection for client /127.0.0.1:61530 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:13,885] INFO Accepted socket connection from /127.0.0.1:61533 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:13,886] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:13,899] INFO Closed socket connection for client /127.0.0.1:61533 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:14,964] INFO Accepted socket connection from /127.0.0.1:61534 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:14,964] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:14,968] INFO Closed socket connection for client /127.0.0.1:61534 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:15,983] INFO Accepted socket connection from /127.0.0.1:61536 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:15,984] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:15,991] INFO Closed socket connection for client /127.0.0.1:61536 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:16,905] INFO Accepted socket connection from /127.0.0.1:61538 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:16,906] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:16,915] INFO Closed socket connection for client /127.0.0.1:61538 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:17,930] INFO Accepted socket connection from /127.0.0.1:61539 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:17,931] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:17,940] INFO Closed socket connection for client /127.0.0.1:61539 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:18,953] INFO Accepted socket connection from /127.0.0.1:61540 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:18,954] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:18,963] INFO Closed socket connection for client /127.0.0.1:61540 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:20,180] INFO Accepted socket connection from /127.0.0.1:61541 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:20,181] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:20,189] INFO Closed socket connection for client /127.0.0.1:61541 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:21,152] INFO Accepted socket connection from /127.0.0.1:61542 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:21,153] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:21,164] INFO Closed socket connection for client /127.0.0.1:61542 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:22,282] INFO Accepted socket connection from /127.0.0.1:61543 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:22,283] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:22,292] INFO Closed socket connection for client /127.0.0.1:61543 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:23,507] INFO Accepted socket connection from /127.0.0.1:61544 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:28:23,508] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:23,516] INFO Closed socket connection for client /127.0.0.1:61544 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:31,574] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:28:31,578] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 02:28:31,608] WARN No entry found for connection 1 (kafka.utils.CoreUtils$)
java.lang.IllegalStateException: No entry found for connection 1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:330)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:134)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:885)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.server.KafkaServer.doControlledShutdown$1(KafkaServer.scala:496)
	at kafka.server.KafkaServer.controlledShutdown(KafkaServer.scala:545)
	at kafka.server.KafkaServer.$anonfun$shutdown$2(KafkaServer.scala:567)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:567)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:48)
	at kafka.Kafka$$anon$1.run(Kafka.scala:72)
[2019-01-10 02:28:31,632] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:28:31,638] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:28:31,638] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:28:31,641] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:28:31,681] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:28:31,684] INFO [Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:28:31,693] INFO [Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:28:31,706] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 02:28:31,710] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:31,801] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:31,801] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:31,815] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:28:31,819] INFO [ProducerId Manager 3]: Shutdown complete: last producerId assigned 9000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:28:31,828] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 02:28:31,829] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:28:31,834] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:28:31,834] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:28:31,838] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:28:31,842] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:28:31,844] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:31,857] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:31,857] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:31,858] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,002] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,002] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,004] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:28:32,015] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 02:28:32,017] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:28:32,020] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:28:32,020] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:28:32,034] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:28:32,043] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:28:32,046] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:28:32,048] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:28:32,052] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,208] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,208] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,215] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,416] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,416] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,423] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,558] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,558] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:32,603] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 02:28:32,608] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:28:32,631] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:28:32,649] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:28:32,651] INFO Processed session termination for sessionid: 0x1002fbb7c7b0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:28:32,674] INFO Session: 0x1002fbb7c7b0003 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:28:32,674] WARN Unable to read additional data from client sessionid 0x1002fbb7c7b0003, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:32,681] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:28:32,682] INFO EventThread shut down for session: 0x1002fbb7c7b0003 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:28:32,686] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:32,683] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60624 which had sessionid 0x1002fbb7c7b0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:33,313] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:33,313] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:33,314] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:34,289] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:34,289] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:34,299] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:35,225] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:35,225] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:35,232] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:28:35,335] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:28:35,343] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:28:37,491] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:28:37,497] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 02:28:37,602] WARN No entry found for connection 1 (kafka.utils.CoreUtils$)
java.lang.IllegalStateException: No entry found for connection 1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:330)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:134)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:885)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.server.KafkaServer.doControlledShutdown$1(KafkaServer.scala:496)
	at kafka.server.KafkaServer.controlledShutdown(KafkaServer.scala:545)
	at kafka.server.KafkaServer.$anonfun$shutdown$2(KafkaServer.scala:567)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:567)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:48)
	at kafka.Kafka$$anon$1.run(Kafka.scala:72)
[2019-01-10 02:28:37,616] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:28:37,618] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:28:37,618] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:28:37,621] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:28:37,652] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:28:37,655] INFO [Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:28:37,662] INFO [Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:28:37,671] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 02:28:37,673] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:37,679] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:37,679] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:37,684] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:28:37,686] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 8000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:28:37,687] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 02:28:37,688] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:28:37,693] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:28:37,694] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:28:37,697] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:28:37,699] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:28:37,700] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:37,829] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:37,829] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:37,829] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,029] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,029] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,037] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:28:38,042] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 02:28:38,044] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:28:38,052] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:28:38,052] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:28:38,058] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:28:38,074] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:28:38,082] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:28:38,084] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:28:38,086] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,226] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,226] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,226] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,283] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,283] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,283] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,440] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,440] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:38,461] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 02:28:38,466] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:28:38,490] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:28:38,519] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:28:38,522] INFO Processed session termination for sessionid: 0x1002fbb7c7b0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:28:38,553] INFO Session: 0x1002fbb7c7b0002 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:28:38,554] INFO Closed socket connection for client /127.0.0.1:60601 which had sessionid 0x1002fbb7c7b0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:38,556] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:28:38,564] INFO EventThread shut down for session: 0x1002fbb7c7b0002 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:28:38,567] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:38,925] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:38,926] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:38,925] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:39,053] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:39,053] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:39,054] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:40,054] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:40,054] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:40,057] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:28:40,169] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:28:40,176] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:28:41,053] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:28:41,061] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 02:28:41,078] WARN No entry found for connection 1 (kafka.utils.CoreUtils$)
java.lang.IllegalStateException: No entry found for connection 1
	at org.apache.kafka.clients.ClusterConnectionStates.nodeState(ClusterConnectionStates.java:330)
	at org.apache.kafka.clients.ClusterConnectionStates.disconnected(ClusterConnectionStates.java:134)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:885)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.server.KafkaServer.doControlledShutdown$1(KafkaServer.scala:496)
	at kafka.server.KafkaServer.controlledShutdown(KafkaServer.scala:545)
	at kafka.server.KafkaServer.$anonfun$shutdown$2(KafkaServer.scala:567)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:86)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:567)
	at kafka.server.KafkaServerStartable.shutdown(KafkaServerStartable.scala:48)
	at kafka.Kafka$$anon$1.run(Kafka.scala:72)
[2019-01-10 02:28:41,083] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:28:41,087] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:28:41,087] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:28:41,089] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:28:41,106] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:28:41,108] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:28:41,117] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:28:41,126] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 02:28:41,130] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,238] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,238] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,250] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:28:41,253] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 7000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:28:41,261] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 02:28:41,262] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:28:41,268] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:28:41,268] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:28:41,281] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:28:41,282] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:28:41,283] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,290] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,290] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,291] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,427] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,427] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,436] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:28:41,439] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 02:28:41,440] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:28:41,449] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:28:41,450] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:28:41,455] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:28:41,465] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:28:41,466] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:28:41,467] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:28:41,471] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,626] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,626] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,629] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,789] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,789] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,794] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,838] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,838] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:28:41,847] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 02:28:41,848] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:28:41,872] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:28:41,885] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:28:41,887] INFO Processed session termination for sessionid: 0x1002fbb7c7b0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:28:41,942] INFO Session: 0x1002fbb7c7b0001 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:28:41,944] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:60583 which had sessionid 0x1002fbb7c7b0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:28:41,949] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:28:41,951] INFO EventThread shut down for session: 0x1002fbb7c7b0001 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:28:41,956] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:42,623] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:42,623] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:42,631] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:43,623] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:43,623] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:43,628] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:43,653] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:43,653] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:28:43,659] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:28:43,723] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:28:43,731] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:29:16,535] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:29:16,540] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:29:16,541] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:29:16,543] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:29:16,544] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-10 02:29:16,572] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:29:16,576] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-10 02:29:16,907] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,908] INFO Server environment:host.name=192.168.1.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,915] INFO Server environment:java.version=10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,918] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,920] INFO Server environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,929] INFO Server environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,937] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,962] INFO Server environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,963] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,965] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,966] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,967] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,969] INFO Server environment:user.name=AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,971] INFO Server environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,980] INFO Server environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,998] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:16,999] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:17,003] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:17,052] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-10 02:29:17,058] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:29:24,748] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:29:25,673] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:29:25,676] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:29:25,726] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:29:25,926] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,929] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,930] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,930] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,930] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,931] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,936] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,937] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,938] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,959] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,960] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,961] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,962] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,963] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,964] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:25,969] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:26,067] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:29:26,077] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:29:26,085] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:29:26,085] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:61568 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:29:26,104] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:61568 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:26,112] INFO Creating new log file: log.16e (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-10 02:29:26,195] INFO Established session 0x1002fdd6a0b0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:61568 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:26,199] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002fdd6a0b0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:29:26,214] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:29:26,344] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0x1 zxid:0x16f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,417] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0x2 zxid:0x170 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,478] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0x3 zxid:0x171 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,522] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0x4 zxid:0x172 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,555] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0x5 zxid:0x173 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,621] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0x6 zxid:0x174 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,676] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0x7 zxid:0x175 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,712] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0x8 zxid:0x176 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,744] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0x9 zxid:0x177 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,787] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0xa zxid:0x178 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,820] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0xb zxid:0x179 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,842] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0xc zxid:0x17a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:26,864] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:create cxid:0xd zxid:0x17b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:27,436] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 02:29:27,642] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:29:27,706] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:29:27,811] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:29:27,812] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:29:27,812] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:29:27,990] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:29:28,041] INFO Logs loading complete in 47 ms. (kafka.log.LogManager)
[2019-01-10 02:29:28,123] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:29:28,144] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:29:29,501] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2019-01-10 02:29:29,605] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:29:29,681] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:29,682] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:29,681] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:29,753] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:29:29,909] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:29:29,967] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:29:29,979] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:29:30,153] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:30,153] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:30,153] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:30,308] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:30,316] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:30,372] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 26 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:29:30,422] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:29:30,504] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:29:30,515] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:29:30,519] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:29:30,518] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:29:30,697] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:29:30,773] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:29:30,795] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:29:30,801] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:29:30,815] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 02:29:31,016] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:31,111] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-0, old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:31,268] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:multi cxid:0xdc zxid:0x17f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:31,336] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:31,368] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 175 ms (kafka.log.Log)
[2019-01-10 02:29:31,378] INFO Created log for partition old-skul-2 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:31,380] INFO [Partition old-skul-2 broker=1] No checkpointed highwatermark is found for partition old-skul-2 (kafka.cluster.Partition)
[2019-01-10 02:29:31,391] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,398] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,399] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,404] INFO [Partition old-skul-2 broker=1] old-skul-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:29:31,494] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0000 type:multi cxid:0xe0 zxid:0x181 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:31,557] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:31,564] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-10 02:29:31,567] INFO Created log for partition old-skul-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:31,568] INFO [Partition old-skul-0 broker=1] No checkpointed highwatermark is found for partition old-skul-0 (kafka.cluster.Partition)
[2019-01-10 02:29:31,570] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,579] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,581] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,585] INFO [Partition old-skul-0 broker=1] old-skul-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:29:31,665] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:31,673] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-10 02:29:31,679] INFO Created log for partition old-skul-1 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:31,681] INFO [Partition old-skul-1 broker=1] No checkpointed highwatermark is found for partition old-skul-1 (kafka.cluster.Partition)
[2019-01-10 02:29:31,682] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,684] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,685] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,686] INFO [Partition old-skul-1 broker=1] old-skul-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:29:31,774] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:31,780] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-10 02:29:31,797] INFO Created log for partition metalingus-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:31,800] INFO [Partition metalingus-0 broker=1] No checkpointed highwatermark is found for partition metalingus-0 (kafka.cluster.Partition)
[2019-01-10 02:29:31,810] INFO Replica loaded for partition metalingus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:31,813] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:31,894] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:31,902] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:31,911] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:31,914] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:29:31,922] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:31,929] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:29:31,937] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:31,944] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:29:31,948] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:31,950] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:29:32,043] ERROR Error while renaming dir for metalingus-0 in log dir C:\tmp\kafka-logs-1 (kafka.server.LogDirFailureChannel)
java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.228cee64ca1f42b690b08b531ae9ee7d-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.base/java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:728)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at kafka.log.Log.maybeHandleIOException(Log.scala:1927)
	at kafka.log.Log.renameDir(Log.scala:726)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:842)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:353)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:259)
	at kafka.cluster.Partition.delete(Partition.scala:347)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:350)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:380)
	at scala.collection.Iterator.foreach(Iterator.scala:937)
	at scala.collection.Iterator.foreach$(Iterator.scala:937)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1425)
	at scala.collection.IterableLike.foreach(IterableLike.scala:70)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:69)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:378)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:200)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:111)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.base/java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.228cee64ca1f42b690b08b531ae9ee7d-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.base/java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-01-10 02:29:32,058] INFO [ReplicaManager broker=1] Stopping serving replicas in dir C:\tmp\kafka-logs-1 (kafka.server.ReplicaManager)
[2019-01-10 02:29:32,095] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:32,098] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:29:32,135] INFO [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions old-skul-2,old-skul-1,old-skul-0 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs-1. (kafka.server.ReplicaManager)
[2019-01-10 02:29:32,148] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:32,150] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:29:32,149] INFO Stopping serving logs in dir C:\tmp\kafka-logs-1 (kafka.log.LogManager)
[2019-01-10 02:29:32,158] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:32,162] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:29:32,168] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs-1 have failed (kafka.log.LogManager)
[2019-01-10 02:29:32,534] WARN Exception causing close of session 0x1002fdd6a0b0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:29:32,536] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:61568 which had sessionid 0x1002fdd6a0b0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:29:33,027] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:29:33,033] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:29:33,112] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:29:33,188] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,189] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,190] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,190] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,191] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,191] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,194] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,196] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,196] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,197] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,199] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,219] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,221] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,222] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,224] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,230] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7ac0e420 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:33,297] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:29:33,300] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:29:33,309] INFO Accepted socket connection from /127.0.0.1:61585 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:29:33,311] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:29:33,327] INFO Client attempting to establish new session at /127.0.0.1:61585 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:33,388] INFO Established session 0x1002fdd6a0b0001 with negotiated timeout 6000 for client /127.0.0.1:61585 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:33,393] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002fdd6a0b0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:29:33,409] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:29:33,545] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0x1 zxid:0x184 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,603] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0x2 zxid:0x185 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,638] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0x3 zxid:0x186 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,673] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0x4 zxid:0x187 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,770] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0x5 zxid:0x188 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,860] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0x6 zxid:0x189 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,890] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0x7 zxid:0x18a txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,916] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0x8 zxid:0x18b txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,936] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0x9 zxid:0x18c txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,971] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0xa zxid:0x18d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:33,993] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0xb zxid:0x18e txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:34,027] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0xc zxid:0x18f txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:34,057] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:create cxid:0xd zxid:0x190 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:34,545] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 02:29:34,754] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:29:34,826] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9093
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:29:34,980] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:29:34,980] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:29:34,980] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:29:35,152] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:29:35,197] INFO Logs loading complete in 42 ms. (kafka.log.LogManager)
[2019-01-10 02:29:35,282] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:29:35,299] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:29:36,443] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2019-01-10 02:29:36,568] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:29:36,655] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:36,656] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:36,655] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:36,727] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:29:36,923] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:29:36,982] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:29:36,985] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:29:37,035] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:29:37,153] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:37,168] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:37,168] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:37,231] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:37,236] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:37,262] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:29:37,361] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:11000,blockEndProducerId:11999) by writing to Zk with path version 12 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:29:37,428] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:29:37,433] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:29:37,435] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:29:37,559] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:29:37,614] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:29:37,636] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:29:37,637] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:29:37,647] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-10 02:29:38,411] INFO Expiring session 0x1002fdd6a0b0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:38,412] INFO Processed session termination for sessionid: 0x1002fdd6a0b0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:38,764] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:29:38,767] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:29:38,845] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:29:38,934] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:39,005] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,063] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,064] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,065] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,068] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,076] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,084] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,097] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,114] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,123] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,127] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,130] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,133] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,146] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,149] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,165] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3a0baae5 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:29:39,241] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:29:39,287] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:29:39,313] INFO Accepted socket connection from /127.0.0.1:61602 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:29:39,331] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:39,314] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:29:39,356] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:multi cxid:0xe6 zxid:0x195 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:39,381] INFO Client attempting to establish new session at /127.0.0.1:61602 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:39,398] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 184 ms (kafka.log.Log)
[2019-01-10 02:29:39,406] INFO Created log for partition old-skul-2 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:39,414] INFO [Partition old-skul-2 broker=2] No checkpointed highwatermark is found for partition old-skul-2 (kafka.cluster.Partition)
[2019-01-10 02:29:39,427] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:39,516] INFO Established session 0x1002fdd6a0b0002 with negotiated timeout 6000 for client /127.0.0.1:61602 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:29:39,520] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002fdd6a0b0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:29:39,546] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:29:39,553] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:39,566] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-01-10 02:29:39,570] INFO Created log for partition old-skul-0 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:39,583] INFO [Partition old-skul-0 broker=2] No checkpointed highwatermark is found for partition old-skul-0 (kafka.cluster.Partition)
[2019-01-10 02:29:39,645] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:39,682] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0001 type:multi cxid:0xec zxid:0x198 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:39,686] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:39,700] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2019-01-10 02:29:39,714] INFO Created log for partition old-skul-1 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:39,721] INFO [Partition old-skul-1 broker=2] No checkpointed highwatermark is found for partition old-skul-1 (kafka.cluster.Partition)
[2019-01-10 02:29:39,724] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:39,727] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0x1 zxid:0x199 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:39,731] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:29:39,809] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0x2 zxid:0x19a txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:39,859] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0x3 zxid:0x19b txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:39,895] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0x4 zxid:0x19c txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:39,915] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0x5 zxid:0x19d txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:39,935] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0x6 zxid:0x19e txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:39,971] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0x7 zxid:0x19f txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:40,006] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0x8 zxid:0x1a0 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:40,036] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0x9 zxid:0x1a1 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:40,062] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0xa zxid:0x1a2 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:40,108] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0xb zxid:0x1a3 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:40,137] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0xc zxid:0x1a4 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:40,162] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0002 type:create cxid:0xd zxid:0x1a5 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:29:40,505] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 02:29:40,687] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:29:40,737] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9094
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:29:40,822] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:29:40,823] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:29:40,829] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:29:40,937] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:29:40,964] INFO Logs loading complete in 27 ms. (kafka.log.LogManager)
[2019-01-10 02:29:41,007] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:29:41,015] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:29:41,755] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2019-01-10 02:29:41,840] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:29:41,891] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:41,896] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:41,896] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:41,928] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:29:42,085] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:29:42,152] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:29:42,167] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:29:42,225] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:42,434] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:42,442] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:42,443] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:29:42,501] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:42,507] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:42,520] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:29:42,610] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:12000,blockEndProducerId:12999) by writing to Zk with path version 13 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:29:42,669] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:29:42,676] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:29:42,676] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:29:42,772] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:29:42,831] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:29:42,862] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:29:42,875] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:29:42,881] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-10 02:29:42,955] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:29:43,135] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:43,162] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 85 ms (kafka.log.Log)
[2019-01-10 02:29:43,170] INFO Created log for partition old-skul-2 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:43,180] INFO [Partition old-skul-2 broker=3] No checkpointed highwatermark is found for partition old-skul-2 (kafka.cluster.Partition)
[2019-01-10 02:29:43,186] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:43,203] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:43,215] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-01-10 02:29:43,217] INFO Created log for partition old-skul-0 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:43,218] INFO [Partition old-skul-0 broker=3] No checkpointed highwatermark is found for partition old-skul-0 (kafka.cluster.Partition)
[2019-01-10 02:29:43,224] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:43,246] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:29:43,252] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-10 02:29:43,255] INFO Created log for partition old-skul-1 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:29:43,256] INFO [Partition old-skul-1 broker=3] No checkpointed highwatermark is found for partition old-skul-1 (kafka.cluster.Partition)
[2019-01-10 02:29:43,263] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:29:43,270] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:31,311] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:30:32,180] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:30:32,182] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:30:32,211] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:30:32,535] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,535] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,537] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,538] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,538] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,539] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,544] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,546] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,579] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,581] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,582] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,583] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,584] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,585] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,587] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,590] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:30:32,640] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:30:32,643] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:30:32,649] INFO Accepted socket connection from /127.0.0.1:61636 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:30:32,650] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:30:32,662] INFO Client attempting to establish new session at /127.0.0.1:61636 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:30:32,755] INFO Established session 0x1002fdd6a0b0003 with negotiated timeout 6000 for client /127.0.0.1:61636 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:30:32,761] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002fdd6a0b0003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:30:32,778] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:30:32,867] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0x1 zxid:0x1a9 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:32,911] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0x2 zxid:0x1aa txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:32,962] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0x3 zxid:0x1ab txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,007] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0x4 zxid:0x1ac txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,039] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0x5 zxid:0x1ad txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,061] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0x6 zxid:0x1ae txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,093] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0x7 zxid:0x1af txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,117] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0x8 zxid:0x1b0 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,151] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0x9 zxid:0x1b1 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,172] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0xa zxid:0x1b2 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,195] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0xb zxid:0x1b3 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,216] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0xc zxid:0x1b4 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,238] INFO Got user-level KeeperException when processing sessionid:0x1002fdd6a0b0003 type:create cxid:0xd zxid:0x1b5 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:33,616] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 02:30:33,791] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:30:33,824] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://localhost:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:30:33,935] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:30:33,935] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:30:33,938] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:30:34,045] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:30:34,246] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-10 02:30:34,252] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:30:34,358] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:30:34,370] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 255 ms (kafka.log.Log)
[2019-01-10 02:30:34,416] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-10 02:30:34,417] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:30:34,482] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:30:34,489] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-01-10 02:30:34,509] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-10 02:30:34,511] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:30:34,574] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:30:34,579] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 79 ms (kafka.log.Log)
[2019-01-10 02:30:34,600] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-10 02:30:34,602] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:30:34,681] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:30:34,691] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 99 ms (kafka.log.Log)
[2019-01-10 02:30:34,707] INFO Logs loading complete in 661 ms. (kafka.log.LogManager)
[2019-01-10 02:30:34,732] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:30:34,736] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:30:35,490] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2019-01-10 02:30:35,591] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:30:35,677] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:30:35,684] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:30:35,684] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:30:35,724] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:30:35,862] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:30:35,919] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:30:35,922] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:30:35,969] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:35,973] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:36,061] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:36,065] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:36,179] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:30:36,187] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:30:36,189] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:30:36,280] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,288] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:36,296] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,316] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,326] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,340] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,275] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,341] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,345] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(old-skul-2, old-skul-0, old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:36,354] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:36,342] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,385] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,430] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 44 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:30:36,433] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,455] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,499] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:13000,blockEndProducerId:13999) by writing to Zk with path version 14 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:30:36,540] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9092) for partitions Map(old-skul-0 -> (offset=0, leaderEpoch=3), old-skul-1 -> (offset=0, leaderEpoch=3), old-skul-2 -> (offset=0, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:36,500] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:36,562] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(old-skul-2, old-skul-0, old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:36,574] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:30:36,600] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in old-skul-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:30:36,602] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:36,622] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-10 02:30:36,627] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in old-skul-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:30:36,629] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-10 02:30:36,630] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in old-skul-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:30:36,637] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-10 02:30:36,656] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:30:36,680] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:30:36,714] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker BrokerEndPoint(id=1, host=localhost:9092) for partitions Map(old-skul-0 -> (offset=0, leaderEpoch=3), old-skul-1 -> (offset=0, leaderEpoch=3), old-skul-2 -> (offset=0, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:36,744] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:36,718] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:30:36,762] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:30:36,794] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in old-skul-1. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:30:36,815] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-10 02:30:36,819] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in old-skul-0. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:30:36,822] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-10 02:30:36,825] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Based on replica's leader epoch, leader replied with an unknown offset in old-skul-2. The initial fetch offset 0 will be used for truncation. (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:30:36,827] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2019-01-10 02:30:36,896] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:30:36,941] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:30:36,956] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:30:36,957] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:30:36,961] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 02:30:37,145] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:37,193] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition old-skul-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-01-10 02:30:37,205] ERROR [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error for partition old-skul-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-01-10 02:30:37,219] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition old-skul-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-01-10 02:30:37,233] ERROR [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error for partition old-skul-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-01-10 02:30:37,226] ERROR [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error for partition old-skul-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-01-10 02:30:37,247] ERROR [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error for partition old-skul-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2019-01-10 02:30:37,323] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-0, old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:37,344] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,348] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,348] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,350] INFO [Partition old-skul-2 broker=1] old-skul-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:30:37,481] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,483] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,484] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,486] INFO [Partition old-skul-0 broker=1] old-skul-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:30:37,533] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,534] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,537] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,538] INFO [Partition old-skul-1 broker=1] old-skul-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:30:37,585] INFO Replica loaded for partition metalingus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:30:37,587] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:37,616] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:37,629] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-0, old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:37,630] INFO [Partition old-skul-2 broker=1] old-skul-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-10 02:30:37,631] WARN [LeaderEpochCache old-skul-2] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:30:37,690] INFO [Partition old-skul-0 broker=1] old-skul-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-10 02:30:37,691] WARN [LeaderEpochCache old-skul-0] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:30:37,725] INFO [Partition old-skul-1 broker=1] old-skul-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: 2 (kafka.cluster.Partition)
[2019-01-10 02:30:37,726] WARN [LeaderEpochCache old-skul-1] New epoch entry EpochEntry(epoch=3, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=2, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:30:37,767] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:30:37,778] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:37,778] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:30:37,787] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:37,788] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:30:37,797] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:37,797] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:30:37,800] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:37,800] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:30:37,879] ERROR Error while renaming dir for metalingus-0 in log dir C:\tmp\kafka-logs-1 (kafka.server.LogDirFailureChannel)
java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.fa622bb9043244b69720d3f895b17b0f-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.base/java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:728)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at kafka.log.Log.maybeHandleIOException(Log.scala:1927)
	at kafka.log.Log.renameDir(Log.scala:726)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:842)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:353)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:259)
	at kafka.cluster.Partition.delete(Partition.scala:347)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:350)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:380)
	at scala.collection.Iterator.foreach(Iterator.scala:937)
	at scala.collection.Iterator.foreach$(Iterator.scala:937)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1425)
	at scala.collection.IterableLike.foreach(IterableLike.scala:70)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:69)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:378)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:200)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:111)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.base/java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.fa622bb9043244b69720d3f895b17b0f-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.base/java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-01-10 02:30:37,891] INFO [ReplicaManager broker=1] Stopping serving replicas in dir C:\tmp\kafka-logs-1 (kafka.server.ReplicaManager)
[2019-01-10 02:30:37,908] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:37,909] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:30:37,927] INFO [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions old-skul-2,old-skul-1,old-skul-0 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs-1. (kafka.server.ReplicaManager)
[2019-01-10 02:30:37,928] INFO Stopping serving logs in dir C:\tmp\kafka-logs-1 (kafka.log.LogManager)
[2019-01-10 02:30:37,933] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs-1 have failed (kafka.log.LogManager)
[2019-01-10 02:30:37,934] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:37,935] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:30:38,275] WARN Exception causing close of session 0x1002fdd6a0b0003: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:30:38,276] INFO Closed socket connection for client /127.0.0.1:61636 which had sessionid 0x1002fdd6a0b0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:30:38,310] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:38,313] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:38,316] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:38,321] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:39,388] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:40,500] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:41,324] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:41,325] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:41,329] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:41,338] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:41,339] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:41,344] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:41,606] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:42,712] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:43,818] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:44,337] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:44,338] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:44,346] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:44,355] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:44,356] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:44,366] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:44,411] INFO Expiring session 0x1002fdd6a0b0003, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:30:44,412] INFO Processed session termination for sessionid: 0x1002fdd6a0b0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:30:44,946] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:45,168] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:45,172] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:30:47,357] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:47,358] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:47,367] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:47,375] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:47,378] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:47,387] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:50,376] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:50,376] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:50,380] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:50,396] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:50,397] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:50,404] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:53,387] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:53,388] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:53,397] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:53,413] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:53,414] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:53,426] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:56,408] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:56,408] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:56,414] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:56,438] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:56,439] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:56,443] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:59,423] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:59,424] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:59,433] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:30:59,452] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:30:59,453] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:30:59,458] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:02,438] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:02,439] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:02,448] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:02,465] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:02,466] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:02,475] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:05,458] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:05,459] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:05,464] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:05,490] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:05,490] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:05,495] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:08,504] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:08,505] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:08,514] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:08,475] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:09,906] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:09,907] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:11,524] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:11,525] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:11,536] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:12,913] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:12,914] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:12,925] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:14,548] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:14,549] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:14,559] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:15,934] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:15,935] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:15,945] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:17,570] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:17,570] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:17,578] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:18,961] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:18,961] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:18,972] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:20,588] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:20,589] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:20,600] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:21,982] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:21,982] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:21,987] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:23,610] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:23,611] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:23,620] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:24,994] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:24,995] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:25,007] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:26,629] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:26,629] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:26,634] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:28,018] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:28,019] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:28,034] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:29,642] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:29,643] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:29,656] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:31,044] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:31,045] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:31,057] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:32,666] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:32,667] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:32,676] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:34,065] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:34,066] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:34,076] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:35,686] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:35,687] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:35,697] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:37,094] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:37,100] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:37,110] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:38,707] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:38,707] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:38,711] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:40,120] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:40,121] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:40,127] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:41,717] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:41,718] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:41,723] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:43,135] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:43,136] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:43,146] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:44,733] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:44,734] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:44,740] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:46,155] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:46,156] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:46,168] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:47,747] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:47,748] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:47,754] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:49,176] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:49,177] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:49,188] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:50,764] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:50,765] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:50,770] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:52,199] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:52,200] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:52,210] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:53,775] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:53,776] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:53,781] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:55,220] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:55,221] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:55,233] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:56,788] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:56,788] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:56,791] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:58,258] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:58,258] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:58,266] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:31:58,830] INFO Accepted socket connection from /127.0.0.1:61742 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:31:58,856] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:58,860] INFO Closed socket connection for client /127.0.0.1:61742 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:58,924] INFO Accepted socket connection from /127.0.0.1:61743 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:31:58,926] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:58,932] INFO Closed socket connection for client /127.0.0.1:61743 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:59,037] INFO Accepted socket connection from /127.0.0.1:61744 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:31:59,038] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:59,042] INFO Closed socket connection for client /127.0.0.1:61744 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:59,302] INFO Accepted socket connection from /127.0.0.1:61745 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:31:59,313] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:59,314] INFO Closed socket connection for client /127.0.0.1:61745 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:59,779] INFO Accepted socket connection from /127.0.0.1:61746 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:31:59,780] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:59,784] INFO Closed socket connection for client /127.0.0.1:61746 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:31:59,813] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:31:59,813] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:31:59,816] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:00,606] INFO Accepted socket connection from /127.0.0.1:61750 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:00,608] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:00,615] INFO Closed socket connection for client /127.0.0.1:61750 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:01,275] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:01,275] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:01,287] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:01,542] INFO Accepted socket connection from /127.0.0.1:61752 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:01,544] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:01,549] INFO Closed socket connection for client /127.0.0.1:61752 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:02,412] INFO Accepted socket connection from /127.0.0.1:61755 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:02,413] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:02,422] INFO Closed socket connection for client /127.0.0.1:61755 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:02,822] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:02,823] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:02,828] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:03,589] INFO Accepted socket connection from /127.0.0.1:61757 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:03,590] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:03,600] INFO Closed socket connection for client /127.0.0.1:61757 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:04,295] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:04,296] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:04,306] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:04,462] INFO Accepted socket connection from /127.0.0.1:61759 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:04,463] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:04,468] INFO Closed socket connection for client /127.0.0.1:61759 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:05,385] INFO Accepted socket connection from /127.0.0.1:61761 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:05,387] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:05,396] INFO Closed socket connection for client /127.0.0.1:61761 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:05,837] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:05,838] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:05,843] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:06,510] INFO Accepted socket connection from /127.0.0.1:61764 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:06,511] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:06,521] INFO Closed socket connection for client /127.0.0.1:61764 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:07,316] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:07,316] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:07,321] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:07,389] INFO Accepted socket connection from /127.0.0.1:61765 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:07,390] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:07,398] INFO Closed socket connection for client /127.0.0.1:61765 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:08,413] INFO Accepted socket connection from /127.0.0.1:61768 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:08,415] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:08,423] INFO Closed socket connection for client /127.0.0.1:61768 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:08,853] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:08,854] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:08,858] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:09,543] INFO Accepted socket connection from /127.0.0.1:61770 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:09,545] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:09,553] INFO Closed socket connection for client /127.0.0.1:61770 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:10,330] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:10,331] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:10,341] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:10,570] INFO Accepted socket connection from /127.0.0.1:61772 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:10,571] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:10,582] INFO Closed socket connection for client /127.0.0.1:61772 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:11,596] INFO Accepted socket connection from /127.0.0.1:61774 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:11,597] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:11,606] INFO Closed socket connection for client /127.0.0.1:61774 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:11,869] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:11,870] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:11,876] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:12,622] INFO Accepted socket connection from /127.0.0.1:61778 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:12,623] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:12,631] INFO Closed socket connection for client /127.0.0.1:61778 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:13,350] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:13,352] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:13,364] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:13,694] INFO Accepted socket connection from /127.0.0.1:61780 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:13,696] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:13,705] INFO Closed socket connection for client /127.0.0.1:61780 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:14,626] INFO Accepted socket connection from /127.0.0.1:61783 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:14,627] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:14,636] INFO Closed socket connection for client /127.0.0.1:61783 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:14,881] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:14,884] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:14,898] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:15,806] INFO Accepted socket connection from /127.0.0.1:61786 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:15,807] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:15,816] INFO Closed socket connection for client /127.0.0.1:61786 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:16,372] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:16,373] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:16,385] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:16,780] INFO Accepted socket connection from /127.0.0.1:61788 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:16,782] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:16,791] INFO Closed socket connection for client /127.0.0.1:61788 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:17,758] INFO Accepted socket connection from /127.0.0.1:61790 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:17,759] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:17,769] INFO Closed socket connection for client /127.0.0.1:61790 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:17,909] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:17,909] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:17,914] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:18,936] INFO Accepted socket connection from /127.0.0.1:61793 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:18,937] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:18,941] INFO Closed socket connection for client /127.0.0.1:61793 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:19,394] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:19,394] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:19,399] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:20,117] INFO Accepted socket connection from /127.0.0.1:61796 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:20,118] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:20,123] INFO Closed socket connection for client /127.0.0.1:61796 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:20,920] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:20,920] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:20,923] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:21,195] INFO Accepted socket connection from /127.0.0.1:61797 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:21,196] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:21,200] INFO Closed socket connection for client /127.0.0.1:61797 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:22,068] INFO Accepted socket connection from /127.0.0.1:61800 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:22,070] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:22,081] INFO Closed socket connection for client /127.0.0.1:61800 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:22,405] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:22,406] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:22,418] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:22,997] INFO Accepted socket connection from /127.0.0.1:61802 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:22,998] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:23,010] INFO Closed socket connection for client /127.0.0.1:61802 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:23,934] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:23,934] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:23,939] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:23,982] INFO Accepted socket connection from /127.0.0.1:61804 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:23,986] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:23,990] INFO Closed socket connection for client /127.0.0.1:61804 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:25,208] INFO Accepted socket connection from /127.0.0.1:61806 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:25,210] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:25,220] INFO Closed socket connection for client /127.0.0.1:61806 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:25,431] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:25,432] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:25,442] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:26,181] INFO Accepted socket connection from /127.0.0.1:61809 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:26,182] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:26,191] INFO Closed socket connection for client /127.0.0.1:61809 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:26,945] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:26,946] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:26,951] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:27,312] INFO Accepted socket connection from /127.0.0.1:61810 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:27,313] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:27,320] INFO Closed socket connection for client /127.0.0.1:61810 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:28,183] INFO Accepted socket connection from /127.0.0.1:61813 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:28,184] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:28,197] INFO Closed socket connection for client /127.0.0.1:61813 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:28,452] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:28,453] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:28,465] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:29,264] INFO Accepted socket connection from /127.0.0.1:61815 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:29,265] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:29,274] INFO Closed socket connection for client /127.0.0.1:61815 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:29,958] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:29,960] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:29,965] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:30,191] INFO Accepted socket connection from /127.0.0.1:61817 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:30,192] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:30,201] INFO Closed socket connection for client /127.0.0.1:61817 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:31,317] INFO Accepted socket connection from /127.0.0.1:61819 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:31,319] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:31,330] INFO Closed socket connection for client /127.0.0.1:61819 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:31,471] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:31,472] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:31,481] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:32,242] INFO Accepted socket connection from /127.0.0.1:61822 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:32,243] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:32,252] INFO Closed socket connection for client /127.0.0.1:61822 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:32,974] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:32,975] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:32,980] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:33,167] INFO Accepted socket connection from /127.0.0.1:61823 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:33,169] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:33,181] INFO Closed socket connection for client /127.0.0.1:61823 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:34,096] INFO Accepted socket connection from /127.0.0.1:61826 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:34,098] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:34,106] INFO Closed socket connection for client /127.0.0.1:61826 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:34,490] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:34,490] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:34,499] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:35,069] INFO Accepted socket connection from /127.0.0.1:61828 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:35,071] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:35,081] INFO Closed socket connection for client /127.0.0.1:61828 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:35,986] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:35,986] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:35,988] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:36,043] INFO Accepted socket connection from /127.0.0.1:61829 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:36,046] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:36,050] INFO Closed socket connection for client /127.0.0.1:61829 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:37,015] INFO Accepted socket connection from /127.0.0.1:61832 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:37,016] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:37,019] INFO Closed socket connection for client /127.0.0.1:61832 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:37,510] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:37,510] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:37,515] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:37,883] INFO Accepted socket connection from /127.0.0.1:61833 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:37,884] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:37,893] INFO Closed socket connection for client /127.0.0.1:61833 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:38,959] INFO Accepted socket connection from /127.0.0.1:61836 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:38,960] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:38,968] INFO Closed socket connection for client /127.0.0.1:61836 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:38,997] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:38,998] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:39,004] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:39,831] INFO Accepted socket connection from /127.0.0.1:61838 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:39,834] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:39,842] INFO Closed socket connection for client /127.0.0.1:61838 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:40,524] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:40,525] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:40,532] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:40,859] INFO Accepted socket connection from /127.0.0.1:61840 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:40,860] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:40,872] INFO Closed socket connection for client /127.0.0.1:61840 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:41,784] INFO Accepted socket connection from /127.0.0.1:61842 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:41,786] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:41,796] INFO Closed socket connection for client /127.0.0.1:61842 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:42,013] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:42,014] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:42,019] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:42,657] INFO Accepted socket connection from /127.0.0.1:61845 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:42,659] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:42,668] INFO Closed socket connection for client /127.0.0.1:61845 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:43,543] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:43,543] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:43,550] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:43,632] INFO Accepted socket connection from /127.0.0.1:61846 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:43,633] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:43,643] INFO Closed socket connection for client /127.0.0.1:61846 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:44,808] INFO Accepted socket connection from /127.0.0.1:61848 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:44,808] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:44,819] INFO Closed socket connection for client /127.0.0.1:61848 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:45,026] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:45,027] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:45,034] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:45,884] INFO Accepted socket connection from /127.0.0.1:61850 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:45,886] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:45,899] INFO Closed socket connection for client /127.0.0.1:61850 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:46,558] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:46,559] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:46,565] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:46,869] INFO Accepted socket connection from /127.0.0.1:61851 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:46,871] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:46,881] INFO Closed socket connection for client /127.0.0.1:61851 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:47,846] INFO Accepted socket connection from /127.0.0.1:61853 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:47,847] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:47,853] INFO Closed socket connection for client /127.0.0.1:61853 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:48,041] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:48,042] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:48,047] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:49,071] INFO Accepted socket connection from /127.0.0.1:61855 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:49,072] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:49,082] INFO Closed socket connection for client /127.0.0.1:61855 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:49,572] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:49,573] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:49,581] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:50,150] INFO Accepted socket connection from /127.0.0.1:61857 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:50,151] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:50,162] INFO Closed socket connection for client /127.0.0.1:61857 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:51,054] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:51,055] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:51,060] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:51,281] INFO Accepted socket connection from /127.0.0.1:61859 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:51,283] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:51,292] INFO Closed socket connection for client /127.0.0.1:61859 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:52,360] INFO Accepted socket connection from /127.0.0.1:61861 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:52,361] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:52,368] INFO Closed socket connection for client /127.0.0.1:61861 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:52,586] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:52,587] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:52,594] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:53,435] INFO Accepted socket connection from /127.0.0.1:61863 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:53,436] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:53,446] INFO Closed socket connection for client /127.0.0.1:61863 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:54,065] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:54,066] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:54,070] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:54,359] INFO Accepted socket connection from /127.0.0.1:61864 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:54,361] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:54,371] INFO Closed socket connection for client /127.0.0.1:61864 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:55,337] INFO Accepted socket connection from /127.0.0.1:61867 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:55,339] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:55,347] INFO Closed socket connection for client /127.0.0.1:61867 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:55,600] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:55,601] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:55,607] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:56,360] INFO Accepted socket connection from /127.0.0.1:61869 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:56,361] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:56,369] INFO Closed socket connection for client /127.0.0.1:61869 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:57,077] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:57,078] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:57,083] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:57,438] INFO Accepted socket connection from /127.0.0.1:61870 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:57,439] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:57,448] INFO Closed socket connection for client /127.0.0.1:61870 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:58,413] INFO Accepted socket connection from /127.0.0.1:61873 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:58,414] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:58,426] INFO Closed socket connection for client /127.0.0.1:61873 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:58,618] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:32:58,618] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:32:58,622] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:32:59,540] INFO Accepted socket connection from /127.0.0.1:61875 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:32:59,542] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:32:59,550] INFO Closed socket connection for client /127.0.0.1:61875 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:00,091] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:00,091] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:00,094] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:00,621] INFO Accepted socket connection from /127.0.0.1:61876 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:00,622] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:00,628] INFO Closed socket connection for client /127.0.0.1:61876 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:01,490] INFO Accepted socket connection from /127.0.0.1:61879 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:01,491] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:01,498] INFO Closed socket connection for client /127.0.0.1:61879 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:01,627] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:01,628] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:01,638] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:02,618] INFO Accepted socket connection from /127.0.0.1:61883 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:02,619] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:02,626] INFO Closed socket connection for client /127.0.0.1:61883 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:03,102] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:03,103] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:03,109] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:03,588] INFO Accepted socket connection from /127.0.0.1:61884 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:03,590] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:03,599] INFO Closed socket connection for client /127.0.0.1:61884 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:04,648] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:04,649] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:04,656] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:04,813] INFO Accepted socket connection from /127.0.0.1:61886 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:04,815] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:04,828] INFO Closed socket connection for client /127.0.0.1:61886 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:05,797] INFO Accepted socket connection from /127.0.0.1:61888 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:05,798] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:05,806] INFO Closed socket connection for client /127.0.0.1:61888 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:06,114] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:06,115] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:06,120] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:06,821] INFO Accepted socket connection from /127.0.0.1:61890 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:06,822] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:06,833] INFO Closed socket connection for client /127.0.0.1:61890 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:07,662] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:07,663] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:07,670] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:07,998] INFO Accepted socket connection from /127.0.0.1:61891 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:08,000] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:08,012] INFO Closed socket connection for client /127.0.0.1:61891 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:08,976] INFO Accepted socket connection from /127.0.0.1:61893 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:08,977] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:08,985] INFO Closed socket connection for client /127.0.0.1:61893 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:09,129] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:09,130] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:09,135] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:10,000] INFO Accepted socket connection from /127.0.0.1:61895 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:10,001] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:10,012] INFO Closed socket connection for client /127.0.0.1:61895 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:10,677] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:10,678] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:10,685] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:10,926] INFO Accepted socket connection from /127.0.0.1:61896 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:10,926] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:10,935] INFO Closed socket connection for client /127.0.0.1:61896 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:11,798] INFO Accepted socket connection from /127.0.0.1:61898 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:11,799] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:11,808] INFO Closed socket connection for client /127.0.0.1:61898 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:12,142] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:12,143] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:12,150] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:12,673] INFO Accepted socket connection from /127.0.0.1:61899 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:12,675] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:12,682] INFO Closed socket connection for client /127.0.0.1:61899 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:13,694] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:13,695] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:13,702] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:13,746] INFO Accepted socket connection from /127.0.0.1:61901 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:13,747] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:13,755] INFO Closed socket connection for client /127.0.0.1:61901 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:14,972] INFO Accepted socket connection from /127.0.0.1:61903 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:14,973] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:14,982] INFO Closed socket connection for client /127.0.0.1:61903 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:15,159] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:15,160] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:15,166] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:15,946] INFO Accepted socket connection from /127.0.0.1:61905 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:15,947] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:15,956] INFO Closed socket connection for client /127.0.0.1:61905 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:16,711] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:16,711] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:16,717] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:17,074] INFO Accepted socket connection from /127.0.0.1:61906 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:17,075] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:17,082] INFO Closed socket connection for client /127.0.0.1:61906 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:18,046] INFO Accepted socket connection from /127.0.0.1:61908 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:18,047] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:18,056] INFO Closed socket connection for client /127.0.0.1:61908 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:18,174] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:18,174] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:18,177] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:19,224] INFO Accepted socket connection from /127.0.0.1:61910 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:19,225] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:19,229] INFO Closed socket connection for client /127.0.0.1:61910 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:19,729] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:19,730] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:19,736] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:20,094] INFO Accepted socket connection from /127.0.0.1:61911 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:20,095] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:20,104] INFO Closed socket connection for client /127.0.0.1:61911 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:20,917] INFO Accepted socket connection from /127.0.0.1:61913 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:20,926] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:20,935] INFO Closed socket connection for client /127.0.0.1:61913 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:21,189] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:21,190] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:21,195] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:22,052] INFO Accepted socket connection from /127.0.0.1:61916 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:22,054] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:22,062] INFO Closed socket connection for client /127.0.0.1:61916 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:22,742] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:22,743] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:22,748] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:23,229] INFO Accepted socket connection from /127.0.0.1:61920 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:23,230] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:23,240] INFO Closed socket connection for client /127.0.0.1:61920 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:24,106] INFO Accepted socket connection from /127.0.0.1:61921 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:24,107] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:24,117] INFO Closed socket connection for client /127.0.0.1:61921 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:24,203] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:24,203] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:24,206] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:25,081] INFO Accepted socket connection from /127.0.0.1:61923 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:25,082] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:25,085] INFO Closed socket connection for client /127.0.0.1:61923 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:25,756] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:25,757] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:25,767] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:25,900] INFO Accepted socket connection from /127.0.0.1:61924 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:25,914] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:25,924] INFO Closed socket connection for client /127.0.0.1:61924 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:26,895] INFO Accepted socket connection from /127.0.0.1:61927 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:26,895] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:26,905] INFO Closed socket connection for client /127.0.0.1:61927 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:27,212] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:27,213] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:27,218] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:27,819] INFO Accepted socket connection from /127.0.0.1:61929 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:27,820] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:27,830] INFO Closed socket connection for client /127.0.0.1:61929 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:28,744] INFO Accepted socket connection from /127.0.0.1:61930 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:28,746] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:28,754] INFO Closed socket connection for client /127.0.0.1:61930 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:28,772] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:28,773] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:28,780] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:29,970] INFO Accepted socket connection from /127.0.0.1:61933 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:29,972] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:29,980] INFO Closed socket connection for client /127.0.0.1:61933 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:30,224] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:30,225] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:30,229] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:30,846] INFO Accepted socket connection from /127.0.0.1:61935 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:30,847] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:30,851] INFO Closed socket connection for client /127.0.0.1:61935 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:31,788] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:31,789] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:31,796] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:31,815] INFO Accepted socket connection from /127.0.0.1:61936 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:31,818] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:31,829] INFO Closed socket connection for client /127.0.0.1:61936 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:32,792] INFO Accepted socket connection from /127.0.0.1:61938 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:32,792] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:32,799] INFO Closed socket connection for client /127.0.0.1:61938 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:33,234] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:33,235] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:33,238] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:33,766] INFO Accepted socket connection from /127.0.0.1:61939 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:33,767] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:33,770] INFO Closed socket connection for client /127.0.0.1:61939 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:34,802] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:34,803] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:34,811] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:34,933] INFO Accepted socket connection from /127.0.0.1:61941 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:34,934] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:34,936] INFO Closed socket connection for client /127.0.0.1:61941 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:36,154] INFO Accepted socket connection from /127.0.0.1:61943 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:36,156] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:36,165] INFO Closed socket connection for client /127.0.0.1:61943 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:36,245] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:36,246] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:36,251] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:37,327] INFO Accepted socket connection from /127.0.0.1:61946 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:37,328] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:37,333] INFO Closed socket connection for client /127.0.0.1:61946 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:37,819] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:37,819] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:37,822] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:38,350] INFO Accepted socket connection from /127.0.0.1:61948 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:38,350] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:38,359] INFO Closed socket connection for client /127.0.0.1:61948 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:39,260] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:39,261] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:39,266] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:39,476] INFO Accepted socket connection from /127.0.0.1:61949 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:39,477] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:39,482] INFO Closed socket connection for client /127.0.0.1:61949 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:40,345] INFO Accepted socket connection from /127.0.0.1:61951 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:40,347] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:40,356] INFO Closed socket connection for client /127.0.0.1:61951 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:40,835] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:40,836] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:40,843] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:41,318] INFO Accepted socket connection from /127.0.0.1:61953 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:41,319] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:41,329] INFO Closed socket connection for client /127.0.0.1:61953 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:42,273] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:42,274] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:42,279] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:42,294] INFO Accepted socket connection from /127.0.0.1:61954 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:42,296] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:42,306] INFO Closed socket connection for client /127.0.0.1:61954 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:43,322] INFO Accepted socket connection from /127.0.0.1:61956 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:43,324] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:43,329] INFO Closed socket connection for client /127.0.0.1:61956 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:43,848] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:43,848] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:43,851] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:44,397] INFO Accepted socket connection from /127.0.0.1:61958 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:44,398] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:44,403] INFO Closed socket connection for client /127.0.0.1:61958 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:45,287] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:45,288] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:45,293] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:45,317] INFO Accepted socket connection from /127.0.0.1:61959 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:45,319] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:45,331] INFO Closed socket connection for client /127.0.0.1:61959 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:46,344] INFO Accepted socket connection from /127.0.0.1:61961 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:46,345] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:46,349] INFO Closed socket connection for client /127.0.0.1:61961 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:46,857] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:46,858] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:46,863] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:47,212] INFO Accepted socket connection from /127.0.0.1:61962 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:47,213] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:47,221] INFO Closed socket connection for client /127.0.0.1:61962 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:48,184] INFO Accepted socket connection from /127.0.0.1:61964 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:48,185] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:48,194] INFO Closed socket connection for client /127.0.0.1:61964 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:48,302] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:48,302] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:48,308] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:49,205] INFO Accepted socket connection from /127.0.0.1:61966 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:49,206] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:49,215] INFO Closed socket connection for client /127.0.0.1:61966 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:49,872] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:49,873] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:49,879] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:50,380] INFO Accepted socket connection from /127.0.0.1:61968 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:50,381] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:50,391] INFO Closed socket connection for client /127.0.0.1:61968 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:51,304] INFO Accepted socket connection from /127.0.0.1:61970 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:51,306] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:51,313] INFO Closed socket connection for client /127.0.0.1:61970 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:51,318] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:51,320] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:51,328] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:52,428] INFO Accepted socket connection from /127.0.0.1:61972 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:52,430] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:52,442] INFO Closed socket connection for client /127.0.0.1:61972 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:52,886] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:52,887] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:52,894] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:53,660] INFO Accepted socket connection from /127.0.0.1:61974 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:53,661] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:53,668] INFO Closed socket connection for client /127.0.0.1:61974 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:54,335] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:54,336] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:54,341] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:54,734] INFO Accepted socket connection from /127.0.0.1:61976 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:54,735] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:54,743] INFO Closed socket connection for client /127.0.0.1:61976 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:55,753] INFO Accepted socket connection from /127.0.0.1:61978 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:55,754] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:55,762] INFO Closed socket connection for client /127.0.0.1:61978 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:55,900] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:55,900] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:55,908] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:56,977] INFO Accepted socket connection from /127.0.0.1:61980 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:56,978] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:56,986] INFO Closed socket connection for client /127.0.0.1:61980 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:57,348] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:57,349] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:57,354] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:58,049] INFO Accepted socket connection from /127.0.0.1:61982 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:58,058] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:58,067] INFO Closed socket connection for client /127.0.0.1:61982 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:58,914] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:33:58,915] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:33:58,924] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:33:59,185] INFO Accepted socket connection from /127.0.0.1:61983 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:33:59,187] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:33:59,194] INFO Closed socket connection for client /127.0.0.1:61983 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:00,056] INFO Accepted socket connection from /127.0.0.1:61985 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:00,057] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:00,062] INFO Closed socket connection for client /127.0.0.1:61985 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:00,362] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:00,363] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:00,367] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:01,181] INFO Accepted socket connection from /127.0.0.1:61987 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:01,182] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:01,194] INFO Closed socket connection for client /127.0.0.1:61987 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:01,931] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:01,932] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:01,938] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:02,413] INFO Accepted socket connection from /127.0.0.1:61989 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:02,415] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:02,426] INFO Closed socket connection for client /127.0.0.1:61989 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:03,375] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:03,376] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:03,381] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:03,388] INFO Accepted socket connection from /127.0.0.1:61990 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:03,389] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:03,400] INFO Closed socket connection for client /127.0.0.1:61990 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:04,419] INFO Accepted socket connection from /127.0.0.1:61992 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:04,420] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:04,429] INFO Closed socket connection for client /127.0.0.1:61992 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:04,945] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:04,946] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:04,952] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:05,546] INFO Accepted socket connection from /127.0.0.1:61994 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:05,547] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:05,558] INFO Closed socket connection for client /127.0.0.1:61994 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:06,388] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:06,388] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:06,394] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:06,573] INFO Accepted socket connection from /127.0.0.1:61995 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:06,574] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:06,583] INFO Closed socket connection for client /127.0.0.1:61995 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:07,749] INFO Accepted socket connection from /127.0.0.1:61997 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:07,749] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:07,754] INFO Closed socket connection for client /127.0.0.1:61997 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:07,964] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:07,964] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:07,968] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:08,867] INFO Accepted socket connection from /127.0.0.1:62000 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:08,868] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:08,876] INFO Closed socket connection for client /127.0.0.1:62000 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:09,404] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:09,405] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:09,410] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:09,840] INFO Accepted socket connection from /127.0.0.1:62001 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:09,841] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:09,850] INFO Closed socket connection for client /127.0.0.1:62001 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:10,917] INFO Accepted socket connection from /127.0.0.1:62003 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:10,919] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:10,930] INFO Closed socket connection for client /127.0.0.1:62003 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:10,977] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:10,978] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:10,983] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:12,092] INFO Accepted socket connection from /127.0.0.1:62006 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:12,096] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:12,110] INFO Closed socket connection for client /127.0.0.1:62006 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:12,416] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:12,418] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:12,428] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:13,029] INFO Accepted socket connection from /127.0.0.1:62008 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:13,030] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:13,035] INFO Closed socket connection for client /127.0.0.1:62008 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:13,991] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:13,992] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:13,998] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:14,101] INFO Accepted socket connection from /127.0.0.1:62009 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:14,102] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:14,113] INFO Closed socket connection for client /127.0.0.1:62009 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:15,125] INFO Accepted socket connection from /127.0.0.1:62011 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:15,125] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:15,129] INFO Closed socket connection for client /127.0.0.1:62011 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:15,436] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:15,437] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:15,442] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:16,240] INFO Accepted socket connection from /127.0.0.1:62013 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:16,241] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:16,250] INFO Closed socket connection for client /127.0.0.1:62013 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:17,004] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:17,005] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:17,012] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:17,315] INFO Accepted socket connection from /127.0.0.1:62014 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:17,316] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:17,324] INFO Closed socket connection for client /127.0.0.1:62014 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:18,439] INFO Accepted socket connection from /127.0.0.1:62016 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:18,440] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:18,444] INFO Closed socket connection for client /127.0.0.1:62016 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:18,450] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:18,451] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:18,459] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:19,259] INFO Accepted socket connection from /127.0.0.1:62018 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:19,260] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:19,268] INFO Closed socket connection for client /127.0.0.1:62018 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:20,020] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:20,020] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:20,027] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:20,387] INFO Accepted socket connection from /127.0.0.1:62019 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:20,387] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:20,397] INFO Closed socket connection for client /127.0.0.1:62019 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:21,365] INFO Accepted socket connection from /127.0.0.1:62022 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:21,365] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:21,373] INFO Closed socket connection for client /127.0.0.1:62022 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:21,469] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:21,473] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:21,478] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:22,340] INFO Accepted socket connection from /127.0.0.1:62024 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:22,340] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:22,349] INFO Closed socket connection for client /127.0.0.1:62024 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:23,035] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:23,035] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:23,041] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:23,415] INFO Accepted socket connection from /127.0.0.1:62025 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:23,416] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:23,428] INFO Closed socket connection for client /127.0.0.1:62025 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:24,389] INFO Accepted socket connection from /127.0.0.1:62028 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:24,390] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:24,399] INFO Closed socket connection for client /127.0.0.1:62028 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:24,484] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:24,485] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:24,491] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:25,518] INFO Accepted socket connection from /127.0.0.1:62030 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:25,519] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:25,528] INFO Closed socket connection for client /127.0.0.1:62030 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:26,047] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:26,048] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:26,056] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:26,540] INFO Accepted socket connection from /127.0.0.1:62032 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:26,541] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:26,550] INFO Closed socket connection for client /127.0.0.1:62032 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:27,501] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:27,502] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:27,508] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:27,617] INFO Accepted socket connection from /127.0.0.1:62034 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:27,618] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:27,627] INFO Closed socket connection for client /127.0.0.1:62034 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:28,540] INFO Accepted socket connection from /127.0.0.1:62036 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:28,541] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:28,549] INFO Closed socket connection for client /127.0.0.1:62036 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:29,067] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:29,071] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:29,074] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:29,664] INFO Accepted socket connection from /127.0.0.1:62038 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:29,665] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:29,676] INFO Closed socket connection for client /127.0.0.1:62038 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:30,514] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:30,515] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:30,520] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:30,791] INFO Accepted socket connection from /127.0.0.1:62039 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:30,792] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:30,801] INFO Closed socket connection for client /127.0.0.1:62039 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:31,815] INFO Accepted socket connection from /127.0.0.1:62041 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:31,816] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:31,826] INFO Closed socket connection for client /127.0.0.1:62041 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:32,082] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:32,083] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:32,091] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:32,840] INFO Accepted socket connection from /127.0.0.1:62043 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:32,842] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:32,851] INFO Closed socket connection for client /127.0.0.1:62043 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:33,531] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:33,534] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:33,545] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:33,864] INFO Accepted socket connection from /127.0.0.1:62044 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:33,867] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:33,874] INFO Closed socket connection for client /127.0.0.1:62044 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:34,938] INFO Accepted socket connection from /127.0.0.1:62046 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:34,939] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:34,949] INFO Closed socket connection for client /127.0.0.1:62046 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:35,097] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:35,097] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:35,104] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:36,013] INFO Accepted socket connection from /127.0.0.1:62049 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:36,014] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:36,023] INFO Closed socket connection for client /127.0.0.1:62049 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:36,553] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:36,554] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:36,559] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:37,188] INFO Accepted socket connection from /127.0.0.1:62051 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:37,189] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:37,197] INFO Closed socket connection for client /127.0.0.1:62051 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:38,111] INFO Accepted socket connection from /127.0.0.1:62052 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:38,112] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:38,113] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:38,121] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:38,113] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:38,124] INFO Closed socket connection for client /127.0.0.1:62052 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:39,087] INFO Accepted socket connection from /127.0.0.1:62055 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:39,089] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:39,099] INFO Closed socket connection for client /127.0.0.1:62055 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:39,572] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:39,572] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:39,577] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:40,117] INFO Accepted socket connection from /127.0.0.1:62057 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:40,118] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:40,123] INFO Closed socket connection for client /127.0.0.1:62057 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:40,988] INFO Accepted socket connection from /127.0.0.1:62059 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:40,991] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:41,001] INFO Closed socket connection for client /127.0.0.1:62059 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:41,135] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:41,136] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:41,142] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:42,020] INFO Accepted socket connection from /127.0.0.1:62061 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:42,021] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:42,029] INFO Closed socket connection for client /127.0.0.1:62061 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:42,586] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:42,587] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:42,593] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:42,892] INFO Accepted socket connection from /127.0.0.1:62062 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:42,893] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:42,901] INFO Closed socket connection for client /127.0.0.1:62062 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:43,968] INFO Accepted socket connection from /127.0.0.1:62064 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:43,970] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:43,979] INFO Closed socket connection for client /127.0.0.1:62064 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:44,148] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:44,149] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:44,157] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:44,944] INFO Accepted socket connection from /127.0.0.1:62066 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:44,945] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:44,949] INFO Closed socket connection for client /127.0.0.1:62066 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:45,611] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:45,612] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:45,617] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:45,811] INFO Accepted socket connection from /127.0.0.1:62067 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:45,813] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:45,821] INFO Closed socket connection for client /127.0.0.1:62067 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:46,936] INFO Accepted socket connection from /127.0.0.1:62069 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:46,937] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:46,945] INFO Closed socket connection for client /127.0.0.1:62069 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:47,163] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:47,164] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:47,170] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:47,911] INFO Accepted socket connection from /127.0.0.1:62071 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:47,911] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:47,921] INFO Closed socket connection for client /127.0.0.1:62071 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:48,625] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:48,626] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:48,633] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:48,982] INFO Accepted socket connection from /127.0.0.1:62073 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:48,982] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:48,988] INFO Closed socket connection for client /127.0.0.1:62073 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:50,102] INFO Accepted socket connection from /127.0.0.1:62075 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:50,103] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:50,111] INFO Closed socket connection for client /127.0.0.1:62075 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:50,177] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:50,178] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:50,185] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:51,227] INFO Accepted socket connection from /127.0.0.1:62077 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:34:51,228] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:51,240] INFO Closed socket connection for client /127.0.0.1:62077 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:34:51,639] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:51,640] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:51,645] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:53,190] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:53,191] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:53,196] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:54,653] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:54,654] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:54,660] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:56,205] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:56,206] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:56,212] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:57,668] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:57,669] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:57,674] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:34:59,220] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:34:59,221] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:34:59,227] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:00,689] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:00,690] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:00,696] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:02,235] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:02,235] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:02,239] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:03,703] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:03,704] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:03,708] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:05,245] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:05,245] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:05,251] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:06,716] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:06,717] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:06,723] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:08,257] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:08,258] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:08,265] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:09,730] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:09,730] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:09,734] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:11,275] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:11,275] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:11,281] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:12,741] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:12,742] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:12,747] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:14,288] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:14,289] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:14,295] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:15,754] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:15,755] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:15,760] WARN [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=3, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:17,299] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:17,300] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:17,307] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:17,528] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:35:17,533] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 02:35:17,586] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:17,587] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:17,608] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(old-skul-2) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:17,615] INFO [KafkaServer id=3] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-01-10 02:35:17,618] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:17,618] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(old-skul-2) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:17,645] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:17,654] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(old-skul-1) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:17,662] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(old-skul-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:17,671] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:35:17,666] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:35:17,676] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(old-skul-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:17,676] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:35:17,676] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:35:17,691] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:35:17,708] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:35:17,712] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:35:17,726] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:17,740] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:17,750] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:35:17,754] INFO [Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:35:17,763] INFO [Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:35:17,771] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 02:35:17,774] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:17,855] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:17,855] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:17,871] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:35:17,875] INFO [ProducerId Manager 3]: Shutdown complete: last producerId assigned 12000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:35:17,879] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 02:35:17,880] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:35:17,886] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:35:17,886] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:35:17,896] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:35:17,905] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:35:17,909] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,057] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,057] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,068] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,257] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,257] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,266] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:35:18,270] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 02:35:18,276] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:35:18,278] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:35:18,278] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:35:18,282] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:18,303] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:18,306] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:18,308] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:18,309] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,481] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,481] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,485] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,684] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,684] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,684] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,844] WARN [Controller id=2, targetBrokerId=3] Connection to node 3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:18,885] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,885] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:18,949] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 02:35:18,953] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:35:19,114] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:35:19,128] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:35:19,130] INFO Processed session termination for sessionid: 0x1002fdd6a0b0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:35:19,153] INFO Session: 0x1002fdd6a0b0002 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:35:19,154] WARN Unable to read additional data from client sessionid 0x1002fdd6a0b0002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:35:19,153] INFO EventThread shut down for session: 0x1002fdd6a0b0002 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:35:19,156] INFO Closed socket connection for client /127.0.0.1:61602 which had sessionid 0x1002fdd6a0b0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:35:19,156] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:35:19,174] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:19,954] WARN [Controller id=2, targetBrokerId=3] Connection to node 3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:20,009] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:20,009] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:20,009] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:20,099] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:20,313] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:20,314] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1: java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-01-10 02:35:20,322] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={old-skul-2=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-0=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), old-skul-1=(offset=0, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=INVALID, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to localhost:9092 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:70)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:92)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:190)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:241)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:111)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:21,010] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:21,010] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:21,019] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:21,045] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:21,045] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:21,054] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:35:21,113] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:35:21,121] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:35:21,644] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:35:21,652] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 02:35:21,684] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:21,687] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:21,694] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(old-skul-2) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:21,694] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(old-skul-2) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:21,703] INFO [KafkaServer id=2] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-01-10 02:35:21,704] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:21,707] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(old-skul-1) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:21,710] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:35:21,712] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(old-skul-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:21,713] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:35:21,713] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:35:21,715] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(old-skul-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:21,718] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:35:21,721] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:35:21,727] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:35:21,729] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-01-10 02:35:21,731] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:21,731] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:21,743] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:35:21,744] INFO [Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:35:21,753] INFO [Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:35:21,760] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 02:35:21,764] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:21,914] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:21,914] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:21,925] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:35:21,927] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 11000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:35:21,929] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 02:35:21,935] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:35:21,937] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:35:21,937] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:35:21,939] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:35:21,941] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:35:21,942] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,114] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,114] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,118] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,314] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,314] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,318] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:35:22,324] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 02:35:22,325] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:35:22,325] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:35:22,325] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:35:22,327] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:22,338] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:35:22,342] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:22,343] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:35:22,344] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,476] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,476] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,476] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,515] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,515] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,521] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,676] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,676] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:35:22,776] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 02:35:22,778] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:35:22,839] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-01-10 02:35:22,925] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:35:22,940] WARN [Controller id=2, targetBrokerId=2] Error connecting to node localhost:9093 (id: 2 rack: null) (org.apache.kafka.clients.NetworkClient)
java.nio.channels.ClosedByInterruptException
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(Unknown Source)
	at java.base/sun.nio.ch.SocketChannelImpl.connect(Unknown Source)
	at org.apache.kafka.common.network.Selector.doConnect(Selector.java:273)
	at org.apache.kafka.common.network.Selector.connect(Selector.java:254)
	at org.apache.kafka.clients.NetworkClient.initiateConnect(NetworkClient.java:879)
	at org.apache.kafka.clients.NetworkClient.ready(NetworkClient.java:276)
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:64)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:279)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:233)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-01-10 02:35:22,959] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:35:22,961] INFO Processed session termination for sessionid: 0x1002fdd6a0b0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:35:23,006] INFO Session: 0x1002fdd6a0b0001 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:35:23,006] WARN Unable to read additional data from client sessionid 0x1002fdd6a0b0001, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:35:23,007] INFO EventThread shut down for session: 0x1002fdd6a0b0001 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:35:23,008] INFO Closed socket connection for client /127.0.0.1:61585 which had sessionid 0x1002fdd6a0b0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:35:23,010] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:35:23,020] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:23,371] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:23,371] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:23,373] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:23,377] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:23,377] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:23,378] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:24,372] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:24,372] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:35:24,380] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:35:24,456] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:35:24,462] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:37:41,800] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:37:41,804] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:37:41,805] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:37:41,805] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:37:41,805] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-10 02:37:41,830] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:37:41,831] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-10 02:37:42,362] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,363] INFO Server environment:host.name=192.168.1.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,365] INFO Server environment:java.version=10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,366] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,366] INFO Server environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,367] INFO Server environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,373] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,403] INFO Server environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,404] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,406] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,407] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,408] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,410] INFO Server environment:user.name=AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,411] INFO Server environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,421] INFO Server environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,441] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,442] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,445] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:42,485] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-10 02:37:42,489] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:37:57,568] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:37:58,432] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:37:58,434] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:37:58,467] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:37:58,523] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,523] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,525] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,526] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,526] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,526] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,529] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,529] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,529] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,529] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,530] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,530] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,530] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,530] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,530] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,532] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:37:58,595] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:37:58,597] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:37:58,603] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:37:58,603] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62137 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:37:58,626] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62137 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:58,628] INFO Creating new log file: log.1c3 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-10 02:37:58,707] INFO Established session 0x1002fe520570000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62137 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:37:58,715] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002fe520570000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:37:58,735] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:37:58,840] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0x1 zxid:0x1c4 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:58,876] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0x2 zxid:0x1c5 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:58,928] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0x3 zxid:0x1c6 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:58,976] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0x4 zxid:0x1c7 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:58,993] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0x5 zxid:0x1c8 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:59,017] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0x6 zxid:0x1c9 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:59,047] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0x7 zxid:0x1ca txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:59,073] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0x8 zxid:0x1cb txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:59,092] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0x9 zxid:0x1cc txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:59,117] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0xa zxid:0x1cd txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:59,137] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0xb zxid:0x1ce txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:59,161] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0xc zxid:0x1cf txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:59,181] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:create cxid:0xd zxid:0x1d0 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:37:59,530] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 02:37:59,709] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://192.168.1.6:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:37:59,745] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://192.168.1.6:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:37:59,829] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:37:59,829] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:37:59,834] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:37:59,963] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:38:00,134] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-10 02:38:00,149] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:38:00,256] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:38:00,265] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 224 ms (kafka.log.Log)
[2019-01-10 02:38:00,317] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-10 02:38:00,319] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:38:00,379] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:38:00,385] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-01-10 02:38:00,411] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-10 02:38:00,412] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:38:00,465] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:38:00,470] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-01-10 02:38:00,501] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2019-01-10 02:38:00,503] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:38:00,561] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:38:00,568] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-01-10 02:38:00,586] INFO Logs loading complete in 623 ms. (kafka.log.LogManager)
[2019-01-10 02:38:00,617] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:38:00,620] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:38:01,489] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-01-10 02:38:01,580] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:38:01,666] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:38:01,670] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:38:01,670] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:38:01,707] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:38:01,815] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:38:01,874] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:38:01,876] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(192.168.1.6,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:38:01,973] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:38:01,982] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:38:01,987] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:38:02,067] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:38:02,075] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:38:02,113] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 38 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:38:02,132] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:14000,blockEndProducerId:14999) by writing to Zk with path version 15 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:38:02,272] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:38:02,278] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:38:02,283] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:38:02,446] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:38:02,521] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:38:02,542] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:38:02,620] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:38:02,653] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 02:38:02,715] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:38:02,933] INFO Replica loaded for partition metalingus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:02,953] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:03,005] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:03,028] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:03,041] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:38:03,042] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:multi cxid:0xe5 zxid:0x1d7 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:38:03,079] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:38:03,093] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-0, old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:38:03,108] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:03,108] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:03,115] INFO [Partition old-skul-2 broker=1] old-skul-2 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:38:03,200] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:03,201] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:03,203] INFO [Partition old-skul-0 broker=1] old-skul-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:38:03,235] INFO Got user-level KeeperException when processing sessionid:0x1002fe520570000 type:multi cxid:0xe9 zxid:0x1d9 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:38:03,247] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:03,247] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:38:03,251] INFO [Partition old-skul-1 broker=1] old-skul-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:38:03,310] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:38:03,317] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:38:03,318] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:38:03,325] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:38:03,325] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:38:03,331] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:38:03,331] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:38:03,333] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:38:03,338] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:38:03,398] ERROR Error while renaming dir for metalingus-0 in log dir C:\tmp\kafka-logs-1 (kafka.server.LogDirFailureChannel)
java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.e8711a2c1223416aa01b9f666644b758-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.base/java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:728)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at kafka.log.Log.maybeHandleIOException(Log.scala:1927)
	at kafka.log.Log.renameDir(Log.scala:726)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:842)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:353)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:259)
	at kafka.cluster.Partition.delete(Partition.scala:347)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:350)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:380)
	at scala.collection.Iterator.foreach(Iterator.scala:937)
	at scala.collection.Iterator.foreach$(Iterator.scala:937)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1425)
	at scala.collection.IterableLike.foreach(IterableLike.scala:70)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:69)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:378)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:200)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:111)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.base/java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.e8711a2c1223416aa01b9f666644b758-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.base/java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-01-10 02:38:03,401] INFO [ReplicaManager broker=1] Stopping serving replicas in dir C:\tmp\kafka-logs-1 (kafka.server.ReplicaManager)
[2019-01-10 02:38:03,422] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:38:03,424] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:38:03,441] INFO [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions old-skul-2,old-skul-1,old-skul-0 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs-1. (kafka.server.ReplicaManager)
[2019-01-10 02:38:03,442] INFO Stopping serving logs in dir C:\tmp\kafka-logs-1 (kafka.log.LogManager)
[2019-01-10 02:38:03,450] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:38:03,450] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs-1 have failed (kafka.log.LogManager)
[2019-01-10 02:38:03,451] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:38:03,460] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:38:03,821] WARN Exception causing close of session 0x1002fe520570000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:38:03,823] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62137 which had sessionid 0x1002fe520570000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:38:11,411] INFO Expiring session 0x1002fe520570000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:38:11,413] INFO Processed session termination for sessionid: 0x1002fe520570000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:06,913] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:39:06,921] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:39:06,921] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:39:06,922] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:39:06,923] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-10 02:39:06,954] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:39:06,956] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-10 02:39:07,300] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,301] INFO Server environment:host.name=192.168.1.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,309] INFO Server environment:java.version=10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,312] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,314] INFO Server environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,317] INFO Server environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,330] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,331] INFO Server environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,334] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,368] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,370] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,372] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,373] INFO Server environment:user.name=AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,375] INFO Server environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,376] INFO Server environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,396] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,396] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,398] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:07,436] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-10 02:39:07,442] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:39:18,294] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:39:19,121] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:39:19,124] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:39:19,156] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:39:19,239] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,239] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,242] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,242] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,242] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,243] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,245] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,246] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,246] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,246] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,246] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,246] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,246] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,247] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,247] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,250] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:39:19,308] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:39:19,312] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:39:19,318] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:39:19,318] INFO Accepted socket connection from /127.0.0.1:62173 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:39:19,339] INFO Client attempting to establish new session at /127.0.0.1:62173 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:19,341] INFO Creating new log file: log.1dc (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-10 02:39:19,408] INFO Established session 0x1002fe66c3b0000 with negotiated timeout 6000 for client /127.0.0.1:62173 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:19,417] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002fe66c3b0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:39:19,437] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:39:19,532] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0x1 zxid:0x1dd txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,574] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0x2 zxid:0x1de txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,627] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0x3 zxid:0x1df txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,672] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0x4 zxid:0x1e0 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,726] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0x5 zxid:0x1e1 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,749] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0x6 zxid:0x1e2 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,779] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0x7 zxid:0x1e3 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,804] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0x8 zxid:0x1e4 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,826] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0x9 zxid:0x1e5 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,848] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0xa zxid:0x1e6 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,871] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0xb zxid:0x1e7 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,893] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0xc zxid:0x1e8 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:19,914] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:create cxid:0xd zxid:0x1e9 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:20,246] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 02:39:20,264] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:39:20,425] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://192.168.1.6:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:39:20,455] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://192.168.1.6:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:39:20,531] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:39:20,532] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:39:20,537] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:39:20,620] INFO Log directory C:\tmp\kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2019-01-10 02:39:20,641] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:39:20,671] INFO Logs loading complete in 30 ms. (kafka.log.LogManager)
[2019-01-10 02:39:20,710] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:39:20,719] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:39:21,426] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-01-10 02:39:21,509] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:39:21,560] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:39:21,561] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:39:21,567] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:39:21,601] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:39:21,767] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:39:21,830] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:39:21,834] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(192.168.1.6,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:39:21,839] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:39:21,985] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:39:21,993] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:39:21,993] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:39:22,091] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:39:22,099] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:39:22,120] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:39:22,164] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:15000,blockEndProducerId:15999) by writing to Zk with path version 16 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:39:22,283] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:39:22,289] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:39:22,294] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:39:22,473] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:39:22,500] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:39:22,514] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:39:22,518] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:39:22,522] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 02:39:22,763] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:39:22,838] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-0, old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:39:22,972] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:39:22,977] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:multi cxid:0xdc zxid:0x1ed txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:23,010] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 118 ms (kafka.log.Log)
[2019-01-10 02:39:23,019] INFO Created log for partition old-skul-2 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:39:23,021] INFO [Partition old-skul-2 broker=1] No checkpointed highwatermark is found for partition old-skul-2 (kafka.cluster.Partition)
[2019-01-10 02:39:23,026] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,036] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,037] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,043] INFO [Partition old-skul-2 broker=1] old-skul-2 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:39:23,146] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:39:23,155] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-01-10 02:39:23,159] INFO Created log for partition old-skul-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:39:23,161] INFO [Partition old-skul-0 broker=1] No checkpointed highwatermark is found for partition old-skul-0 (kafka.cluster.Partition)
[2019-01-10 02:39:23,162] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,162] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,163] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,163] INFO [Partition old-skul-0 broker=1] old-skul-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:39:23,247] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:39:23,255] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-10 02:39:23,262] INFO Created log for partition old-skul-1 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:39:23,263] INFO [Partition old-skul-1 broker=1] No checkpointed highwatermark is found for partition old-skul-1 (kafka.cluster.Partition)
[2019-01-10 02:39:23,264] INFO Got user-level KeeperException when processing sessionid:0x1002fe66c3b0000 type:multi cxid:0xe2 zxid:0x1ef txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:39:23,264] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,269] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,270] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,270] INFO [Partition old-skul-1 broker=1] old-skul-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:39:23,352] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:39:23,358] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-01-10 02:39:23,361] INFO Created log for partition metalingus-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:39:23,362] INFO [Partition metalingus-0 broker=1] No checkpointed highwatermark is found for partition metalingus-0 (kafka.cluster.Partition)
[2019-01-10 02:39:23,362] INFO Replica loaded for partition metalingus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:39:23,363] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:39:23,408] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:39:23,415] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:39:23,422] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:39:23,423] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:39:23,429] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:39:23,429] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:39:23,441] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:39:23,441] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:39:23,444] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:39:23,444] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:39:23,529] ERROR Error while renaming dir for metalingus-0 in log dir C:\tmp\kafka-logs-1 (kafka.server.LogDirFailureChannel)
java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.cb54eedba97f4195904eb1e90aa55c06-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.base/java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:728)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at kafka.log.Log.maybeHandleIOException(Log.scala:1927)
	at kafka.log.Log.renameDir(Log.scala:726)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:842)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:353)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:259)
	at kafka.cluster.Partition.delete(Partition.scala:347)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:350)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:380)
	at scala.collection.Iterator.foreach(Iterator.scala:937)
	at scala.collection.Iterator.foreach$(Iterator.scala:937)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1425)
	at scala.collection.IterableLike.foreach(IterableLike.scala:70)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:69)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:378)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:200)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:111)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.base/java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.cb54eedba97f4195904eb1e90aa55c06-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.base/java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-01-10 02:39:23,533] INFO [ReplicaManager broker=1] Stopping serving replicas in dir C:\tmp\kafka-logs-1 (kafka.server.ReplicaManager)
[2019-01-10 02:39:23,552] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:39:23,559] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:39:23,581] INFO [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions old-skul-2,old-skul-1,old-skul-0 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs-1. (kafka.server.ReplicaManager)
[2019-01-10 02:39:23,587] INFO Stopping serving logs in dir C:\tmp\kafka-logs-1 (kafka.log.LogManager)
[2019-01-10 02:39:23,591] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:39:23,591] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:39:23,597] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:39:23,597] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:39:23,610] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs-1 have failed (kafka.log.LogManager)
[2019-01-10 02:39:23,967] WARN Exception causing close of session 0x1002fe66c3b0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:39:23,969] INFO Closed socket connection for client /127.0.0.1:62173 which had sessionid 0x1002fe66c3b0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:39:32,411] INFO Expiring session 0x1002fe66c3b0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:39:32,413] INFO Processed session termination for sessionid: 0x1002fe66c3b0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:08,582] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:42:08,586] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:42:08,586] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:42:08,586] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:42:08,586] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-10 02:42:08,611] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:42:08,612] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-10 02:42:08,868] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,868] INFO Server environment:host.name=192.168.1.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,871] INFO Server environment:java.version=10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,871] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,872] INFO Server environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,872] INFO Server environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,878] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,879] INFO Server environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,881] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,918] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,919] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,920] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,922] INFO Server environment:user.name=AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,923] INFO Server environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,924] INFO Server environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,943] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,943] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,944] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:08,982] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-10 02:42:08,985] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:42:38,929] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:42:39,810] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:42:39,812] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:42:39,841] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:42:39,911] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,912] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,912] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,912] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,913] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,913] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,916] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,917] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,918] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,919] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,920] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,922] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,938] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,940] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,941] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,944] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:42:39,990] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:42:39,992] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:42:39,999] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:42:39,999] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62230 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:42:40,019] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62230 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:40,022] INFO Creating new log file: log.1f2 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-10 02:42:40,182] INFO Established session 0x1002fe9316a0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62230 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:40,191] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002fe9316a0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:42:40,207] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:42:40,304] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0x1 zxid:0x1f3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,344] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0x2 zxid:0x1f4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,369] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0x3 zxid:0x1f5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,386] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0x4 zxid:0x1f6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,405] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0x5 zxid:0x1f7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,421] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0x6 zxid:0x1f8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,445] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0x7 zxid:0x1f9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,487] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0x8 zxid:0x1fa txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,508] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0x9 zxid:0x1fb txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,535] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0xa zxid:0x1fc txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,552] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0xb zxid:0x1fd txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,579] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0xc zxid:0x1fe txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,597] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:create cxid:0xd zxid:0x1ff txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:40,935] INFO Cluster ID = stzFsR1rQFGAW0LR-Vn7CA (kafka.server.KafkaServer)
[2019-01-10 02:42:40,949] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:42:41,122] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:42:41,151] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:42:41,239] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:42:41,239] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:42:41,247] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:42:41,340] INFO Log directory C:\tmp\kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2019-01-10 02:42:41,362] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:42:41,384] INFO Logs loading complete in 21 ms. (kafka.log.LogManager)
[2019-01-10 02:42:41,426] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:42:41,441] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:42:42,180] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2019-01-10 02:42:42,265] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:42:42,326] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:42:42,333] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:42:42,333] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:42:42,383] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:42:42,536] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:42:42,602] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:42:42,607] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:42:42,615] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:42:42,762] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:42:42,772] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:42:42,773] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:42:42,863] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:42:42,870] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:42:42,905] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 36 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:42:42,946] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:16000,blockEndProducerId:16999) by writing to Zk with path version 17 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:42:43,044] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:42:43,050] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:42:43,052] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:42:43,207] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:42:43,255] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:42:43,277] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:42:43,292] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:42:43,328] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 02:42:43,432] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:42:43,560] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-0, old-skul-1) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:42:43,693] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:42:43,750] INFO [Log partition=old-skul-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 121 ms (kafka.log.Log)
[2019-01-10 02:42:43,766] INFO Created log for partition old-skul-2 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:42:43,772] INFO [Partition old-skul-2 broker=1] No checkpointed highwatermark is found for partition old-skul-2 (kafka.cluster.Partition)
[2019-01-10 02:42:43,782] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:43,797] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:43,799] INFO Replica loaded for partition old-skul-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:43,808] INFO [Partition old-skul-2 broker=1] old-skul-2 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:42:43,816] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:multi cxid:0xdc zxid:0x203 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:43,952] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:42:43,959] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-01-10 02:42:43,965] INFO Created log for partition old-skul-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:42:43,966] INFO [Partition old-skul-0 broker=1] No checkpointed highwatermark is found for partition old-skul-0 (kafka.cluster.Partition)
[2019-01-10 02:42:43,974] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:43,975] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:43,976] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:43,977] INFO [Partition old-skul-0 broker=1] old-skul-0 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:42:43,981] INFO Got user-level KeeperException when processing sessionid:0x1002fe9316a0000 type:multi cxid:0xe1 zxid:0x205 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:42:44,046] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:42:44,053] INFO [Log partition=old-skul-1, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-01-10 02:42:44,055] INFO Created log for partition old-skul-1 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:42:44,056] INFO [Partition old-skul-1 broker=1] No checkpointed highwatermark is found for partition old-skul-1 (kafka.cluster.Partition)
[2019-01-10 02:42:44,057] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:44,058] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:44,059] INFO Replica loaded for partition old-skul-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:44,060] INFO [Partition old-skul-1 broker=1] old-skul-1 starts at Leader Epoch 5 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:42:44,144] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:42:44,150] INFO [Log partition=metalingus-0, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-01-10 02:42:44,154] INFO Created log for partition metalingus-0 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:42:44,155] INFO [Partition metalingus-0 broker=1] No checkpointed highwatermark is found for partition metalingus-0 (kafka.cluster.Partition)
[2019-01-10 02:42:44,155] INFO Replica loaded for partition metalingus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:42:44,158] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:42:44,195] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:42:44,201] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: metalingus-0. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:42:44,210] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:42:44,211] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:42:44,219] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:42:44,222] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:42:44,229] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:42:44,230] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:42:44,234] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:42:44,237] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:42:44,312] ERROR Error while renaming dir for metalingus-0 in log dir C:\tmp\kafka-logs-1 (kafka.server.LogDirFailureChannel)
java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.e093ee556da444c8a1f66ecfdec39a9a-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
	at java.base/java.nio.file.Files.move(Unknown Source)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:809)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:728)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at kafka.log.Log.maybeHandleIOException(Log.scala:1927)
	at kafka.log.Log.renameDir(Log.scala:726)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:842)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:353)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:251)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:259)
	at kafka.cluster.Partition.delete(Partition.scala:347)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:350)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:380)
	at scala.collection.Iterator.foreach(Iterator.scala:937)
	at scala.collection.Iterator.foreach$(Iterator.scala:937)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1425)
	at scala.collection.IterableLike.foreach(IterableLike.scala:70)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:69)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:378)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:200)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:111)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.base/java.lang.Thread.run(Unknown Source)
	Suppressed: java.nio.file.AccessDeniedException: C:\tmp\kafka-logs-1\metalingus-0 -> C:\tmp\kafka-logs-1\metalingus-0.e093ee556da444c8a1f66ecfdec39a9a-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileCopy.move(Unknown Source)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(Unknown Source)
		at java.base/java.nio.file.Files.move(Unknown Source)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
		... 22 more
[2019-01-10 02:42:44,317] INFO [ReplicaManager broker=1] Stopping serving replicas in dir C:\tmp\kafka-logs-1 (kafka.server.ReplicaManager)
[2019-01-10 02:42:44,333] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:42:44,340] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(old-skul-2, old-skul-1, old-skul-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:42:44,358] INFO [ReplicaManager broker=1] Broker 1 stopped fetcher for partitions old-skul-2,old-skul-1,old-skul-0 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs-1. (kafka.server.ReplicaManager)
[2019-01-10 02:42:44,363] INFO Stopping serving logs in dir C:\tmp\kafka-logs-1 (kafka.log.LogManager)
[2019-01-10 02:42:44,378] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:42:44,384] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:42:44,383] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs-1 have failed (kafka.log.LogManager)
[2019-01-10 02:42:44,397] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(metalingus-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:42:44,766] WARN Exception causing close of session 0x1002fe9316a0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:42:44,770] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62230 which had sessionid 0x1002fe9316a0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:42:50,410] INFO Expiring session 0x1002fe9316a0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:42:50,412] INFO Processed session termination for sessionid: 0x1002fe9316a0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:44:26,166] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:44:26,171] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:44:26,172] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:44:26,174] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-01-10 02:44:26,175] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-01-10 02:44:26,210] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-01-10 02:44:26,212] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-01-10 02:44:26,555] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,556] INFO Server environment:host.name=192.168.1.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,567] INFO Server environment:java.version=10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,570] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,572] INFO Server environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,582] INFO Server environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,589] INFO Server environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,617] INFO Server environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,619] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,620] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,621] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,622] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,623] INFO Server environment:user.name=AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,625] INFO Server environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,626] INFO Server environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,651] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,651] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,652] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:26,693] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-01-10 02:44:26,700] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:44:38,572] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:44:39,428] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:44:39,431] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:44:39,464] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:44:39,538] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,538] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,545] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,547] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,549] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,551] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,558] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,559] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,562] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,564] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,566] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,589] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,590] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,591] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,592] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,596] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:44:39,654] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:44:39,657] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:44:39,665] INFO Accepted socket connection from /127.0.0.1:62301 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:44:39,665] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:44:39,685] INFO Client attempting to establish new session at /127.0.0.1:62301 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:39,691] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-01-10 02:44:39,777] INFO Established session 0x1002feb4b050000 with negotiated timeout 6000 for client /127.0.0.1:62301 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:44:39,786] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002feb4b050000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:44:39,807] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:44:39,954] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:44:40,167] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:44:40,243] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:44:40,845] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:44:40,976] INFO Cluster ID = 9FPkoAAvTWKM-AdrrQ_WsQ (kafka.server.KafkaServer)
[2019-01-10 02:44:40,990] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:44:41,150] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:44:41,185] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:44:41,252] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:44:41,252] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:44:41,260] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:44:41,321] INFO Log directory C:\tmp\kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2019-01-10 02:44:41,354] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:44:41,376] INFO Logs loading complete in 21 ms. (kafka.log.LogManager)
[2019-01-10 02:44:41,420] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:44:41,433] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:44:42,156] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2019-01-10 02:44:42,231] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:44:42,276] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:44:42,282] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:44:42,283] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:44:42,315] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:44:42,383] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:44:42,455] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:44:42,459] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:44:42,471] WARN No meta.properties file under dir C:\tmp\kafka-logs-1\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:44:42,655] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:44:42,680] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:44:42,680] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:44:42,713] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-01-10 02:44:42,733] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:44:42,737] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:44:42,751] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:44:42,824] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:44:42,915] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:44:42,922] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:44:42,935] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:44:43,046] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:44:43,065] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:44:43,133] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:44:43,173] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050000 type:multi cxid:0x36 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:44:43,182] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:44:43,210] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 02:44:43,264] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050000 type:multi cxid:0x38 zxid:0x1d txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:18,483] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:45:19,829] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:45:19,831] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:45:19,863] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:20,107] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,107] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,111] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,112] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,113] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,114] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,120] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,162] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,164] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,164] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,165] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,166] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,168] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,169] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,169] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,173] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:20,246] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:20,248] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:45:20,256] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62323 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:45:20,257] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:45:20,268] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62323 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:45:20,349] INFO Established session 0x1002feb4b050001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62323 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:45:20,355] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002feb4b050001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:45:20,370] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:20,491] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0x1 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,535] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0x2 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,574] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0x3 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,647] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0x4 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,670] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0x5 zxid:0x23 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,696] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0x6 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,724] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0x7 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,750] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0x8 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,770] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0x9 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,796] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0xa zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,814] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0xb zxid:0x29 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,839] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0xc zxid:0x2a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:20,873] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050001 type:create cxid:0xd zxid:0x2b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:21,290] INFO Cluster ID = 9FPkoAAvTWKM-AdrrQ_WsQ (kafka.server.KafkaServer)
[2019-01-10 02:45:21,314] WARN No meta.properties file under dir C:\tmp\kafka-logs-2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:45:21,517] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:45:21,554] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:45:21,637] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:21,662] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:21,662] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:21,736] INFO Log directory C:\tmp\kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2019-01-10 02:45:21,770] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:45:21,815] INFO Logs loading complete in 44 ms. (kafka.log.LogManager)
[2019-01-10 02:45:21,872] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:45:21,885] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:45:23,330] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Socket server failed to bind to localhost:9092: Address already in use: bind.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:450)
	at kafka.network.Acceptor.<init>(SocketServer.scala:340)
	at kafka.network.SocketServer.$anonfun$createAcceptorAndProcessors$1(SocketServer.scala:146)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:58)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:51)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at kafka.network.SocketServer.createAcceptorAndProcessors(SocketServer.scala:142)
	at kafka.network.SocketServer.startup(SocketServer.scala:91)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:250)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:75)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.BindException: Address already in use: bind
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Unknown Source)
	at java.base/sun.nio.ch.Net.bind(Unknown Source)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:446)
	... 11 more
[2019-01-10 02:45:23,348] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:45:23,367] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:45:23,384] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:45:23,401] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:45:23,493] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:45:23,495] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:23,501] INFO Processed session termination for sessionid: 0x1002feb4b050001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:23,558] INFO Session: 0x1002feb4b050001 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:23,559] WARN Unable to read additional data from client sessionid 0x1002feb4b050001, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:45:23,565] INFO EventThread shut down for session: 0x1002feb4b050001 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:45:23,568] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62323 which had sessionid 0x1002feb4b050001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:45:23,572] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:23,582] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:23,689] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:23,696] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:23,689] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:24,705] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:24,705] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:24,713] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:25,697] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:25,697] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:25,712] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:45:25,819] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:45:25,839] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:45:25,841] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-01-10 02:45:25,855] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:45:31,738] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:45:32,678] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:45:32,680] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:45:32,708] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:32,786] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,786] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,789] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,790] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,791] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,793] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,799] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,835] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,837] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,839] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,844] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,850] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,852] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,853] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,854] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,857] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:32,909] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:32,911] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:45:32,919] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:45:32,918] INFO Accepted socket connection from /127.0.0.1:62331 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:45:32,931] INFO Client attempting to establish new session at /127.0.0.1:62331 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:45:33,017] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002feb4b050002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:45:33,014] INFO Established session 0x1002feb4b050002 with negotiated timeout 6000 for client /127.0.0.1:62331 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:45:33,036] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:33,132] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0x1 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,177] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0x2 zxid:0x2f txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,238] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0x3 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,289] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0x4 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,315] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0x5 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,333] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0x6 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,367] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0x7 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,404] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0x8 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,428] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0x9 zxid:0x36 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,461] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0xa zxid:0x37 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,480] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0xb zxid:0x38 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,512] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0xc zxid:0x39 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,535] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050002 type:create cxid:0xd zxid:0x3a txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:33,966] INFO Cluster ID = 9FPkoAAvTWKM-AdrrQ_WsQ (kafka.server.KafkaServer)
[2019-01-10 02:45:33,997] WARN No meta.properties file under dir C:\tmp\kafka-logs-3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:45:34,228] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:45:34,265] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:45:34,352] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:34,352] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:34,361] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:34,439] INFO Log directory C:\tmp\kafka-logs-3 not found, creating it. (kafka.log.LogManager)
[2019-01-10 02:45:34,470] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:45:34,501] INFO Logs loading complete in 31 ms. (kafka.log.LogManager)
[2019-01-10 02:45:34,555] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:45:34,569] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:45:35,488] ERROR [KafkaServer id=3] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Socket server failed to bind to 0.0.0.0:9092: Address already in use: bind.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:450)
	at kafka.network.Acceptor.<init>(SocketServer.scala:340)
	at kafka.network.SocketServer.$anonfun$createAcceptorAndProcessors$1(SocketServer.scala:146)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:58)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:51)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at kafka.network.SocketServer.createAcceptorAndProcessors(SocketServer.scala:142)
	at kafka.network.SocketServer.startup(SocketServer.scala:91)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:250)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:75)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.BindException: Address already in use: bind
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Unknown Source)
	at java.base/sun.nio.ch.Net.bind(Unknown Source)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:446)
	... 11 more
[2019-01-10 02:45:35,516] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:45:35,522] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:45:35,536] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:45:35,553] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:45:35,625] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:45:35,630] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:35,635] INFO Processed session termination for sessionid: 0x1002feb4b050002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:45:35,693] INFO Session: 0x1002feb4b050002 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:45:35,694] INFO Closed socket connection for client /127.0.0.1:62331 which had sessionid 0x1002feb4b050002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:45:35,697] INFO EventThread shut down for session: 0x1002feb4b050002 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:45:35,707] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:45:35,715] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:36,365] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:36,365] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:36,369] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:37,364] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:37,364] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:37,371] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:38,373] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:38,373] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:45:38,392] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:45:38,504] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:45:38,524] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:45:38,526] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-01-10 02:45:38,534] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:47:03,107] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:47:04,089] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:47:04,092] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:47:04,130] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:47:04,458] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,458] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,468] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,471] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,473] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,476] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,492] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,515] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,519] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,520] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,521] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,522] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,524] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,532] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,533] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,537] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:04,584] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:47:04,593] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:47:04,598] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:47:04,597] INFO Accepted socket connection from /127.0.0.1:62352 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:47:04,607] INFO Client attempting to establish new session at /127.0.0.1:62352 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:47:04,663] INFO Established session 0x1002feb4b050003 with negotiated timeout 6000 for client /127.0.0.1:62352 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:47:04,667] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002feb4b050003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:47:04,677] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:47:04,757] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0x1 zxid:0x3d txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:04,802] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0x2 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:04,869] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0x3 zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:04,929] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0x4 zxid:0x40 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:04,962] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0x5 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:05,052] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0x6 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:05,093] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0x7 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:05,127] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0x8 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:05,151] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0x9 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:05,172] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0xa zxid:0x46 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:05,196] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0xb zxid:0x47 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:05,217] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0xc zxid:0x48 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:05,240] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:create cxid:0xd zxid:0x49 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:05,640] INFO Cluster ID = 9FPkoAAvTWKM-AdrrQ_WsQ (kafka.server.KafkaServer)
[2019-01-10 02:47:05,661] WARN No meta.properties file under dir C:\tmp\kafka-logs-2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:47:05,868] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:47:05,897] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:47:05,987] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:05,991] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:05,987] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:06,073] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:47:06,103] INFO Logs loading complete in 30 ms. (kafka.log.LogManager)
[2019-01-10 02:47:06,148] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:47:06,161] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:47:06,994] INFO Awaiting socket connections on localhost:9093. (kafka.network.Acceptor)
[2019-01-10 02:47:07,080] INFO [SocketServer brokerId=2] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:47:07,141] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:47:07,149] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:47:07,149] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:47:07,188] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:47:07,376] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:47:07,400] INFO Result of znode creation at /brokers/ids/2 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:47:07,411] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(localhost,9093,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:47:07,428] WARN No meta.properties file under dir C:\tmp\kafka-logs-2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:47:07,588] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:47:07,607] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:47:07,607] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:47:07,639] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:47:07,642] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:47:07,657] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:47:07,714] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:47:07,778] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:47:07,787] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:47:07,792] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:47:07,903] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:47:07,928] INFO [SocketServer brokerId=2] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:47:07,944] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:47:07,946] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:47:07,960] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-01-10 02:47:15,261] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:47:16,244] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:47:16,246] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:47:16,287] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:47:16,362] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,363] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,372] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,375] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,377] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,379] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,395] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,397] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,404] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,428] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,429] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,432] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,433] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,435] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,436] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,439] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:16,500] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:47:16,502] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:47:16,510] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62370 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:47:16,510] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:47:16,525] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62370 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:47:16,553] INFO Established session 0x1002feb4b050004 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62370 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:47:16,556] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002feb4b050004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:47:16,566] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:47:16,653] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0x1 zxid:0x4d txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:16,700] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0x2 zxid:0x4e txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:16,776] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0x3 zxid:0x4f txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:16,819] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0x4 zxid:0x50 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:16,872] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0x5 zxid:0x51 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:16,898] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0x6 zxid:0x52 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:16,927] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0x7 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:16,950] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0x8 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:16,973] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0x9 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:16,995] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0xa zxid:0x56 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:17,017] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0xb zxid:0x57 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:17,039] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0xc zxid:0x58 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:17,061] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050004 type:create cxid:0xd zxid:0x59 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:17,506] INFO Cluster ID = 9FPkoAAvTWKM-AdrrQ_WsQ (kafka.server.KafkaServer)
[2019-01-10 02:47:17,539] WARN No meta.properties file under dir C:\tmp\kafka-logs-3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:47:17,739] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:47:17,776] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:47:17,870] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:17,877] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:17,882] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:17,979] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:47:18,010] INFO Logs loading complete in 31 ms. (kafka.log.LogManager)
[2019-01-10 02:47:18,058] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:47:18,072] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:47:19,000] ERROR [KafkaServer id=3] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Socket server failed to bind to 0.0.0.0:9092: Address already in use: bind.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:450)
	at kafka.network.Acceptor.<init>(SocketServer.scala:340)
	at kafka.network.SocketServer.$anonfun$createAcceptorAndProcessors$1(SocketServer.scala:146)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:58)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:51)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at kafka.network.SocketServer.createAcceptorAndProcessors(SocketServer.scala:142)
	at kafka.network.SocketServer.startup(SocketServer.scala:91)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:250)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:75)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.BindException: Address already in use: bind
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Unknown Source)
	at java.base/sun.nio.ch.Net.bind(Unknown Source)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(Unknown Source)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:446)
	... 11 more
[2019-01-10 02:47:19,021] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:47:19,028] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:47:19,040] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:47:19,058] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:47:19,131] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:47:19,136] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:47:19,145] INFO Processed session termination for sessionid: 0x1002feb4b050004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:47:19,220] INFO Session: 0x1002feb4b050004 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:47:19,221] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62370 which had sessionid 0x1002feb4b050004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:47:19,224] INFO EventThread shut down for session: 0x1002feb4b050004 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:47:19,227] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:47:19,237] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:19,881] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:19,881] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:19,887] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:20,888] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:20,888] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:20,892] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:21,889] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:21,889] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:47:21,896] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:47:22,014] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:47:22,031] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:47:22,033] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-01-10 02:47:22,045] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:48:05,395] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:48:06,313] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:48:06,315] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:48:06,353] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:48:06,706] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,707] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,717] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,719] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,721] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,733] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,748] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,770] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,771] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,773] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,774] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,777] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,778] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,786] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,787] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,790] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:48:06,835] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:48:06,837] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:48:06,849] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:48:06,849] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:62381 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:48:06,857] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:62381 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:48:06,945] INFO Established session 0x1002feb4b050005 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:62381 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:48:06,953] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1002feb4b050005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:48:06,980] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:48:07,068] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0x1 zxid:0x5c txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,145] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0x2 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,231] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0x3 zxid:0x5e txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,318] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0x4 zxid:0x5f txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,351] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0x5 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,386] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0x6 zxid:0x61 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,417] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0x7 zxid:0x62 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,442] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0x8 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,463] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0x9 zxid:0x64 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,486] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0xa zxid:0x65 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,507] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0xb zxid:0x66 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,530] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0xc zxid:0x67 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,551] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:create cxid:0xd zxid:0x68 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:48:07,963] INFO Cluster ID = 9FPkoAAvTWKM-AdrrQ_WsQ (kafka.server.KafkaServer)
[2019-01-10 02:48:07,975] WARN No meta.properties file under dir C:\tmp\kafka-logs-3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:48:08,129] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:48:08,169] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:48:08,274] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:48:08,274] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:48:08,274] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:48:08,362] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:48:08,388] INFO Logs loading complete in 26 ms. (kafka.log.LogManager)
[2019-01-10 02:48:08,444] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:48:08,453] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:48:09,251] INFO Awaiting socket connections on localhost:9094. (kafka.network.Acceptor)
[2019-01-10 02:48:09,337] INFO [SocketServer brokerId=3] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:48:09,390] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:48:09,399] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:48:09,399] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:48:09,489] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:48:09,713] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:48:09,778] INFO Result of znode creation at /brokers/ids/3 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:48:09,785] INFO Registered broker 3 at path /brokers/ids/3 with addresses: ArrayBuffer(EndPoint(localhost,9094,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:48:09,801] WARN No meta.properties file under dir C:\tmp\kafka-logs-3\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-01-10 02:48:09,956] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:48:09,963] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:48:09,962] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:48:10,002] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:48:10,004] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:48:10,022] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:48:10,090] INFO [ProducerId Manager 3]: Acquired new producerId block (brokerId:3,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:48:10,155] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:48:10,179] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:48:10,179] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:48:10,279] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:48:10,304] INFO [SocketServer brokerId=3] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:48:10,322] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:48:10,323] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:48:10,333] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2019-01-10 02:49:49,971] INFO Accepted socket connection from /127.0.0.1:62425 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:49,992] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:49,993] INFO Closed socket connection for client /127.0.0.1:62425 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:50,057] INFO Accepted socket connection from /127.0.0.1:62426 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:50,058] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:50,061] INFO Closed socket connection for client /127.0.0.1:62426 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:50,220] INFO Accepted socket connection from /127.0.0.1:62427 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:50,222] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:50,227] INFO Closed socket connection for client /127.0.0.1:62427 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:50,436] INFO Accepted socket connection from /127.0.0.1:62429 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:50,448] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:50,449] INFO Closed socket connection for client /127.0.0.1:62429 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:50,913] INFO Accepted socket connection from /127.0.0.1:62430 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:50,913] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:50,917] INFO Closed socket connection for client /127.0.0.1:62430 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:51,686] INFO Accepted socket connection from /127.0.0.1:62431 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:51,687] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:51,691] INFO Closed socket connection for client /127.0.0.1:62431 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:52,716] INFO Accepted socket connection from /127.0.0.1:62432 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:52,717] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:52,720] INFO Closed socket connection for client /127.0.0.1:62432 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:53,834] INFO Accepted socket connection from /127.0.0.1:62433 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:53,837] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:53,844] INFO Closed socket connection for client /127.0.0.1:62433 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:55,012] INFO Accepted socket connection from /127.0.0.1:62435 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:55,013] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:55,018] INFO Closed socket connection for client /127.0.0.1:62435 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:56,236] INFO Accepted socket connection from /127.0.0.1:62436 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:56,237] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:56,243] INFO Closed socket connection for client /127.0.0.1:62436 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:57,107] INFO Accepted socket connection from /127.0.0.1:62437 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:57,108] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:57,113] INFO Closed socket connection for client /127.0.0.1:62437 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:58,076] INFO Accepted socket connection from /127.0.0.1:62438 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:58,078] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:58,081] INFO Closed socket connection for client /127.0.0.1:62438 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:58,942] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050000 type:setData cxid:0x4b zxid:0x6b txntype:-1 reqpath:n/a Error Path:/config/topics/old-skul Error:KeeperErrorCode = NoNode for /config/topics/old-skul (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:49:58,993] INFO Topic creation Map(old-skul-0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)
[2019-01-10 02:49:59,002] INFO Accepted socket connection from /127.0.0.1:62442 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:59,004] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:59,009] INFO Closed socket connection for client /127.0.0.1:62442 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:59,028] INFO [KafkaApi-1] Auto creation of topic old-skul with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-01-10 02:49:59,247] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(old-skul-0) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:49:59,395] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:49:59,418] INFO [Log partition=old-skul-0, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2019-01-10 02:49:59,427] INFO Created log for partition old-skul-0 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:49:59,429] INFO [Partition old-skul-0 broker=2] No checkpointed highwatermark is found for partition old-skul-0 (kafka.cluster.Partition)
[2019-01-10 02:49:59,435] INFO Replica loaded for partition old-skul-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:49:59,452] INFO [Partition old-skul-0 broker=2] old-skul-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:49:59,977] INFO Accepted socket connection from /127.0.0.1:62446 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:49:59,978] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:49:59,987] INFO Closed socket connection for client /127.0.0.1:62446 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:01,107] INFO Accepted socket connection from /127.0.0.1:62448 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:01,108] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:01,118] INFO Closed socket connection for client /127.0.0.1:62448 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:02,232] INFO Accepted socket connection from /127.0.0.1:62449 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:02,234] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:02,241] INFO Closed socket connection for client /127.0.0.1:62449 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:03,204] INFO Accepted socket connection from /127.0.0.1:62451 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:03,205] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:03,212] INFO Closed socket connection for client /127.0.0.1:62451 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:04,328] INFO Accepted socket connection from /127.0.0.1:62452 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:04,329] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:04,336] INFO Closed socket connection for client /127.0.0.1:62452 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:05,253] INFO Accepted socket connection from /127.0.0.1:62453 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:05,255] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:05,261] INFO Closed socket connection for client /127.0.0.1:62453 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:06,327] INFO Accepted socket connection from /127.0.0.1:62454 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:06,328] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:06,338] INFO Closed socket connection for client /127.0.0.1:62454 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:07,506] INFO Accepted socket connection from /127.0.0.1:62455 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:07,507] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:07,514] INFO Closed socket connection for client /127.0.0.1:62455 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:08,529] INFO Accepted socket connection from /127.0.0.1:62457 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:08,530] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:08,536] INFO Closed socket connection for client /127.0.0.1:62457 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:09,556] INFO Accepted socket connection from /127.0.0.1:62458 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:09,558] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:09,565] INFO Closed socket connection for client /127.0.0.1:62458 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:10,476] INFO Accepted socket connection from /127.0.0.1:62459 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:10,477] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:10,479] INFO Closed socket connection for client /127.0.0.1:62459 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:11,643] INFO Accepted socket connection from /127.0.0.1:62461 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:11,644] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:11,651] INFO Closed socket connection for client /127.0.0.1:62461 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:12,567] INFO Accepted socket connection from /127.0.0.1:62462 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:12,570] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:12,579] INFO Closed socket connection for client /127.0.0.1:62462 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:13,500] INFO Accepted socket connection from /127.0.0.1:62463 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:13,501] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:13,508] INFO Closed socket connection for client /127.0.0.1:62463 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:14,570] INFO Accepted socket connection from /127.0.0.1:62465 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:14,571] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:14,577] INFO Closed socket connection for client /127.0.0.1:62465 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:15,690] INFO Accepted socket connection from /127.0.0.1:62466 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:15,692] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:15,699] INFO Closed socket connection for client /127.0.0.1:62466 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:16,714] INFO Accepted socket connection from /127.0.0.1:62467 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:16,716] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:16,724] INFO Closed socket connection for client /127.0.0.1:62467 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:17,841] INFO Accepted socket connection from /127.0.0.1:62468 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:17,842] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:17,850] INFO Closed socket connection for client /127.0.0.1:62468 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:18,967] INFO Accepted socket connection from /127.0.0.1:62469 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:18,970] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:18,984] INFO Closed socket connection for client /127.0.0.1:62469 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:19,900] INFO Accepted socket connection from /127.0.0.1:62470 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:19,901] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:19,908] INFO Closed socket connection for client /127.0.0.1:62470 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:20,874] INFO Accepted socket connection from /127.0.0.1:62473 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:20,876] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:20,881] INFO Closed socket connection for client /127.0.0.1:62473 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:22,050] INFO Accepted socket connection from /127.0.0.1:62474 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:22,051] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:22,058] INFO Closed socket connection for client /127.0.0.1:62474 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:23,024] INFO Accepted socket connection from /127.0.0.1:62476 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:23,025] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:23,030] INFO Closed socket connection for client /127.0.0.1:62476 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:24,148] INFO Accepted socket connection from /127.0.0.1:62477 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:24,149] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:24,157] INFO Closed socket connection for client /127.0.0.1:62477 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:25,171] INFO Accepted socket connection from /127.0.0.1:62478 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:25,172] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:25,179] INFO Closed socket connection for client /127.0.0.1:62478 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:26,143] INFO Accepted socket connection from /127.0.0.1:62480 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:26,144] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:26,152] INFO Closed socket connection for client /127.0.0.1:62480 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:27,318] INFO Accepted socket connection from /127.0.0.1:62483 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:27,319] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:27,326] INFO Closed socket connection for client /127.0.0.1:62483 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:28,238] INFO Accepted socket connection from /127.0.0.1:62484 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:28,239] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:28,247] INFO Closed socket connection for client /127.0.0.1:62484 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:29,160] INFO Accepted socket connection from /127.0.0.1:62485 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:29,161] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:29,168] INFO Closed socket connection for client /127.0.0.1:62485 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:30,031] INFO Accepted socket connection from /127.0.0.1:62486 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:30,032] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:30,041] INFO Closed socket connection for client /127.0.0.1:62486 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:31,005] INFO Accepted socket connection from /127.0.0.1:62497 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:31,007] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:31,015] INFO Closed socket connection for client /127.0.0.1:62497 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:32,083] INFO Accepted socket connection from /127.0.0.1:62499 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:32,084] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:32,090] INFO Closed socket connection for client /127.0.0.1:62499 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:33,206] INFO Accepted socket connection from /127.0.0.1:62501 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:33,208] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:33,214] INFO Closed socket connection for client /127.0.0.1:62501 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:34,330] INFO Accepted socket connection from /127.0.0.1:62502 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:34,331] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:34,339] INFO Closed socket connection for client /127.0.0.1:62502 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:35,355] INFO Accepted socket connection from /127.0.0.1:62503 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:35,356] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:35,364] INFO Closed socket connection for client /127.0.0.1:62503 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:36,483] INFO Accepted socket connection from /127.0.0.1:62504 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:36,484] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:36,492] INFO Closed socket connection for client /127.0.0.1:62504 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:37,455] INFO Accepted socket connection from /127.0.0.1:62505 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:37,456] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:37,461] INFO Closed socket connection for client /127.0.0.1:62505 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:38,474] INFO Accepted socket connection from /127.0.0.1:62506 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:38,476] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:38,482] INFO Closed socket connection for client /127.0.0.1:62506 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:39,703] INFO Accepted socket connection from /127.0.0.1:62507 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:39,704] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:39,712] INFO Closed socket connection for client /127.0.0.1:62507 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:40,881] INFO Accepted socket connection from /127.0.0.1:62508 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:40,882] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:40,890] INFO Closed socket connection for client /127.0.0.1:62508 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:42,057] INFO Accepted socket connection from /127.0.0.1:62509 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:42,058] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:42,065] INFO Closed socket connection for client /127.0.0.1:62509 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:43,234] INFO Accepted socket connection from /127.0.0.1:62511 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:43,235] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:43,244] INFO Closed socket connection for client /127.0.0.1:62511 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:44,108] INFO Accepted socket connection from /127.0.0.1:62512 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:44,109] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:44,117] INFO Closed socket connection for client /127.0.0.1:62512 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:45,266] INFO Accepted socket connection from /127.0.0.1:62513 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:45,267] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:45,274] INFO Closed socket connection for client /127.0.0.1:62513 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:46,390] INFO Accepted socket connection from /127.0.0.1:62514 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:46,391] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:46,398] INFO Closed socket connection for client /127.0.0.1:62514 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:47,415] INFO Accepted socket connection from /127.0.0.1:62515 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:47,417] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:47,427] INFO Closed socket connection for client /127.0.0.1:62515 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:48,289] INFO Accepted socket connection from /127.0.0.1:62516 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:48,290] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:48,296] INFO Closed socket connection for client /127.0.0.1:62516 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:49,514] INFO Accepted socket connection from /127.0.0.1:62517 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:49,515] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:49,523] INFO Closed socket connection for client /127.0.0.1:62517 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:50,691] INFO Accepted socket connection from /127.0.0.1:62518 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:50:50,693] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:50:50,698] INFO Closed socket connection for client /127.0.0.1:62518 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:04,949] INFO Accepted socket connection from /127.0.0.1:62523 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:04,975] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:04,976] INFO Closed socket connection for client /127.0.0.1:62523 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:05,041] INFO Accepted socket connection from /127.0.0.1:62524 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:05,043] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:05,045] INFO Closed socket connection for client /127.0.0.1:62524 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:05,151] INFO Accepted socket connection from /127.0.0.1:62525 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:05,153] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:05,156] INFO Closed socket connection for client /127.0.0.1:62525 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:05,374] INFO Accepted socket connection from /127.0.0.1:62526 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:05,384] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:05,384] INFO Closed socket connection for client /127.0.0.1:62526 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:05,795] INFO Accepted socket connection from /127.0.0.1:62527 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:05,797] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:05,800] INFO Closed socket connection for client /127.0.0.1:62527 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:06,518] INFO Accepted socket connection from /127.0.0.1:62528 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:06,519] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:06,523] INFO Closed socket connection for client /127.0.0.1:62528 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:07,343] INFO Accepted socket connection from /127.0.0.1:62529 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:07,344] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:07,354] INFO Closed socket connection for client /127.0.0.1:62529 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:08,316] INFO Accepted socket connection from /127.0.0.1:62530 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:08,321] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:08,327] INFO Closed socket connection for client /127.0.0.1:62530 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:09,191] INFO Accepted socket connection from /127.0.0.1:62531 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:09,193] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:09,199] INFO Closed socket connection for client /127.0.0.1:62531 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:10,215] INFO Accepted socket connection from /127.0.0.1:62533 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:10,216] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:10,225] INFO Closed socket connection for client /127.0.0.1:62533 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:11,191] INFO Accepted socket connection from /127.0.0.1:62534 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:11,192] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:11,201] INFO Closed socket connection for client /127.0.0.1:62534 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:12,366] INFO Accepted socket connection from /127.0.0.1:62536 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:12,367] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:12,375] INFO Closed socket connection for client /127.0.0.1:62536 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:13,390] INFO Accepted socket connection from /127.0.0.1:62537 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:13,392] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:13,399] INFO Closed socket connection for client /127.0.0.1:62537 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:14,516] INFO Accepted socket connection from /127.0.0.1:62538 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:14,517] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:14,523] INFO Closed socket connection for client /127.0.0.1:62538 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:15,540] INFO Accepted socket connection from /127.0.0.1:62539 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:15,540] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:15,544] INFO Closed socket connection for client /127.0.0.1:62539 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:16,713] INFO Accepted socket connection from /127.0.0.1:62540 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:16,714] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:16,720] INFO Closed socket connection for client /127.0.0.1:62540 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:17,834] INFO Accepted socket connection from /127.0.0.1:62541 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:17,835] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:17,843] INFO Closed socket connection for client /127.0.0.1:62541 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:18,959] INFO Accepted socket connection from /127.0.0.1:62542 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:18,960] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:18,968] INFO Closed socket connection for client /127.0.0.1:62542 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:19,831] INFO Accepted socket connection from /127.0.0.1:62543 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:19,833] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:19,841] INFO Closed socket connection for client /127.0.0.1:62543 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:21,008] INFO Accepted socket connection from /127.0.0.1:62544 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:21,009] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:21,019] INFO Closed socket connection for client /127.0.0.1:62544 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:21,883] INFO Accepted socket connection from /127.0.0.1:62545 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:21,886] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:21,892] INFO Closed socket connection for client /127.0.0.1:62545 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:22,756] INFO Accepted socket connection from /127.0.0.1:62546 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:22,757] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:22,764] INFO Closed socket connection for client /127.0.0.1:62546 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:23,679] INFO Accepted socket connection from /127.0.0.1:62547 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:23,680] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:23,688] INFO Closed socket connection for client /127.0.0.1:62547 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:24,551] INFO Accepted socket connection from /127.0.0.1:62548 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:24,552] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:24,560] INFO Closed socket connection for client /127.0.0.1:62548 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:25,627] INFO Accepted socket connection from /127.0.0.1:62551 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:25,630] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:25,641] INFO Closed socket connection for client /127.0.0.1:62551 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:26,605] INFO Accepted socket connection from /127.0.0.1:62552 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:26,608] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:26,612] INFO Closed socket connection for client /127.0.0.1:62552 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:27,783] INFO Accepted socket connection from /127.0.0.1:62553 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:27,784] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:27,791] INFO Closed socket connection for client /127.0.0.1:62553 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:28,707] INFO Accepted socket connection from /127.0.0.1:62554 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:28,709] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:28,719] INFO Closed socket connection for client /127.0.0.1:62554 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:29,782] INFO Accepted socket connection from /127.0.0.1:62555 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:29,783] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:29,790] INFO Closed socket connection for client /127.0.0.1:62555 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:30,904] INFO Accepted socket connection from /127.0.0.1:62557 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:30,906] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:30,911] INFO Closed socket connection for client /127.0.0.1:62557 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:31,776] INFO Accepted socket connection from /127.0.0.1:62558 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:31,777] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:31,786] INFO Closed socket connection for client /127.0.0.1:62558 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:32,648] INFO Accepted socket connection from /127.0.0.1:62559 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:32,652] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:32,660] INFO Closed socket connection for client /127.0.0.1:62559 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:33,775] INFO Accepted socket connection from /127.0.0.1:62561 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:33,776] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:33,785] INFO Closed socket connection for client /127.0.0.1:62561 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:34,851] INFO Accepted socket connection from /127.0.0.1:62562 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:34,852] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:34,859] INFO Closed socket connection for client /127.0.0.1:62562 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:35,775] INFO Accepted socket connection from /127.0.0.1:62563 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:35,776] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:35,780] INFO Closed socket connection for client /127.0.0.1:62563 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:36,645] INFO Accepted socket connection from /127.0.0.1:62564 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:36,646] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:36,654] INFO Closed socket connection for client /127.0.0.1:62564 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:37,770] INFO Accepted socket connection from /127.0.0.1:62565 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:37,771] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:37,788] INFO Closed socket connection for client /127.0.0.1:62565 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:38,699] INFO Accepted socket connection from /127.0.0.1:62567 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:38,700] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:38,704] INFO Closed socket connection for client /127.0.0.1:62567 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:39,716] INFO Accepted socket connection from /127.0.0.1:62568 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:39,717] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:39,724] INFO Closed socket connection for client /127.0.0.1:62568 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:40,893] INFO Accepted socket connection from /127.0.0.1:62569 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:40,894] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:40,900] INFO Closed socket connection for client /127.0.0.1:62569 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:42,066] INFO Accepted socket connection from /127.0.0.1:62572 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:42,068] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:42,075] INFO Closed socket connection for client /127.0.0.1:62572 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:43,140] INFO Accepted socket connection from /127.0.0.1:62573 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:43,141] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:43,149] INFO Closed socket connection for client /127.0.0.1:62573 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:44,159] INFO Accepted socket connection from /127.0.0.1:62574 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:44,161] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:44,165] INFO Closed socket connection for client /127.0.0.1:62574 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:45,031] INFO Accepted socket connection from /127.0.0.1:62575 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:45,032] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:45,039] INFO Closed socket connection for client /127.0.0.1:62575 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:46,205] INFO Accepted socket connection from /127.0.0.1:62576 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:46,206] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:46,210] INFO Closed socket connection for client /127.0.0.1:62576 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:47,330] INFO Accepted socket connection from /127.0.0.1:62577 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:47,332] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:47,341] INFO Closed socket connection for client /127.0.0.1:62577 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:48,406] INFO Accepted socket connection from /127.0.0.1:62581 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:48,407] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:48,413] INFO Closed socket connection for client /127.0.0.1:62581 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:49,538] INFO Accepted socket connection from /127.0.0.1:62582 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:49,543] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:49,546] INFO Closed socket connection for client /127.0.0.1:62582 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:50,667] INFO Accepted socket connection from /127.0.0.1:62583 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:50,668] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:50,672] INFO Closed socket connection for client /127.0.0.1:62583 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:51,541] INFO Accepted socket connection from /127.0.0.1:62585 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:51,542] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:51,546] INFO Closed socket connection for client /127.0.0.1:62585 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:52,358] INFO Accepted socket connection from /127.0.0.1:62586 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:52,361] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:52,369] INFO Closed socket connection for client /127.0.0.1:62586 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:53,483] INFO Accepted socket connection from /127.0.0.1:62587 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:53,484] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:53,488] INFO Closed socket connection for client /127.0.0.1:62587 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:54,554] INFO Accepted socket connection from /127.0.0.1:62589 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:54,556] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:54,563] INFO Closed socket connection for client /127.0.0.1:62589 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:55,578] INFO Accepted socket connection from /127.0.0.1:62590 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:55,579] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:55,589] INFO Closed socket connection for client /127.0.0.1:62590 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:56,504] INFO Accepted socket connection from /127.0.0.1:62591 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:56,506] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:56,514] INFO Closed socket connection for client /127.0.0.1:62591 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:57,377] INFO Accepted socket connection from /127.0.0.1:62592 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:57,378] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:57,386] INFO Closed socket connection for client /127.0.0.1:62592 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:58,350] INFO Accepted socket connection from /127.0.0.1:62593 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:51:58,351] WARN Exception causing close of session 0x0: null (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:51:58,358] INFO Closed socket connection for client /127.0.0.1:62593 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:52:09,496] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050000 type:setData cxid:0x59 zxid:0x71 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:52:09,541] INFO Topic creation Map(__consumer_offsets-22 -> ArrayBuffer(3), __consumer_offsets-30 -> ArrayBuffer(2), __consumer_offsets-8 -> ArrayBuffer(1), __consumer_offsets-21 -> ArrayBuffer(2), __consumer_offsets-4 -> ArrayBuffer(3), __consumer_offsets-27 -> ArrayBuffer(2), __consumer_offsets-7 -> ArrayBuffer(3), __consumer_offsets-9 -> ArrayBuffer(2), __consumer_offsets-46 -> ArrayBuffer(3), __consumer_offsets-25 -> ArrayBuffer(3), __consumer_offsets-35 -> ArrayBuffer(1), __consumer_offsets-41 -> ArrayBuffer(1), __consumer_offsets-33 -> ArrayBuffer(2), __consumer_offsets-23 -> ArrayBuffer(1), __consumer_offsets-49 -> ArrayBuffer(3), __consumer_offsets-47 -> ArrayBuffer(1), __consumer_offsets-16 -> ArrayBuffer(3), __consumer_offsets-28 -> ArrayBuffer(3), __consumer_offsets-31 -> ArrayBuffer(3), __consumer_offsets-36 -> ArrayBuffer(2), __consumer_offsets-42 -> ArrayBuffer(2), __consumer_offsets-3 -> ArrayBuffer(2), __consumer_offsets-18 -> ArrayBuffer(2), __consumer_offsets-37 -> ArrayBuffer(3), __consumer_offsets-15 -> ArrayBuffer(2), __consumer_offsets-24 -> ArrayBuffer(2), __consumer_offsets-38 -> ArrayBuffer(1), __consumer_offsets-17 -> ArrayBuffer(1), __consumer_offsets-48 -> ArrayBuffer(2), __consumer_offsets-19 -> ArrayBuffer(3), __consumer_offsets-11 -> ArrayBuffer(1), __consumer_offsets-13 -> ArrayBuffer(3), __consumer_offsets-2 -> ArrayBuffer(1), __consumer_offsets-43 -> ArrayBuffer(3), __consumer_offsets-6 -> ArrayBuffer(2), __consumer_offsets-14 -> ArrayBuffer(1), __consumer_offsets-20 -> ArrayBuffer(1), __consumer_offsets-0 -> ArrayBuffer(2), __consumer_offsets-44 -> ArrayBuffer(1), __consumer_offsets-39 -> ArrayBuffer(2), __consumer_offsets-12 -> ArrayBuffer(2), __consumer_offsets-45 -> ArrayBuffer(2), __consumer_offsets-1 -> ArrayBuffer(3), __consumer_offsets-5 -> ArrayBuffer(1), __consumer_offsets-26 -> ArrayBuffer(1), __consumer_offsets-29 -> ArrayBuffer(1), __consumer_offsets-34 -> ArrayBuffer(3), __consumer_offsets-10 -> ArrayBuffer(3), __consumer_offsets-32 -> ArrayBuffer(1), __consumer_offsets-40 -> ArrayBuffer(3)) (kafka.zk.AdminZkClient)
[2019-01-10 02:52:09,588] INFO [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-01-10 02:52:10,376] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:52:10,356] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:52:10,428] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:52:10,429] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:10,458] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-01-10 02:52:10,463] INFO Created log for partition __consumer_offsets-0 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:10,466] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-01-10 02:52:10,474] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:10,477] INFO [Partition __consumer_offsets-0 broker=2] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:10,559] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:10,573] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-01-10 02:52:10,588] INFO Created log for partition __consumer_offsets-48 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:10,592] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-01-10 02:52:10,594] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:10,605] INFO [Partition __consumer_offsets-48 broker=2] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:10,624] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:10,652] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:10,679] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 159 ms (kafka.log.Log)
[2019-01-10 02:52:10,673] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:10,696] INFO Created log for partition __consumer_offsets-29 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:10,702] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2019-01-10 02:52:10,699] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2019-01-10 02:52:10,709] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 173 ms (kafka.log.Log)
[2019-01-10 02:52:10,708] INFO Created log for partition __consumer_offsets-45 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:10,723] INFO Created log for partition __consumer_offsets-10 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:10,723] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:10,711] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-01-10 02:52:10,729] INFO [Partition __consumer_offsets-10 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-01-10 02:52:10,745] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:10,738] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:10,750] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:10,752] INFO [Partition __consumer_offsets-45 broker=2] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:10,759] INFO [Partition __consumer_offsets-10 broker=3] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:10,853] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:10,861] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-01-10 02:52:10,864] INFO Created log for partition __consumer_offsets-42 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:10,869] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-01-10 02:52:10,871] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:10,873] INFO [Partition __consumer_offsets-42 broker=2] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:10,919] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:10,928] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:10,928] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2019-01-10 02:52:10,937] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:10,937] INFO Created log for partition __consumer_offsets-26 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:10,941] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2019-01-10 02:52:10,946] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-01-10 02:52:10,949] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-01-10 02:52:10,957] INFO Created log for partition __consumer_offsets-7 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:10,958] INFO Created log for partition __consumer_offsets-39 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:10,953] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:10,969] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:10,960] INFO [Partition __consumer_offsets-7 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-01-10 02:52:10,977] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:10,969] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-01-10 02:52:10,990] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:10,990] INFO [Partition __consumer_offsets-7 broker=3] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,007] INFO [Partition __consumer_offsets-39 broker=2] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,063] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,072] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2019-01-10 02:52:11,074] INFO Created log for partition __consumer_offsets-23 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,075] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-01-10 02:52:11,076] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,077] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,112] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,120] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2019-01-10 02:52:11,123] INFO Created log for partition __consumer_offsets-4 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,125] INFO [Partition __consumer_offsets-4 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-01-10 02:52:11,133] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,134] INFO [Partition __consumer_offsets-4 broker=3] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,171] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,181] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-01-10 02:52:11,183] INFO Created log for partition __consumer_offsets-36 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,189] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-01-10 02:52:11,190] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,202] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,204] INFO [Partition __consumer_offsets-36 broker=2] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,220] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-01-10 02:52:11,228] INFO Created log for partition __consumer_offsets-20 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,234] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-01-10 02:52:11,235] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,236] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,319] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,329] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 100 ms (kafka.log.Log)
[2019-01-10 02:52:11,333] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,337] INFO Created log for partition __consumer_offsets-1 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,347] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-01-10 02:52:11,355] INFO Created log for partition __consumer_offsets-33 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,350] INFO [Partition __consumer_offsets-1 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,351] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,366] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,361] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-01-10 02:52:11,379] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,374] INFO [Partition __consumer_offsets-1 broker=3] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,382] INFO [Partition __consumer_offsets-33 broker=2] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,388] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2019-01-10 02:52:11,427] INFO Created log for partition __consumer_offsets-17 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,433] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-01-10 02:52:11,436] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,438] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,553] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,556] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,567] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 101 ms (kafka.log.Log)
[2019-01-10 02:52:11,574] INFO Created log for partition __consumer_offsets-49 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,584] INFO [Partition __consumer_offsets-49 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-01-10 02:52:11,588] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,589] INFO [Partition __consumer_offsets-49 broker=3] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,583] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,594] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 120 ms (kafka.log.Log)
[2019-01-10 02:52:11,603] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-01-10 02:52:11,610] INFO Created log for partition __consumer_offsets-30 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,613] INFO Created log for partition __consumer_offsets-14 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,621] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-01-10 02:52:11,624] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,621] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-01-10 02:52:11,634] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,636] INFO [Partition __consumer_offsets-30 broker=2] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,628] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,694] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,703] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-01-10 02:52:11,707] INFO Created log for partition __consumer_offsets-46 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,708] INFO [Partition __consumer_offsets-46 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-01-10 02:52:11,718] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,719] INFO [Partition __consumer_offsets-46 broker=3] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,718] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,758] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-01-10 02:52:11,760] INFO Created log for partition __consumer_offsets-11 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,761] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-01-10 02:52:11,763] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,764] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,843] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,854] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 101 ms (kafka.log.Log)
[2019-01-10 02:52:11,857] INFO Created log for partition __consumer_offsets-27 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,866] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-01-10 02:52:11,867] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,862] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,869] INFO [Partition __consumer_offsets-27 broker=2] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,877] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-01-10 02:52:11,886] INFO Created log for partition __consumer_offsets-43 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,889] INFO [Partition __consumer_offsets-43 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-01-10 02:52:11,891] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,893] INFO [Partition __consumer_offsets-43 broker=3] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,968] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:11,978] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 108 ms (kafka.log.Log)
[2019-01-10 02:52:11,981] INFO Created log for partition __consumer_offsets-8 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:11,982] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-01-10 02:52:11,988] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:11,991] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:11,995] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,004] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-10 02:52:12,008] INFO Created log for partition __consumer_offsets-24 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,011] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-01-10 02:52:12,011] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,013] INFO [Partition __consumer_offsets-24 broker=2] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,094] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,101] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-01-10 02:52:12,103] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,108] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,110] INFO Created log for partition __consumer_offsets-5 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,128] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-01-10 02:52:12,129] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2019-01-10 02:52:12,130] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-10 02:52:12,133] INFO Created log for partition __consumer_offsets-40 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,157] INFO [Partition __consumer_offsets-40 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-01-10 02:52:12,147] INFO Created log for partition __consumer_offsets-21 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,167] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,132] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,185] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,182] INFO [Partition __consumer_offsets-40 broker=3] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,182] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-01-10 02:52:12,191] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,203] INFO [Partition __consumer_offsets-21 broker=2] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,338] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,344] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-01-10 02:52:12,339] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,360] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,361] INFO Created log for partition __consumer_offsets-2 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,374] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-01-10 02:52:12,382] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2019-01-10 02:52:12,376] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-01-10 02:52:12,386] INFO Created log for partition __consumer_offsets-18 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,380] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,394] INFO Created log for partition __consumer_offsets-37 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,393] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,393] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-01-10 02:52:12,401] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,398] INFO [Partition __consumer_offsets-37 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-01-10 02:52:12,412] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,417] INFO [Partition __consumer_offsets-37 broker=3] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,411] INFO [Partition __consumer_offsets-18 broker=2] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,526] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,534] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-10 02:52:12,527] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,541] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,540] INFO Created log for partition __consumer_offsets-34 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,573] INFO [Partition __consumer_offsets-34 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-01-10 02:52:12,576] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,578] INFO [Partition __consumer_offsets-34 broker=3] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,557] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-01-10 02:52:12,594] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 99 ms (kafka.log.Log)
[2019-01-10 02:52:12,599] INFO Created log for partition __consumer_offsets-15 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,611] INFO Created log for partition __consumer_offsets-47 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,602] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-01-10 02:52:12,615] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,614] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-01-10 02:52:12,623] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,621] INFO [Partition __consumer_offsets-15 broker=2] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,633] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,746] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,754] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-01-10 02:52:12,756] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,755] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,759] INFO Created log for partition __consumer_offsets-38 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,767] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 131 ms (kafka.log.Log)
[2019-01-10 02:52:12,771] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-01-10 02:52:12,774] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,770] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-01-10 02:52:12,785] INFO Created log for partition __consumer_offsets-12 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,787] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-01-10 02:52:12,787] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,789] INFO [Partition __consumer_offsets-12 broker=2] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,777] INFO Created log for partition __consumer_offsets-31 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,807] INFO [Partition __consumer_offsets-31 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-01-10 02:52:12,782] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,809] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,811] INFO [Partition __consumer_offsets-31 broker=3] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,936] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,936] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,944] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-01-10 02:52:12,949] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2019-01-10 02:52:12,952] INFO Created log for partition __consumer_offsets-9 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,956] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-01-10 02:52:12,957] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,958] INFO Created log for partition __consumer_offsets-35 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:12,970] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:12,959] INFO [Partition __consumer_offsets-9 broker=2] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,961] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-01-10 02:52:12,978] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:12,982] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-01-10 02:52:12,984] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:12,999] INFO Created log for partition __consumer_offsets-19 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,006] INFO [Partition __consumer_offsets-19 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-01-10 02:52:13,015] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,016] INFO [Partition __consumer_offsets-19 broker=3] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,080] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,088] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2019-01-10 02:52:13,092] INFO Created log for partition __consumer_offsets-6 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,094] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-01-10 02:52:13,103] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,112] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,118] INFO [Partition __consumer_offsets-6 broker=2] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,130] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2019-01-10 02:52:13,136] INFO Created log for partition __consumer_offsets-28 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,144] INFO [Partition __consumer_offsets-28 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-01-10 02:52:13,146] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,149] INFO [Partition __consumer_offsets-28 broker=3] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,151] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,161] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-01-10 02:52:13,165] INFO Created log for partition __consumer_offsets-44 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,167] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-01-10 02:52:13,169] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,177] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,210] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,221] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-01-10 02:52:13,227] INFO Created log for partition __consumer_offsets-3 in C:\tmp\kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,230] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-01-10 02:52:13,232] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,233] INFO [Partition __consumer_offsets-3 broker=2] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,324] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,327] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,340] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-01-10 02:52:13,332] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2019-01-10 02:52:13,343] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,345] INFO Created log for partition __consumer_offsets-32 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,348] INFO Created log for partition __consumer_offsets-25 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,350] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,368] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,364] INFO [Partition __consumer_offsets-25 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-01-10 02:52:13,369] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 19 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,363] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-01-10 02:52:13,383] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,370] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,379] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,393] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,388] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,395] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,399] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,373] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,404] INFO [Partition __consumer_offsets-25 broker=3] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,401] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,402] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,428] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,432] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,439] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,440] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,434] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,441] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,444] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,444] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,456] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,457] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,459] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,459] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,448] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,483] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,485] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,490] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,505] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,508] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,513] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,516] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,506] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,492] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,519] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,523] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-01-10 02:52:13,545] INFO Created log for partition __consumer_offsets-16 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,548] INFO [Partition __consumer_offsets-16 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-01-10 02:52:13,548] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,549] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,551] INFO [Partition __consumer_offsets-16 broker=3] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,552] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,632] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,633] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 173 ms (kafka.log.Log)
[2019-01-10 02:52:13,642] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-01-10 02:52:13,649] INFO Created log for partition __consumer_offsets-41 in C:\tmp\kafka-logs-1 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,648] INFO Created log for partition __consumer_offsets-22 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,653] INFO [Partition __consumer_offsets-22 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-01-10 02:52:13,659] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,652] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-01-10 02:52:13,665] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,669] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,660] INFO [Partition __consumer_offsets-22 broker=3] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,737] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,750] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,763] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,766] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,769] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,770] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,777] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,778] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,770] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,780] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,782] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,783] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,785] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,792] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,795] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,796] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,798] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,797] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,799] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,801] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,808] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,810] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,811] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,813] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,814] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,815] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,832] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,834] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,835] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,828] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:52:13,837] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,845] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs-3] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 118 ms (kafka.log.Log)
[2019-01-10 02:52:13,850] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,853] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,855] INFO Created log for partition __consumer_offsets-13 in C:\tmp\kafka-logs-3 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-01-10 02:52:13,859] INFO [Partition __consumer_offsets-13 broker=3] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-01-10 02:52:13,863] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:52:13,866] INFO [Partition __consumer_offsets-13 broker=3] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:52:13,928] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,933] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,938] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,939] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,940] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,941] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,943] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,951] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,953] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,954] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,954] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-22 in 21 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,956] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,958] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,959] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,959] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,960] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,972] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,974] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,973] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-28 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,977] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,978] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,992] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:13,997] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-37 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,007] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,009] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,010] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,012] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,020] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,021] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,023] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,024] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,026] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,028] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,037] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-19 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:52:14,122] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-52552 in state PreparingRebalance with old generation 0 (__consumer_offsets-40) (reason: Adding new member consumer-1-f8def7d6-9560-4495-a9d3-788ded49957b) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:52:14,151] INFO [GroupCoordinator 3]: Stabilized group console-consumer-52552 generation 1 (__consumer_offsets-40) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:52:14,172] INFO [GroupCoordinator 3]: Assignment received from leader for group console-consumer-52552 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:52:31,898] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-52552 in state PreparingRebalance with old generation 1 (__consumer_offsets-40) (reason: removing member consumer-1-f8def7d6-9560-4495-a9d3-788ded49957b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:52:31,901] INFO [GroupCoordinator 3]: Group console-consumer-52552 with generation 2 is now empty (__consumer_offsets-40) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:02,986] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-50323 in state PreparingRebalance with old generation 0 (__consumer_offsets-44) (reason: Adding new member consumer-1-1b400e9f-29f4-4db4-8f04-784abfdb0fea) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:03,010] INFO [GroupCoordinator 1]: Stabilized group console-consumer-50323 generation 1 (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:03,034] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-50323 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:32,122] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-50323 in state PreparingRebalance with old generation 1 (__consumer_offsets-44) (reason: removing member consumer-1-1b400e9f-29f4-4db4-8f04-784abfdb0fea on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:32,126] INFO [GroupCoordinator 1]: Group console-consumer-50323 with generation 2 is now empty (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:39,785] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-60863 in state PreparingRebalance with old generation 0 (__consumer_offsets-44) (reason: Adding new member consumer-1-965f1ee2-66f4-463f-8943-444044450ce5) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:39,793] INFO [GroupCoordinator 1]: Stabilized group console-consumer-60863 generation 1 (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:39,808] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-60863 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:47,618] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:53:47,634] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 02:53:47,678] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-01-10 02:53:47,687] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:53:47,689] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:53:47,689] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:53:47,695] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:53:47,728] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:53:47,752] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:53:47,760] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:53:47,765] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 02:53:47,767] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:47,875] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:47,875] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:47,883] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:53:47,889] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:53:47,898] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 02:53:47,899] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:53:47,903] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:53:47,903] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:53:47,912] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:53:47,915] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:47,916] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:47,953] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:47,953] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:47,953] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,017] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,017] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,028] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:53:48,033] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 02:53:48,039] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:53:48,049] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:53:48,050] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:53:48,065] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:53:48,070] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:53:48,072] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:53:48,076] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:53:48,078] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,276] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,276] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,284] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,477] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,477] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,480] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,677] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,677] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:53:48,721] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 02:53:48,725] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:53:48,993] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-10 02:53:49,256] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:53:49,283] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:53:49,285] INFO Processed session termination for sessionid: 0x1002feb4b050000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:53:49,303] INFO Session: 0x1002feb4b050000 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:53:49,309] INFO EventThread shut down for session: 0x1002feb4b050000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:53:49,304] INFO Closed socket connection for client /127.0.0.1:62301 which had sessionid 0x1002feb4b050000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:53:49,311] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:53:49,316] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:53:49,338] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:multi cxid:0x69 zxid:0xdb txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:53:49,653] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:multi cxid:0xe9 zxid:0xdc txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:53:49,687] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050005 type:multi cxid:0xeb zxid:0xdd txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:53:49,747] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:53:49,747] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:53:49,751] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:53:50,746] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:53:50,746] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:53:50,755] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:53:51,746] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:53:51,746] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:53:51,761] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:53:51,827] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:53:51,833] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:55:17,219] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 02:55:18,238] INFO starting (kafka.server.KafkaServer)
[2019-01-10 02:55:18,240] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 02:55:18,273] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:55:18,631] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,632] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,642] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,645] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,647] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,657] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,664] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,694] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,696] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,697] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,698] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,699] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,701] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,702] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,703] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,713] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:18,761] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:55:18,763] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:55:18,774] INFO Accepted socket connection from /127.0.0.1:62675 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 02:55:18,774] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:55:18,788] INFO Client attempting to establish new session at /127.0.0.1:62675 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:55:18,882] INFO Established session 0x1002feb4b050006 with negotiated timeout 6000 for client /127.0.0.1:62675 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 02:55:18,892] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002feb4b050006, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:55:18,909] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:55:18,997] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0x1 zxid:0xdf txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,051] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0x2 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,119] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0x3 zxid:0xe1 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,192] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0x4 zxid:0xe2 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,235] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0x5 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,325] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0x6 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,365] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0x7 zxid:0xe5 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,391] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0x8 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,413] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0x9 zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,436] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0xa zxid:0xe8 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,501] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0xb zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,523] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0xc zxid:0xea txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,568] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050006 type:create cxid:0xd zxid:0xeb txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:19,942] INFO Cluster ID = 9FPkoAAvTWKM-AdrrQ_WsQ (kafka.server.KafkaServer)
[2019-01-10 02:55:20,126] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:55:20,163] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 02:55:20,239] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:20,240] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:20,250] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:20,355] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 02:55:20,585] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:20,614] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 175 ms (kafka.log.Log)
[2019-01-10 02:55:20,688] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:20,690] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 46 ms (kafka.log.Log)
[2019-01-10 02:55:20,753] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:20,756] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 50 ms (kafka.log.Log)
[2019-01-10 02:55:20,835] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:20,842] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-01-10 02:55:20,913] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:20,920] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-01-10 02:55:20,989] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:20,992] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-01-10 02:55:21,057] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,060] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2019-01-10 02:55:21,132] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,137] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-01-10 02:55:21,210] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,212] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-01-10 02:55:21,288] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,290] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-01-10 02:55:21,367] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,369] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-01-10 02:55:21,444] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,447] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-01-10 02:55:21,534] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,550] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\__consumer_offsets-44\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-01-10 02:55:21,612] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 153 ms (kafka.log.Log)
[2019-01-10 02:55:21,678] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,680] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-01-10 02:55:21,788] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,791] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 98 ms (kafka.log.Log)
[2019-01-10 02:55:21,865] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 02:55:21,869] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-01-10 02:55:21,886] INFO Logs loading complete in 1530 ms. (kafka.log.LogManager)
[2019-01-10 02:55:21,915] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 02:55:21,924] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 02:55:22,550] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2019-01-10 02:55:22,609] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 02:55:22,642] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:22,648] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:22,648] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:22,672] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:55:22,755] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 02:55:22,822] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 02:55:22,827] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 02:55:22,981] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:22,989] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:22,989] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:23,054] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:23,058] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:23,071] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:23,157] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:55:23,203] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:55:23,208] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:55:23,209] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:55:23,275] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:55:23,305] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 02:55:23,321] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:55:23,322] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 02:55:23,326] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 02:55:23,501] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:55:23,522] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:23,530] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:23,640] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:23,641] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:23,694] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:23,695] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:23,750] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:23,751] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:23,803] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:23,804] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:23,865] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:23,866] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:23,929] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:23,932] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,010] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:24,012] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,076] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:24,077] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,124] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:24,125] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,183] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:24,184] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,238] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:24,240] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,309] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:24,310] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,377] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 3 (kafka.cluster.Replica)
[2019-01-10 02:55:24,378] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,397] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:24,398] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,482] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 02:55:24,484] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 02:55:24,576] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,580] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,596] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,601] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,603] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,603] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,606] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,614] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,618] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,625] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,628] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,630] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,631] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,632] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,634] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,641] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,646] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 67 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,658] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,660] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,662] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,666] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:55:24,669] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,671] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:24,672] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,676] WARN [LeaderEpochCache __consumer_offsets-29] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:24,677] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,680] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,687] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,688] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,690] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,691] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,692] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,694] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,719] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:24,719] WARN [LeaderEpochCache __consumer_offsets-26] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:24,741] INFO [GroupCoordinator 1]: Loading group metadata for console-consumer-50323 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:24,743] INFO [GroupCoordinator 1]: Loading group metadata for console-consumer-60863 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:24,752] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:24,753] WARN [LeaderEpochCache __consumer_offsets-23] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:24,765] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 70 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,766] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:55:24,793] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:24,793] WARN [LeaderEpochCache __consumer_offsets-20] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:24,843] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:24,843] WARN [LeaderEpochCache __consumer_offsets-17] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:24,898] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:24,899] WARN [LeaderEpochCache __consumer_offsets-14] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:24,963] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:24,964] WARN [LeaderEpochCache __consumer_offsets-11] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:25,026] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:25,026] WARN [LeaderEpochCache __consumer_offsets-8] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:25,073] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:25,074] WARN [LeaderEpochCache __consumer_offsets-5] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:25,118] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:25,119] WARN [LeaderEpochCache __consumer_offsets-2] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:25,160] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:25,161] WARN [LeaderEpochCache __consumer_offsets-47] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:25,221] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:25,222] WARN [LeaderEpochCache __consumer_offsets-38] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:25,275] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:25,275] WARN [LeaderEpochCache __consumer_offsets-35] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:25,331] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 1 from offset 3. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:25,387] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:25,388] WARN [LeaderEpochCache __consumer_offsets-32] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:25,440] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 1 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2019-01-10 02:55:25,441] WARN [LeaderEpochCache __consumer_offsets-41] New epoch entry EpochEntry(epoch=1, startOffset=0) caused truncation of conflicting entries ListBuffer(EpochEntry(epoch=0, startOffset=0)). Cache now contains 1 entries. (kafka.server.epoch.LeaderEpochFileCache)
[2019-01-10 02:55:31,673] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-97156 in state PreparingRebalance with old generation 0 (__consumer_offsets-39) (reason: Adding new member consumer-1-0569d545-6582-4056-b703-f72e9347ad0f) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:31,698] INFO [GroupCoordinator 2]: Stabilized group console-consumer-97156 generation 1 (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:31,723] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-97156 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:34,780] INFO [GroupCoordinator 1]: Member consumer-1-965f1ee2-66f4-463f-8943-444044450ce5 in group console-consumer-60863 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:34,794] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-60863 in state PreparingRebalance with old generation 1 (__consumer_offsets-44) (reason: removing member consumer-1-965f1ee2-66f4-463f-8943-444044450ce5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:34,803] INFO [GroupCoordinator 1]: Group console-consumer-60863 with generation 2 is now empty (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:37,578] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-01-10 02:55:37,582] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 02:55:37,645] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-01-10 02:55:37,655] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:55:37,657] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:55:37,657] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 02:55:37,664] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:55:37,703] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 02:55:37,706] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:55:37,714] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 02:55:37,723] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 02:55:37,727] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:37,871] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:37,871] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:37,878] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:55:37,880] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 3000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 02:55:37,881] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 02:55:37,881] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:55:37,885] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:55:37,885] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 02:55:37,891] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 02:55:37,892] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:37,892] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:37,977] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:37,977] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:37,985] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,071] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,071] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,080] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 02:55:38,085] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 02:55:38,090] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:55:38,092] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:55:38,092] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 02:55:38,098] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:55:38,108] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 02:55:38,109] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:55:38,110] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 02:55:38,112] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,166] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,166] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,171] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,366] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,366] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,373] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,567] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,567] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 02:55:38,600] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 02:55:38,602] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 02:55:38,805] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2019-01-10 02:55:39,039] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 02:55:39,060] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:55:39,064] INFO Processed session termination for sessionid: 0x1002feb4b050006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 02:55:39,086] INFO Session: 0x1002feb4b050006 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 02:55:39,087] INFO Closed socket connection for client /127.0.0.1:62675 which had sessionid 0x1002feb4b050006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 02:55:39,093] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 02:55:39,098] INFO EventThread shut down for session: 0x1002feb4b050006 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 02:55:39,101] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:39,253] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:39,253] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:39,256] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:39,262] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:39,262] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:39,263] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:40,261] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:40,261] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 02:55:40,274] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 02:55:40,343] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 02:55:40,353] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-01-10 02:57:07,653] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 10 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:58:10,011] INFO [GroupMetadataManager brokerId=3] Group console-consumer-52552 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 02:58:10,028] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 24 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:15,307] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-01-10 03:01:16,244] INFO starting (kafka.server.KafkaServer)
[2019-01-10 03:01:16,246] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-01-10 03:01:16,275] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 03:01:16,474] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,475] INFO Client environment:host.name=192.168.1.6 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,478] INFO Client environment:java.version=10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,479] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,480] INFO Client environment:java.home=C:\Program Files\Java\jre-10.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,481] INFO Client environment:java.class.path=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\activation-1.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\argparse4j-0.7.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\audience-annotations-0.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\commons-lang3-3.5.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\compileScala.mapping.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-api-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-basic-auth-extension-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-file-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-json-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-runtime-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\connect-transforms-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\guava-20.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-api-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-locator-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\hk2-utils-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-core-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-databind-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-base-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-jaxrs-json-provider-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jackson-module-jaxb-annotations-2.9.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javassist-3.22.0-CR2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.annotation-api-1.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.inject-2.5.0-b42.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.servlet-api-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\javax.ws.rs-api-2.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jaxb-api-2.3.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-client-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-common-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-container-servlet-core-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-hk2-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-media-jaxb-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jersey-server-2.27.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-client-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-continuation-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-http-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-io-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-security-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-server-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlet-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-servlets-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jetty-util-9.4.12.v20180830.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\jopt-simple-5.0.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-clients-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-log4j-appender-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-examples-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-scala_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-streams-test-utils-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka-tools-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-javadoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-scaladoc.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test-sources.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0-test.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\kafka_2.12-2.1.0.jar.asc;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\log4j-1.2.17.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\lz4-java-1.5.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\maven-artifact-3.5.4.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\metrics-core-2.2.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\osgi-resource-locator-1.0.1.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\plexus-utils-3.1.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\reflections-0.9.11.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\rocksdbjni-5.14.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-library-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-logging_2.12-3.9.0.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\scala-reflect-2.12.7.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-api-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\slf4j-log4j12-1.7.25.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\snappy-java-1.1.7.2.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\validation-api-1.1.0.Final.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zkclient-0.10.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zookeeper-3.4.13.jar;C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0\libs\zstd-jni-1.3.5-4.jar (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,488] INFO Client environment:java.library.path=C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Common Files\lenovo\easyplussdk\bin;C:\Program Files (x86)\ATI Technologies\ATI.ACE\Core-Static;C:\Program Files (x86)\GTK2-Runtime\lib;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files (x86)\Windows Live\Shared;C:\Program Files\Git\cmd;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\Scripts\;C:\Users\AYUSH\AppData\Local\Programs\Python\Python36\;C:\Program Files\Java\jdk-10.0.2\bin;C:\Users\AYUSH\AppData\Local\Microsoft\WindowsApps;. (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,490] INFO Client environment:java.io.tmpdir=C:\Users\AYUSH\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,491] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,492] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,493] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,494] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,495] INFO Client environment:user.name=AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,497] INFO Client environment:user.home=C:\Users\AYUSH (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,499] INFO Client environment:user.dir=C:\Users\AYUSH\Desktop\Ronnie\kafka_2.12-2.1.0 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,502] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@79517588 (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:01:16,552] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 03:01:16,553] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-01-10 03:01:16,558] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-01-10 03:01:16,558] INFO Accepted socket connection from /127.0.0.1:62766 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-01-10 03:01:16,570] INFO Client attempting to establish new session at /127.0.0.1:62766 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 03:01:16,664] INFO Established session 0x1002feb4b050007 with negotiated timeout 6000 for client /127.0.0.1:62766 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-01-10 03:01:16,671] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1002feb4b050007, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 03:01:16,688] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 03:01:16,783] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0x1 zxid:0x110 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:16,821] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0x2 zxid:0x111 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:16,872] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0x3 zxid:0x112 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:16,929] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0x4 zxid:0x113 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:16,950] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0x5 zxid:0x114 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:16,972] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0x6 zxid:0x115 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:17,001] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0x7 zxid:0x116 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:17,028] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0x8 zxid:0x117 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:17,050] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0x9 zxid:0x118 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:17,072] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0xa zxid:0x119 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:17,095] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0xb zxid:0x11a txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:17,116] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0xc zxid:0x11b txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:17,138] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:create cxid:0xd zxid:0x11c txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:01:17,557] INFO Cluster ID = 9FPkoAAvTWKM-AdrrQ_WsQ (kafka.server.KafkaServer)
[2019-01-10 03:01:17,721] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 03:01:17,745] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-01-10 03:01:17,823] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:01:17,823] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:01:17,823] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:01:17,927] INFO Loading logs. (kafka.log.LogManager)
[2019-01-10 03:01:18,203] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,225] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 195 ms (kafka.log.Log)
[2019-01-10 03:01:18,300] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,305] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2019-01-10 03:01:18,371] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,374] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-01-10 03:01:18,448] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,450] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-01-10 03:01:18,523] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,528] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-01-10 03:01:18,603] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,606] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-01-10 03:01:18,666] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,669] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2019-01-10 03:01:18,734] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,736] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-01-10 03:01:18,778] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,781] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2019-01-10 03:01:18,870] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:18,872] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 82 ms (kafka.log.Log)
[2019-01-10 03:01:19,009] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:19,012] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 129 ms (kafka.log.Log)
[2019-01-10 03:01:19,081] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:19,083] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-01-10 03:01:19,182] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 4 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:19,197] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'C:\tmp\kafka-logs-1\__consumer_offsets-44\00000000000000000004.snapshot' (kafka.log.ProducerStateManager)
[2019-01-10 03:01:19,225] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 4 in 132 ms (kafka.log.Log)
[2019-01-10 03:01:19,292] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:19,294] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-01-10 03:01:19,368] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:19,371] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-01-10 03:01:19,454] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-01-10 03:01:19,457] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 77 ms (kafka.log.Log)
[2019-01-10 03:01:19,466] INFO Logs loading complete in 1539 ms. (kafka.log.LogManager)
[2019-01-10 03:01:19,493] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-01-10 03:01:19,497] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-01-10 03:01:20,204] INFO Awaiting socket connections on localhost:9092. (kafka.network.Acceptor)
[2019-01-10 03:01:20,262] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-01-10 03:01:20,298] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:01:20,299] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:01:20,300] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:01:20,318] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:01:20,435] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-01-10 03:01:20,470] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-01-10 03:01:20,474] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(localhost,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-01-10 03:01:20,663] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:01:20,667] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:01:20,669] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:01:20,700] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:01:20,703] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:01:20,709] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:20,749] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 03:01:20,811] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 03:01:20,816] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 03:01:20,816] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:01:20,922] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:01:20,945] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-01-10 03:01:20,955] INFO Kafka version : 2.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 03:01:20,956] INFO Kafka commitId : 809be928f1ae004e (org.apache.kafka.common.utils.AppInfoParser)
[2019-01-10 03:01:20,959] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-01-10 03:01:21,205] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,212] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,219] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,225] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,230] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,234] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,238] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,244] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,250] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,254] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,260] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,266] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,270] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,273] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 4 (kafka.cluster.Replica)
[2019-01-10 03:01:21,278] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,281] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-01-10 03:01:21,285] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2019-01-10 03:01:21,320] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-32) (kafka.server.ReplicaFetcherManager)
[2019-01-10 03:01:21,328] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,425] INFO [Partition __consumer_offsets-26 broker=1] __consumer_offsets-26 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,457] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,493] INFO [Partition __consumer_offsets-20 broker=1] __consumer_offsets-20 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,535] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,656] INFO [Partition __consumer_offsets-14 broker=1] __consumer_offsets-14 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,758] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,802] INFO [Partition __consumer_offsets-8 broker=1] __consumer_offsets-8 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,849] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,903] INFO [Partition __consumer_offsets-2 broker=1] __consumer_offsets-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:21,962] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:22,016] INFO [Partition __consumer_offsets-38 broker=1] __consumer_offsets-38 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:22,071] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:22,129] INFO [Partition __consumer_offsets-44 broker=1] __consumer_offsets-44 starts at Leader Epoch 3 from offset 4. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:22,184] INFO [Partition __consumer_offsets-32 broker=1] __consumer_offsets-32 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:22,238] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-01-10 03:01:22,299] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,305] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,313] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,313] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,315] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,316] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,317] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,318] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,318] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,318] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,319] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,319] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,319] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,319] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,320] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,320] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,343] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 38 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,345] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,345] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,346] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,346] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,347] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,347] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,348] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,348] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,349] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,349] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,350] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,350] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,351] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,395] INFO [GroupCoordinator 1]: Loading group metadata for console-consumer-50323 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:01:22,396] INFO [GroupCoordinator 1]: Loading group metadata for console-consumer-60863 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:01:22,397] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 46 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:01:22,397] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:07:07,643] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:08:10,005] INFO [GroupMetadataManager brokerId=3] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-01-10 03:10:07,249] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-97156 in state PreparingRebalance with old generation 1 (__consumer_offsets-39) (reason: removing member consumer-1-0569d545-6582-4056-b703-f72e9347ad0f on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:10:07,256] INFO [GroupCoordinator 2]: Group console-consumer-97156 with generation 2 is now empty (__consumer_offsets-39) (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:10:15,335] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2019-01-10 03:10:15,350] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 03:10:15,389] INFO [KafkaServer id=3] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-01-10 03:10:15,398] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:10:15,399] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:10:15,399] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:10:15,402] INFO [SocketServer brokerId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 03:10:15,429] INFO [SocketServer brokerId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 03:10:15,438] INFO [Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 03:10:15,451] INFO [Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 03:10:15,468] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 03:10:15,472] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:15,519] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:15,519] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:15,526] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 03:10:15,528] INFO [ProducerId Manager 3]: Shutdown complete: last producerId assigned 2000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 03:10:15,533] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 03:10:15,533] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:10:15,536] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:10:15,536] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:10:15,539] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 03:10:15,543] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:10:15,548] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:15,705] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:15,705] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:15,714] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:15,906] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:15,906] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:15,917] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:10:15,921] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 03:10:15,928] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:10:15,931] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:10:15,931] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:10:15,937] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 03:10:15,952] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 03:10:15,954] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 03:10:15,962] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 03:10:15,964] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:16,112] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:16,112] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:16,120] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:16,307] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:16,307] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:16,315] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:16,514] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:16,514] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:16,560] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 03:10:16,562] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 03:10:16,808] INFO [ProducerStateManager partition=__consumer_offsets-40] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-01-10 03:10:16,942] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 03:10:16,979] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 03:10:16,982] INFO Processed session termination for sessionid: 0x1002feb4b050005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:10:17,020] INFO Session: 0x1002feb4b050005 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:10:17,021] WARN Unable to read additional data from client sessionid 0x1002feb4b050005, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 03:10:17,025] INFO EventThread shut down for session: 0x1002feb4b050005 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 03:10:17,027] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 03:10:17,027] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:62381 which had sessionid 0x1002feb4b050005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 03:10:17,032] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:17,073] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:multi cxid:0x3a zxid:0x131 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:10:17,146] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:17,147] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:17,146] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:17,439] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:multi cxid:0xd7 zxid:0x132 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:10:17,472] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050003 type:multi cxid:0xd9 zxid:0x133 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:10:18,145] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:18,145] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:18,145] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:19,154] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:19,154] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:19,167] INFO [SocketServer brokerId=3] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 03:10:19,229] INFO [SocketServer brokerId=3] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 03:10:19,242] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2019-01-10 03:10:26,149] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-01-10 03:10:26,152] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 03:10:26,216] INFO [KafkaServer id=2] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-01-10 03:10:26,227] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:10:26,229] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:10:26,230] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:10:26,236] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 03:10:26,253] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 03:10:26,255] INFO [Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 03:10:26,267] INFO [Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 03:10:26,275] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 03:10:26,279] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,398] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,398] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,417] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 03:10:26,421] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 1000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 03:10:26,426] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 03:10:26,430] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:10:26,433] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:10:26,434] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:10:26,436] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 03:10:26,437] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:10:26,438] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,444] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,444] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,448] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,615] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,615] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,626] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:10:26,631] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 03:10:26,636] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:10:26,640] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:10:26,640] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:10:26,645] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 03:10:26,652] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 03:10:26,653] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 03:10:26,655] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 03:10:26,656] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,837] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,837] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,847] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,939] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,939] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:26,939] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:27,013] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:27,013] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:27,052] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 03:10:27,055] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 03:10:27,241] INFO [ProducerStateManager partition=old-skul-0] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2019-01-10 03:10:27,340] INFO [ProducerStateManager partition=__consumer_offsets-39] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-01-10 03:10:27,519] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 03:10:27,545] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 03:10:27,547] INFO Processed session termination for sessionid: 0x1002feb4b050003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:10:27,569] INFO Session: 0x1002feb4b050003 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:10:27,569] INFO Closed socket connection for client /127.0.0.1:62352 which had sessionid 0x1002feb4b050003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 03:10:27,578] INFO EventThread shut down for session: 0x1002feb4b050003 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 03:10:27,586] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 03:10:27,587] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:27,895] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:multi cxid:0xca zxid:0x136 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:10:27,931] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:27,931] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:27,933] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:27,939] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:27,939] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:27,939] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:27,985] INFO Got user-level KeeperException when processing sessionid:0x1002feb4b050007 type:multi cxid:0xcc zxid:0x137 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:10:28,932] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:28,932] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:28,947] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 03:10:29,016] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 03:10:29,027] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-01-10 03:10:40,920] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-01-10 03:10:40,936] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-01-10 03:10:40,974] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-01-10 03:10:40,980] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:10:40,981] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:10:40,981] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-01-10 03:10:40,982] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-01-10 03:10:41,002] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-01-10 03:10:41,003] INFO [Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 03:10:41,012] INFO [Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-01-10 03:10:41,020] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-01-10 03:10:41,026] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,089] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,089] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,100] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 03:10:41,103] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 4000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-01-10 03:10:41,111] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-01-10 03:10:41,112] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:10:41,113] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:10:41,113] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-01-10 03:10:41,115] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-01-10 03:10:41,118] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:10:41,127] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,175] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,175] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,175] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,282] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,282] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,288] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-01-10 03:10:41,291] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-01-10 03:10:41,292] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:10:41,293] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:10:41,293] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-01-10 03:10:41,296] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-01-10 03:10:41,310] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-01-10 03:10:41,312] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 03:10:41,318] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-01-10 03:10:41,318] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,352] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,352] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,358] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,547] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,547] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,553] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,579] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,579] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-01-10 03:10:41,646] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-01-10 03:10:41,648] INFO Shutting down. (kafka.log.LogManager)
[2019-01-10 03:10:42,001] INFO Shutdown complete. (kafka.log.LogManager)
[2019-01-10 03:10:42,027] INFO [ZooKeeperClient] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 03:10:42,029] INFO Processed session termination for sessionid: 0x1002feb4b050007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-01-10 03:10:42,060] INFO Session: 0x1002feb4b050007 closed (org.apache.zookeeper.ZooKeeper)
[2019-01-10 03:10:42,060] INFO Closed socket connection for client /127.0.0.1:62766 which had sessionid 0x1002feb4b050007 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-01-10 03:10:42,064] INFO [ZooKeeperClient] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-01-10 03:10:42,066] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:42,066] INFO EventThread shut down for session: 0x1002feb4b050007 (org.apache.zookeeper.ClientCnxn)
[2019-01-10 03:10:42,152] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:42,152] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:42,158] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:43,158] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:43,158] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:43,164] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:44,158] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:44,158] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-01-10 03:10:44,166] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-01-10 03:10:44,227] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-01-10 03:10:44,232] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
